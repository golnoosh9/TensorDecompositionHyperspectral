clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=50;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x65]             
B                    [3999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       29-      36  2.2711e+02  3.2575e+01  3.1703e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06        9-      42  1.3288e+03  3.9472e+01  5.5234e-06
    1T  5.7e-06       31-      41  5.7578e+02  3.6881e+01  1.0220e-06
    1T -2.9e-06       24-      36  1.2505e+03  3.8870e+01  1.2639e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-07       18-      36  1.4136e+03  3.3300e+01  4.2578e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       17-      42  5.4523e+02  3.3932e+01  8.6559e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       39-      37  2.9183e+02  2.8850e+01  3.5980e-03
    1T  9.5e-06        5-      35  4.8717e+02  3.1891e+01  9.6687e-06

indexes =

  Columns 1 through 13

   127    84   195    77    38   106    31    58   179    94   183    75    49

  Columns 14 through 26

   190   172   118    14    17    76   167   179   113   193    16    88   193

  Columns 27 through 30

    39   100   137   122


Accuracy =

   98.2255


Accuracy =

   98.0524


Accuracy =

   98.2100


Accuracy =

   98.3185


Accuracy =

   98.0963


Accuracy =

   98.2177


Accuracy =

   98.3004


Accuracy =

   98.2152


Accuracy =

   98.1299


Accuracy =

   98.3624


Accuracy =9.836239e+01

AverageAccuracy =

   96.5481

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('indian_pines_gt');
{Error using load
Unable to read file 'indian_pines_gt'. No such file or directory.
} 
image=indian_pines_corrected;
image_gt=indian_pines_gt;
{Undefined function or variable 'indian_pines_gt'.
} 
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));
{Undefined function or variable 'image_gt'.
} 

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);
{Undefined function or variable 'image_gt'.
} 

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end
{Undefined function or variable 'class_num'.
} 

 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=50;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
{Undefined function or variable 'image_gt'.
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=50;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       42-      24  2.0893e+03  4.4062e+01  2.0514e-05

indexes =

  Columns 1 through 13

   125    52    67    79   127   136    11   107    17   163    22   180    50

  Columns 14 through 26

    89    69   137    73   102    49    18    78   182    50   132    22    53

  Columns 27 through 30

   126   190   183    53

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3650


Accuracy =

   96.4297


Accuracy =

   96.1601


Accuracy =

   96.0954


Accuracy =

   96.4621


Accuracy =

   96.2787


Accuracy =

   96.3111


Accuracy =

   95.9120


Accuracy =

   96.1601


Accuracy =

   96.3111


Accuracy =9.631108e+01

AverageAccuracy =

   93.9863

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=50;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       29-      45  1.5847e+03  4.9986e+01  1.5952e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       44-      42  1.9159e+03  4.2916e+01  9.1745e-05
    1T -3.2e-06       43-      41  4.5695e+03  4.1320e+01  1.4027e-03

indexes =

  Columns 1 through 13

   128    23   140    81    81    60    71   156    96    65   170   131   163

  Columns 14 through 26

   117   103   129   132   143    16    21   189   115   194   158   112    96

  Columns 27 through 30

    93   161   108    86

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.4869


Accuracy =

   94.9392


Accuracy =

   94.8746


Accuracy =

   94.7992


Accuracy =

   94.8638


Accuracy =

   94.4977


Accuracy =

   94.6700


Accuracy =

   94.7238


Accuracy =

   95.0468


Accuracy =

   95.0253


Accuracy =9.502530e+01

AverageAccuracy =

   92.3799

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=40;
trainingNum=40  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06        2-      35  3.0250e+03  4.9590e+01  6.8677e-06

indexes =

  Columns 1 through 13

   190    53    95   168   119    85   155   129   167    63   160    44    82

  Columns 14 through 26

    63   114    84    65   137   189   199   101   174   164    98   192   146

  Columns 27 through 30

   149    15    14   159

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.9675


Accuracy =

   93.7305


Accuracy =

   94.3876


Accuracy =

   93.5797


Accuracy =

   93.5904


Accuracy =

   94.0106


Accuracy =

   93.7305


Accuracy =

   93.2565


Accuracy =

   93.5689


Accuracy =

   93.4288


Accuracy =9.342885e+01

AverageAccuracy =

   86.7130

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=55;
components=50;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [100x55]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       45-      37  1.7905e+03  3.7575e+01  3.2264e-05
    1T  5.8e-06       14-      40  2.0921e+03  3.5369e+01  1.6581e-03
    1T  1.8e-06       26-      36  1.5368e+03  3.0107e+01  1.3865e-05

indexes =

  Columns 1 through 13

    51   144   130   118    69   132    95    10   116   144   102    20   156

  Columns 14 through 26

   198    33   121   187   195   181    88   125   156   136   117   108   125

  Columns 27 through 30

   149   173   193    19

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.5706


Accuracy =

   95.2581


Accuracy =

   95.5383


Accuracy =

   95.3551


Accuracy =

   95.0426


Accuracy =

   95.5599


Accuracy =

   95.7431


Accuracy =

   95.3874


Accuracy =

   95.2473


Accuracy =

   95.4090


Accuracy =9.540899e+01

AverageAccuracy =

   90.6424

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:2:12
    R=65;
components=60;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [144x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       28-      55  3.2282e+03  5.1455e+01  2.1258e-05

indexes =

  Columns 1 through 13

   179   104    85   191   199   144   123   119    15   163   179    48   175

  Columns 14 through 26

    97    28    65   152    88    41   112   104   175    55    70    10     8

  Columns 27 through 30

    97   120   180    28

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.5101


Accuracy =

   95.6053


Accuracy =

   96.3270


Accuracy =

   96.1008


Accuracy =

   95.9285


Accuracy =

   95.7885


Accuracy =

   96.0470


Accuracy =

   96.3162


Accuracy =

   96.0254


Accuracy =

   96.3701


Accuracy =9.637010e+01

AverageAccuracy =

   94.7121

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
ClassAccuracy;


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       31-      61  2.1748e+03  3.6438e+01  1.4323e-04
    1T -8.0e-06        3-      61  2.1399e+03  3.2404e+01  3.6414e-05
    1T -9.5e-06       51-      64  2.5109e+03  4.3965e+01  1.4366e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       65-      59  1.9965e+03  4.0174e+01  7.9616e-04

indexes =

  Columns 1 through 13

   182    74    90    55    39    15   194    14    43    85   174     1    83

  Columns 14 through 26

   157   175   112    85   111    59   159    29    33     3   155    17   200

  Columns 27 through 30

    31    25     3    49

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2835


Accuracy =

   96.0465


Accuracy =

   96.4990


Accuracy =

   95.8634


Accuracy =

   95.9388


Accuracy =

   96.1650


Accuracy =

   95.6480


Accuracy =

   96.2728


Accuracy =

   95.8419


Accuracy =

   96.2297


Accuracy =9.622967e+01

AverageAccuracy =

   90.3927

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=60;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100)

end

AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-07       20-      40  1.7206e+03  3.6319e+01  1.7796e-06
    1T -9.3e-06       29-      54  2.6569e+03  4.9681e+01  6.0690e-05
    1T -8.5e-06       26-      52  2.3744e+03  4.3657e+01  2.2378e-05

indexes =

  Columns 1 through 13

   168    64    75   198   128   181    20   194   193   132    24   101    31

  Columns 14 through 26

    47    97    94    26    96    10    96     9    60    60   104    27   145

  Columns 27 through 30

    78   115   108   127

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.5139


Accuracy =

   95.5570


Accuracy =

   95.6648


Accuracy =

   95.7727


Accuracy =

   95.6001


Accuracy =

   96.0746


Accuracy =

   95.9991


Accuracy =

   95.8266


Accuracy =

   95.0394


Accuracy =

   96.0423


Accuracy =9.604227e+01

i =

     1


class_accuracy =

   90.4762
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     2


class_accuracy =

   90.4762
   94.9768
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     3


class_accuracy =

   90.4762
   94.9768
   97.0706
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     4


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     5


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     6


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
         0
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     7


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
         0
         0
         0
         0
         0
         0
         0
         0
         0


i =

     8


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
         0
         0
         0
         0
         0
         0
         0
         0


i =

     9


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
         0
         0
         0
         0
         0
         0
         0


i =

    10


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
         0
         0
         0
         0
         0
         0


i =

    11


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
   97.9730
         0
         0
         0
         0
         0


i =

    12


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
   97.9730
   94.2272
         0
         0
         0
         0


i =

    13


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
   97.9730
   94.2272
   94.5946
         0
         0
         0


i =

    14


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
   97.9730
   94.2272
   94.5946
   98.5127
         0
         0


i =

    15


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
   97.9730
   94.2272
   94.5946
   98.5127
   98.8571
         0


i =

    16


class_accuracy =

   90.4762
   94.9768
   97.0706
   80.8411
   94.0367
   98.1791
   84.6154
   97.6905
   83.3333
   92.1591
   97.9730
   94.2272
   94.5946
   98.5127
   98.8571
   95.2941


AverageAccuracy =

   93.3023

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=60;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       54-      48  1.5516e+03  4.1582e+01  8.4485e-06

indexes =

  Columns 1 through 13

   117    44   148   200    20   113    41    34   161   105   104    37    73

  Columns 14 through 26

    73    39   156   161   113   175    36   149    42    89   165   198    34

  Columns 27 through 30

   168    93   146   144

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.5313


Accuracy =

   96.4990


Accuracy =

   96.5959


Accuracy =

   96.4990


Accuracy =

   96.4343


Accuracy =

   96.7683


Accuracy =

   96.8114


Accuracy =

   96.6067


Accuracy =

   95.9927


Accuracy =

   96.7037


Accuracy =9.670365e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   95.6690
   97.3404
   86.9767
   98.8506
   98.7897
   57.6923
   98.6143
   77.7778
   94.8980
   98.5573
   91.1111
  100.0000
   97.8204
   97.4359
   95.2381


AverageAccuracy =

   92.1792

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=60;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       22-      49  1.5995e+03  6.1770e+01  1.1017e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        3-      48  1.3172e+03  4.0832e+01  1.7079e-05
    1T  8.1e-06       23-      47  1.5138e+03  3.8985e+01  4.6076e-05

indexes =

  Columns 1 through 13

   113   198    78   141    56     8   198   167   174   183   158    41   192

  Columns 14 through 26

   127    14    20   129   155   200   184    39   179    92   150    68    44

  Columns 27 through 30

   147   162   109   140

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.7211


Accuracy =

   96.0983


Accuracy =

   95.7534


Accuracy =

   96.0121


Accuracy =

   95.6995


Accuracy =

   95.6564


Accuracy =

   95.7857


Accuracy =

   95.6887


Accuracy =

   95.8396


Accuracy =

   95.6672


Accuracy =9.566717e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   95.8301
   92.6667
   95.3704
   95.1945
   98.1846
  100.0000
   98.8532
   83.3333
   88.6234
   98.7370
   90.6716
   95.1872
   97.1154
   99.7143
   84.5238


AverageAccuracy =

   93.4349

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=60;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       40-      55  4.6745e+03  4.8541e+01  2.2636e-05
    1T  6.6e-06       60-      44  1.7440e+03  4.2735e+01  5.0349e-05
    1T -1.6e-06       20-      54  2.5867e+03  4.4318e+01  7.4641e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       57-      53  2.5479e+03  4.4010e+01  6.0990e-06
    1T  2.1e-06       21-      50  1.5707e+03  4.6761e+01  5.6945e-06
    1T  1.9e-06       59-      54  4.1545e+03  4.6769e+01  3.6340e-05

indexes =

  Columns 1 through 13

   169   149   177   103    60    44   200   123   165    77    40   195   151

  Columns 14 through 26

   182    47     9   105   150    62   199   154    26     1    47   189   157

  Columns 27 through 30

    77   124   189   157

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2484


Accuracy =

   96.2376


Accuracy =

   96.0867


Accuracy =

   96.4101


Accuracy =

   95.7740


Accuracy =

   95.8926


Accuracy =

   96.0975


Accuracy =

   95.8387


Accuracy =

   96.1729


Accuracy =

   95.8387


Accuracy =9.583872e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   94.5820
   95.8777
   88.9401
   92.4485
   99.0895
   76.9231
  100.0000
   88.8889
   87.2172
   98.8288
   94.0410
   99.4595
   97.8947
   97.1347
   96.4286


AverageAccuracy =

   93.4906

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       37-      64  5.8191e+03  5.3714e+01  5.3015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       37-      64  5.8191e+03  5.3714e+01  5.3015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       37-      64  5.8191e+03  5.3714e+01  5.3015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       37-      64  5.8191e+03  5.3714e+01  5.3015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       37-      64  5.8191e+03  5.3714e+01  5.3015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       17-      54  1.6422e+03  3.8136e+01  2.6963e-05

indexes =

  Columns 1 through 13

   181   132    83   110    10   185    29   107   147    27    91   180   169

  Columns 14 through 26

   113    52    76   149   139   103    47    84    54    94   149    72   140

  Columns 27 through 30

   109    51   148   107

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.7662


Accuracy =

   96.3889


Accuracy =

   96.9279


Accuracy =

   96.8632


Accuracy =

   96.7015


Accuracy =

   96.7770


Accuracy =

   97.1758


Accuracy =

   96.8201


Accuracy =

   96.7878


Accuracy =

   96.7123


Accuracy =9.671230e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   73.8095
   96.4341
   97.2112
   82.3256
   95.6522
   97.8852
  100.0000
   99.7696
  100.0000
   92.4915
   99.0999
   93.6685
  100.0000
   98.2533
   97.4138
   92.8571


AverageAccuracy =

   94.8045

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.05*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:2:10
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       16-      51  1.9377e+03  4.1659e+01  7.1192e-03

indexes =

  Columns 1 through 13

    88   161   130    30   190   165   137   107    56   188    49    90   185

  Columns 14 through 26

    71   146   192    38    34   144   129   163   199    44    18    49   103

  Columns 27 through 30

   150     9   149   148

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   92.2005


Accuracy =

   93.7788


Accuracy =

   93.9633


Accuracy =

   93.6661


Accuracy =

   94.5578


Accuracy =

   94.6090


Accuracy =

   90.2429


Accuracy =

   93.9428


Accuracy =

   94.9370


Accuracy =

   94.4655


Accuracy =9.446551e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   86.3636
   92.1887
   91.0013
   87.1681
   92.3747
   98.5612
   22.2222
   99.7807
   47.3684
   88.4574
   98.0300
   93.0973
   98.9796
   98.5075
   91.2807
   92.1348


AverageAccuracy =

   86.0948

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.389528s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       10-      43  4.2018e+03  2.7744e+01  2.4224e-05
    1T  5.8e-06       26-      44  5.3923e+03  3.1213e+01  2.8967e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       39-      43  3.0085e+03  2.9004e+01  6.0483e-05

indexes =

  Columns 1 through 13

    86   163    43   125   191    40    45    34   140    61    37    17   175

  Columns 14 through 26

   152   140   193   155    93    97   198   197     8   129   172   198    36

  Columns 27 through 30

   101   154   127   178

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.3211


Accuracy =

   94.0517


Accuracy =

   94.2026


Accuracy =

   94.5043


Accuracy =

   94.4828


Accuracy =

   94.5259


Accuracy =

   94.1056


Accuracy =

   94.3750


Accuracy =

   94.5905


Accuracy =

   94.4612


Accuracy =9.446121e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   93.5808
   93.4667
   83.3333
   93.1350
   97.2686
  100.0000
   99.5402
   88.8889
   84.3360
   97.1184
   90.1304
   97.8495
   98.0769
   98.5755
   96.4286


AverageAccuracy =

   93.7390

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.38996s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       25-      39  1.6875e+03  2.5093e+01  3.5103e-05
    1T  6.9e-06       40-      44  4.6731e+03  2.7764e+01  3.4066e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       45-      38  1.9936e+03  2.3028e+01  5.5506e-05

indexes =

  Columns 1 through 13

   120   115   146   133   133    90    11    90    77    14    88   196   181

  Columns 14 through 26

    66   195    83    51    95   198    47    31   153    32   169     1    90

  Columns 27 through 30

    41    33   132     2

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.6154


Accuracy =

   93.7446


Accuracy =

   93.8092


Accuracy =

   93.8200


Accuracy =

   94.2829


Accuracy =

   93.9922


Accuracy =

   93.6800


Accuracy =

   93.9169


Accuracy =

   94.1968


Accuracy =

   94.0245


Accuracy =9.402455e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   94.7287
   91.5888
   84.1860
   94.9657
   97.8852
   76.9231
   97.9167
   38.8889
   82.7664
   95.8689
   94.6197
   93.6170
   99.0393
   94.8864
   89.2857


AverageAccuracy =

   88.4539

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.385648s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-07        6-      41  2.9407e+03  2.6445e+01  2.8841e-06
    1T -9.9e-06        7-      41  5.6086e+03  2.6954e+01  8.8064e-05

indexes =

  Columns 1 through 13

    79   184    96    78   105   115    25   185    94    74   179   139    50

  Columns 14 through 26

    17    18    17    22    36   146    83    70   149    32   168    36     1

  Columns 27 through 30

   154    79   160    46

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.3242


Accuracy =

   93.6780


Accuracy =

   94.2488


Accuracy =

   94.0657


Accuracy =

   94.2165


Accuracy =

   94.2488


Accuracy =

   94.3996


Accuracy =

   94.3888


Accuracy =

   93.8611


Accuracy =

   94.1519


Accuracy =9.415186e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   89.7138
   89.2430
   87.9630
   94.2792
   97.1342
   26.9231
   98.6207
   27.7778
   89.1923
   97.3933
   92.3650
  100.0000
   99.2119
   97.4212
   95.2941


AverageAccuracy =

   85.6642

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.390342s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       41-      42  2.2037e+03  2.4773e+01  1.8238e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       41-      40  2.5548e+03  2.6328e+01  3.7909e-05
    1T  6.6e-06       15-      41  2.2806e+03  2.6348e+01  4.9403e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       27-      40  2.4693e+03  2.4854e+01  2.1368e-05

indexes =

  Columns 1 through 13

    38   161   122   107     6   128   124    40   134    79    88    99    34

  Columns 14 through 26

    26    34   157    64   175     8    95   139    19    24     1   189   102

  Columns 27 through 30

    28    57    66   133

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.6319


Accuracy =

   95.0954


Accuracy =

   94.7720


Accuracy =

   95.0092


Accuracy =

   94.5349


Accuracy =

   94.5780


Accuracy =

   94.6103


Accuracy =

   94.5457


Accuracy =

   94.7397


Accuracy =

   95.0738


Accuracy =9.507384e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   76.7442
   90.9232
   92.1228
   92.5926
   97.2540
   96.5099
   50.0000
   99.0741
   94.4444
   87.8271
   98.0207
   94.8148
   98.9189
   99.7387
   98.2808
   85.7143


AverageAccuracy =

   90.8113

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.386988s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       30-      43  3.2769e+03  3.0202e+01  3.3451e-05

indexes =

  Columns 1 through 13

    25    72    66    95   197     4     9   120    30   134   190    89    51

  Columns 14 through 26

    59    30    10   165    13   111    86    84   136   127    94   171    87

  Columns 27 through 30

   189   120     4    31

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.1265


Accuracy =

   94.3421


Accuracy =

   93.9649


Accuracy =

   94.5145


Accuracy =

   94.1050


Accuracy =

   94.0080


Accuracy =

   94.1481


Accuracy =

   94.0511


Accuracy =

   94.2990


Accuracy =

   94.2343


Accuracy =9.423429e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   94.2724
   89.1856
   74.4186
   92.9224
   97.8788
   46.1538
  100.0000
   36.8421
   85.3075
   97.2572
   94.2486
  100.0000
   99.5610
   96.0114
   89.2857


AverageAccuracy =

   86.3400

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.387776s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   145   168   151   183    14   188   113    53   150   172   145   104   143

  Columns 14 through 26

    49    76   166   131    54    53     3    71    75   166   178   148    53

  Columns 27 through 30

    48   200   188     4

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.4570


Accuracy =

   94.5001


Accuracy =

   94.6830


Accuracy =

   94.9521


Accuracy =

   94.7368


Accuracy =

   94.7907


Accuracy =

   94.6723


Accuracy =

   94.5431


Accuracy =

   94.9413


Accuracy =

   94.5862


Accuracy =9.458616e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   94.2724
   90.5710
   89.7196
   92.4658
   96.3636
   46.1538
   99.5413
   94.4444
   81.7873
   98.5175
   93.4823
  100.0000
   99.1266
   98.2857
   84.5238


AverageAccuracy =

   90.6082

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.387634s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       20-      44  4.6002e+03  2.6999e+01  4.1576e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       26-      43  3.2993e+03  2.5314e+01  6.7604e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       15-      42  2.4060e+03  2.4913e+01  1.7291e-05
    1T  6.5e-06       41-      40  2.6872e+03  2.5457e+01  5.8449e-05

indexes =

  Columns 1 through 13

   154   126    74    74    52   185    40   187   133   118    60   122    16

  Columns 14 through 26

    60    44    57    68    13    91    31   190    96   109    75     1    28

  Columns 27 through 30

    66    50   151   112

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.3208


Accuracy =

   95.0189


Accuracy =

   94.7062


Accuracy =

   95.2561


Accuracy =

   95.0296


Accuracy =

   95.1806


Accuracy =

   95.2237


Accuracy =

   95.2345


Accuracy =

   95.1375


Accuracy =

   95.1590


Accuracy =9.515903e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   94.1950
   93.2181
   91.1215
   95.6522
   98.0273
   76.9231
   99.0741
   88.8889
   92.9385
   97.3447
   88.2682
   91.3978
   98.0803
   95.1429
   79.7619


AverageAccuracy =

   91.9069

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.387992s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       32-      42  3.8308e+03  3.4408e+01  1.9520e-05
    1T  5.0e-06        4-      37  1.9020e+03  2.8535e+01  2.1003e-05

indexes =

  Columns 1 through 13

   162   113    92   189   151    55   156   119   144    98    21    88   113

  Columns 14 through 26

   124    32    72   170    28    70    73   133   116    63    55   180   150

  Columns 27 through 30

   118   162    79    95

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.2324


Accuracy =

   94.4265


Accuracy =

   93.6718


Accuracy =

   94.8038


Accuracy =

   94.1462


Accuracy =

   94.0815


Accuracy =

   94.4157


Accuracy =

   94.6313


Accuracy =

   93.7365


Accuracy =

   94.4480


Accuracy =9.444804e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   93.4833
   88.5790
   94.3925
   97.9452
   97.5684
   34.6154
   99.7685
   83.3333
   83.3144
   97.7978
   89.5327
   96.7742
   99.3019
   98.2759
   85.8824


AverageAccuracy =

   89.5889

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.40565s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       12-      39  2.5355e+03  2.5771e+01  7.5618e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       33-      42  3.1136e+03  2.5741e+01  9.2353e-05

indexes =

  Columns 1 through 13

    22    53   110   180   173    23   157   126    28   188   126   181   200

  Columns 14 through 26

   134    26    68    68   117    51   199    31   149    75   173    40    88

  Columns 27 through 30

     5    46   142    13

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.1411


Accuracy =

   93.1718


Accuracy =

   93.8072


Accuracy =

   93.7318


Accuracy =

   93.6457


Accuracy =

   93.9365


Accuracy =

   93.8718


Accuracy =

   93.8395


Accuracy =

   94.2811


Accuracy =

   94.1411


Accuracy =9.414109e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   93.5185
   89.8936
   89.3023
   88.5321
   98.1873
   92.3077
   98.8426
   61.1111
   85.2740
   97.4843
   94.7955
   99.4652
   97.0280
   92.8775
   92.8571


AverageAccuracy =

   91.0745

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=12:12:12
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [144x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.379503s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       21-      40  2.0805e+03  2.4631e+01  5.1361e-05
    1T -9.5e-06       29-      42  2.9258e+03  2.6527e+01  6.2610e-05

indexes =

  Columns 1 through 13

   168   105   158   131   151    21    33   114    39   141    58    25   125

  Columns 14 through 26

    90   171    97   119   200   104    87    61    95    64   179   117   143

  Columns 27 through 30

   186    46   131   187

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.7000


Accuracy =

   94.5707


Accuracy =

   94.3876


Accuracy =

   94.7862


Accuracy =

   94.2045


Accuracy =

   94.3984


Accuracy =

   94.0644


Accuracy =

   94.8508


Accuracy =

   94.6569


Accuracy =

   94.3876


Accuracy =9.438759e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   94.0632
   88.4154
   91.1215
   97.9452
   95.0151
         0
   99.5381
   83.3333
   85.1136
   98.8288
   92.1642
   96.2366
   98.6038
   94.5559
   81.1765


AverageAccuracy =

   86.0665

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 35 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 35
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: false


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06        8-      41  1.8151e+03  2.4673e+01  2.8227e-05
    1T  3.1e-06       28-      44  1.5601e+03  3.3936e+01  4.1932e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       24-      40  1.5537e+03  2.6320e+01  6.0154e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.1e-06       24-      39  1.6011e+03  2.6125e+01  5.5848e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-07       40-      41  1.6811e+03  2.6416e+01  6.8319e-06

indexes =

  Columns 1 through 13

   171   154    93   191   136    81   155   157   111   158   144    37    15

  Columns 14 through 26

    79    46   137    69   200   151    84   182    31   155    55   108   100

  Columns 27 through 30

    36    52    46   147

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.3097


Accuracy =

   94.6330


Accuracy =

   94.8594


Accuracy =

   94.2451


Accuracy =

   94.1696


Accuracy =

   95.2581


Accuracy =

   94.6223


Accuracy =

   94.2882


Accuracy =

   94.5576


Accuracy =

   94.5253


Accuracy =9.452527e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   94.5988
   88.4154
   85.0467
   95.8810
   98.7879
   46.1538
  100.0000
   77.7778
   93.7358
   94.1415
   92.3650
   97.8610
   99.9127
   93.1429
   78.5714


AverageAccuracy =

   89.4769

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       39-      37  1.3676e+03  2.3564e+01  1.1999e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-06       24-      43  4.2612e+03  2.8476e+01  2.6796e-05
    1T -6.1e-06       34-      33  1.8346e+03  2.1315e+01  7.4665e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06        2-      37  1.6537e+03  2.2846e+01  5.3167e-05
    1T -2.5e-07       14-      41  1.4328e+03  2.3612e+01  2.4091e-06

indexes =

  Columns 1 through 13

     6    49    90   117    74    10   102   149    62   127   114   186   121

  Columns 14 through 26

    85    30   118    62    62   122   128    46   178   132    89    81   121

  Columns 27 through 30

    93    46    42    64

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.6267


Accuracy =

   93.7129


Accuracy =

   93.9286


Accuracy =

   94.6943


Accuracy =

   94.1766


Accuracy =

   94.0580


Accuracy =

   94.1766


Accuracy =

   94.1335


Accuracy =

   93.7453


Accuracy =

   94.0580


Accuracy =9.405802e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.7209
   91.7375
   94.2743
   83.6449
   88.0460
   96.6616
  100.0000
  100.0000
   44.4444
   86.5297
   98.3326
   93.4944
   89.1892
   99.9129
   84.2857
   89.4118


AverageAccuracy =

   88.9804

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       38-      42  1.7520e+03  2.5598e+01  5.0686e-05

indexes =

  Columns 1 through 13

    53     9   123   173    99   122   143   150   108    53   132    83   115

  Columns 14 through 26

    59   142    23   194   166   116   102    73   119   119    25   100   156

  Columns 27 through 30

    21    36   194   112

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.1614


Accuracy =

   94.5492


Accuracy =

   94.3122


Accuracy =

   94.6784


Accuracy =

   93.9890


Accuracy =

   94.3122


Accuracy =

   94.0860


Accuracy =

   94.3014


Accuracy =

   94.1829


Accuracy =

   94.3337


Accuracy =9.433373e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   92.9621
   91.4780
   84.7222
   91.9908
   95.9276
   92.3077
  100.0000
   83.3333
   86.5909
   96.9833
   93.4701
   94.1176
   99.0385
   96.3068
   90.4762


AverageAccuracy =

   91.9161

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       26-      38  1.3941e+03  2.5297e+01  6.6475e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       19-      42  1.8509e+03  2.9434e+01  8.0698e-06

indexes =

  Columns 1 through 13

    73    87    43    91    58   122   144    59   112    25   171   111   152

  Columns 14 through 26

   166    29    78   137    74   111   166   156    70    58   125    48   175

  Columns 27 through 30

    59    90   181   118

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.0912


Accuracy =

   94.7351


Accuracy =

   94.5302


Accuracy =

   94.5086


Accuracy =

   94.1310


Accuracy =

   94.4978


Accuracy =

   94.3252


Accuracy =

   95.0049


Accuracy =

   94.9941


Accuracy =

   94.6165


Accuracy =9.461646e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   94.6512
   91.3449
   87.9070
   94.4954
   98.0303
   65.3846
  100.0000
   88.8889
   90.9194
   95.1758
   96.6355
   95.6757
   95.1177
   97.4212
   94.0476


AverageAccuracy =

   91.6655

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       28-      42  2.6467e+03  2.6954e+01  1.1125e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       29-      37  1.9204e+03  2.6920e+01  2.0735e-05

indexes =

  Columns 1 through 13

    95    97   176   138    90    23    91    57    29    42   110   122    11

  Columns 14 through 26

   147   123   187   191   123   109   136   173    52    96   111   153   192

  Columns 27 through 30

    39   200    80   149

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.7028


Accuracy =

   94.8538


Accuracy =

   94.4115


Accuracy =

   94.4331


Accuracy =

   94.4546


Accuracy =

   94.6273


Accuracy =

   94.6165


Accuracy =

   94.8538


Accuracy =

   94.8538


Accuracy =

   94.5302


Accuracy =9.453015e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   93.6434
   95.0601
   84.6512
   86.4989
   97.8916
   80.7692
  100.0000
   33.3333
   89.7727
   96.5331
   94.0187
   75.6757
   99.5622
   96.5616
   97.6190


AverageAccuracy =

   88.5518

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       38-      44  4.4508e+03  3.3844e+01  3.2511e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-07       20-      41  2.6439e+03  3.2185e+01  5.0030e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       18-      43  1.9181e+03  3.2521e+01  5.1528e-05

indexes =

  Columns 1 through 13

   101     6    16    38   194    11    45   160   121   118   196    80   128

  Columns 14 through 26

   145    10   168   186   177   107    18    78    88     7     6    19   170

  Columns 27 through 30

   195    86   127    41

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.2839


Accuracy =

   94.4888


Accuracy =

   94.3486


Accuracy =

   94.4888


Accuracy =

   94.4996


Accuracy =

   94.2299


Accuracy =

   94.6290


Accuracy =

   94.6506


Accuracy =

   94.5104


Accuracy =

   94.2731


Accuracy =9.427308e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   91.4153
   88.1175
   95.3271
   97.2540
   98.6343
   69.2308
   99.7685
   77.7778
   88.7115
   97.0721
   90.8922
   94.5946
   96.9432
   96.3173
   85.7143


AverageAccuracy =

   91.1404

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       24-      44  3.2110e+03  3.1211e+01  2.2808e-05
    1T -7.7e-06       24-      42  2.7210e+03  2.7439e+01  3.6312e-05
    1T -4.5e-06       40-      40  1.8055e+03  2.4438e+01  3.5326e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06        3-      43  2.0647e+03  2.6083e+01  3.7471e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06        3-      43  3.4253e+03  2.5468e+01  4.9851e-05

indexes =

  Columns 1 through 13

    89   127   177   145   147    88   200    99   155   147   117    42   198

  Columns 14 through 26

    19   133    53   115   111   166    88    76    11   103    82   193   192

  Columns 27 through 30

   188    48   106    12

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.3948


Accuracy =

   94.4056


Accuracy =

   94.6746


Accuracy =

   94.5777


Accuracy =

   94.5777


Accuracy =

   93.9322


Accuracy =

   93.4373


Accuracy =

   94.7714


Accuracy =

   94.3626


Accuracy =

   94.6746


Accuracy =9.467456e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   93.3591
   84.1965
   93.4884
   94.0774
   99.0937
   84.6154
   98.6175
   83.3333
   89.1800
   97.2560
   94.9627
   97.8723
   99.6522
   91.7379
   90.5882


AverageAccuracy =

   92.8055

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       15-      40  1.5871e+03  2.7386e+01  1.1569e-05
    1T  9.9e-06       10-      41  2.8428e+03  3.0227e+01  5.0717e-05
    1T  6.6e-06       24-      40  2.4379e+03  2.9787e+01  2.9894e-05

indexes =

  Columns 1 through 13

   163    78   155   137    60    14    71    17   194    27   172    74   174

  Columns 14 through 26

   119    20   108   188    81    60   175    62    71    64    33   173    20

  Columns 27 through 30

    11    51    69   155

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.6994


Accuracy =

   94.7641


Accuracy =

   94.8718


Accuracy =

   94.5809


Accuracy =

   94.7425


Accuracy =

   94.9795


Accuracy =

   94.7856


Accuracy =

   94.6886


Accuracy =

   94.7533


Accuracy =

   94.4409


Accuracy =9.444085e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   92.0340
   93.0759
   93.9535
   89.2449
   95.7831
  100.0000
   99.3088
   88.8889
   85.6492
   98.7404
   93.8547
   88.7701
   99.2133
   87.3926
   92.8571


AverageAccuracy =

   93.5241

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       21-      41  2.0351e+03  2.7879e+01  9.5692e-06
    1T  2.1e-07       25-      43  4.5633e+03  2.6522e+01  9.7583e-07

indexes =

  Columns 1 through 13

   178   196    84    92    48   112    14   157    65   127    59   132    20

  Columns 14 through 26

   190   114    18   187   145   180    55   149    79   143     1   104    32

  Columns 27 through 30

   110   149    62    90

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4580


Accuracy =

   95.3069


Accuracy =

   95.8572


Accuracy =

   95.1020


Accuracy =

   95.3501


Accuracy =

   95.4688


Accuracy =

   95.4256


Accuracy =

   95.5767


Accuracy =

   95.1127


Accuracy =

   95.3285


Accuracy =9.532851e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   93.4985
   90.7754
   85.1163
   92.9062
   97.2644
   46.1538
   97.4596
   77.7778
   87.5283
   99.3694
   95.3184
  100.0000
   99.0368
   98.8604
   94.1176


AverageAccuracy =

   90.8001

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   184   156    26    14    66   171   170    15    58    30    52   148    36

  Columns 14 through 26

    42   184    40   166   124    18    26    56   160   108   189    44   148

  Columns 27 through 30

    64    70   109   147

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.6892


Accuracy =

   95.1847


Accuracy =

   95.2602


Accuracy =

   95.0663


Accuracy =

   95.2709


Accuracy =

   95.0124


Accuracy =

   94.7754


Accuracy =

   95.5941


Accuracy =

   95.0447


Accuracy =

   95.2278


Accuracy =9.522784e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   90.5646
   96.6622
   85.6481
   92.5170
   96.6667
  100.0000
  100.0000
  100.0000
   90.6499
   97.7467
   89.9814
   99.4652
   99.4769
   97.7208
   92.8571


AverageAccuracy =

   95.1759

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.05*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [100x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       27-      42  1.7976e+03  3.0180e+01  3.5085e-06
    1T -7.4e-06       42-      38  1.2636e+03  2.8914e+01  6.8485e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       36-      42  1.9950e+03  2.7995e+01  5.9330e-05
    1T  8.3e-06       31-      44  3.1670e+03  3.0848e+01  3.6897e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       30-      40  1.8592e+03  2.6023e+01  4.5495e-05
    1T -5.1e-06       42-      43  2.2656e+03  2.6918e+01  3.6427e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06        7-      41  1.8149e+03  2.8541e+01  2.1421e-04

indexes =

  Columns 1 through 13

   157   198    46    93     5    26    40   181   167    59   146    40   186

  Columns 14 through 26

    99    57   151    49   167   180     3   142    56   186   101   152   100

  Columns 27 through 30

   184   146   101    78

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.6575


Accuracy =

   91.7145


Accuracy =

   90.9454


Accuracy =

   91.7453


Accuracy =

   91.4992


Accuracy =

   91.4992


Accuracy =

   73.5131


Accuracy =

   91.9299


Accuracy =

   91.6530


Accuracy =

   90.8224


Accuracy =9.082240e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   34.0909
   86.8189
   81.7490
   79.2035
   93.6957
   97.6978
         0
   98.6813
   47.3684
   87.2432
   93.1448
   90.2655
   96.4103
   96.0133
   97.0027
   89.8876


AverageAccuracy =

   79.3296

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       39-      40  2.0520e+03  2.9892e+01  4.8906e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       29-      40  1.8552e+03  3.3009e+01  2.8334e-05

indexes =

  Columns 1 through 13

    35   113   153   134   162   200    57   101    66   117   177   114    20

  Columns 14 through 26

    67    65   119    84   159   109   181    62    65   160   174   180    49

  Columns 27 through 30

    70   173   128    86

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.9887


Accuracy =

   95.3012


Accuracy =

   95.1396


Accuracy =

   94.9887


Accuracy =

   95.3012


Accuracy =

   95.1827


Accuracy =

   94.8378


Accuracy =

   95.3120


Accuracy =

   95.1072


Accuracy =

   95.0102


Accuracy =9.501024e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   94.8877
   93.8748
   89.3023
   93.8356
   98.9394
  100.0000
  100.0000
  100.0000
   87.3720
   96.9369
   91.2963
   92.4731
   99.3019
   90.2299
   91.7647


AverageAccuracy =

   94.2694

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       19-      43  1.1720e+03  3.6371e+01  3.7299e-05
    1T -8.1e-06       19-      39  2.1275e+03  3.0206e+01  4.5764e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       28-      39  1.5826e+03  2.8770e+01  3.2655e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-07       44-      40  1.4936e+03  2.8769e+01  3.3581e-06
    1T -9.9e-06       22-      40  1.5450e+03  2.4796e+01  1.0150e-04

indexes =

  Columns 1 through 13

   135     9    40    31   199   102   197    32    22    71    99     2   171

  Columns 14 through 26

    94    46   178   100    31    78     8    76   148    68    37    30    90

  Columns 27 through 30

   102     2    12   183

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.1159


Accuracy =

   95.2345


Accuracy =

   94.3720


Accuracy =

   95.1482


Accuracy =

   94.6523


Accuracy =

   95.0081


Accuracy =

   94.5984


Accuracy =

   95.0728


Accuracy =

   94.9218


Accuracy =

   94.9326


Accuracy =9.493261e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   96.5944
   94.2667
   94.4444
   93.8073
   95.9091
  100.0000
   93.2870
   83.3333
   85.1136
   95.6737
   97.0205
   95.7219
   99.0385
   96.5909
   90.4762


AverageAccuracy =

   94.0084

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       12-      40  1.7333e+03  2.6712e+01  2.5154e-03
    1T -1.5e-06       20-      36  1.3788e+03  2.9189e+01  1.7498e-05

indexes =

  Columns 1 through 13

   144    25   194     4    60   156    17    31   111    46    13    54    43

  Columns 14 through 26

    65   120   106   138    92   158    22   152   194   109    30   139   172

  Columns 27 through 30

   170   135    56   141

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.4750


Accuracy =

   94.3457


Accuracy =

   94.4750


Accuracy =

   94.5073


Accuracy =

   94.0657


Accuracy =

   93.9365


Accuracy =

   94.7550


Accuracy =

   94.1734


Accuracy =

   94.3242


Accuracy =

   94.4750


Accuracy =9.447496e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   95.3775
   85.2394
   90.2326
   95.2055
   99.0923
   84.6154
   99.0741
   88.8889
   86.8032
   96.4029
   98.5075
   79.4595
   98.4266
   96.2963
   92.8571


AverageAccuracy =

   92.1609

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       25-      44  2.2791e+03  3.5670e+01  3.0449e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       11-      39  1.2356e+03  2.3176e+01  2.0053e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       21-      39  1.2471e+03  2.4033e+01  3.0414e-05
    1T  7.9e-06       45-      44  1.0978e+03  3.4833e+01  3.6923e-05
    1T -6.3e-06       25-      42  1.5612e+03  2.3172e+01  5.6245e-05

indexes =

  Columns 1 through 13

    19   149    55    79    88    76   126   163     1   186    81   130   129

  Columns 14 through 26

   128    58   163    92    90   160   190    79   185   168    80   153   150

  Columns 27 through 30

   173   130    35   105

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.5588


Accuracy =

   93.3972


Accuracy =

   93.5911


Accuracy =

   93.6881


Accuracy =

   92.9879


Accuracy =

   93.4080


Accuracy =

   93.2572


Accuracy =

   93.6881


Accuracy =

   93.6558


Accuracy =

   93.0956


Accuracy =9.309565e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   82.5213
   86.7550
   87.9070
   91.5332
   97.2686
  100.0000
   98.6111
  100.0000
   86.4773
   98.2914
   93.8662
   93.0108
   99.5626
   98.8636
   88.0952


AverageAccuracy =

   93.0298

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       12-      33  1.0204e+03  3.0123e+01  8.1473e-03
    1T -8.7e-06       35-      42  1.1364e+03  3.8955e+01  7.1679e-05

indexes =

  Columns 1 through 13

   168    72   192    16   149    32    92   104    97   195    78    41   108

  Columns 14 through 26

   162    16    50    24    90   150    19   101    11   181    16     2    47

  Columns 27 through 30

    12   157   126   126

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.6994


Accuracy =

   94.1392


Accuracy =

   94.6456


Accuracy =

   94.1500


Accuracy =

   94.1284


Accuracy =

   94.4839


Accuracy =

   94.1176


Accuracy =

   94.2793


Accuracy =

   94.4624


Accuracy =

   94.6779


Accuracy =9.467787e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   44.1860
   92.6754
   96.5287
   87.8505
   93.3638
   98.1818
  100.0000
   99.5392
   88.8889
   87.7412
   96.2230
   95.1493
   99.4624
   99.3881
   89.0805
   83.5294


AverageAccuracy =

   90.7368

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       20-      36  1.2377e+03  2.3581e+01  4.2807e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.5e-06        6-      40  1.6079e+03  2.9200e+01  1.3115e-05

indexes =

  Columns 1 through 13

   174   142   148    16   140    80    45   177    11   195   178    61    40

  Columns 14 through 26

    20   195   169   182    73   169    10   129    99    13   200    68   160

  Columns 27 through 30

     7   141   166    27

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.5445


Accuracy =

   94.6307


Accuracy =

   94.7925


Accuracy =

   94.6523


Accuracy =

   94.8032


Accuracy =

   94.7385


Accuracy =

   94.8140


Accuracy =

   94.5229


Accuracy =

   94.6954


Accuracy =

   94.6631


Accuracy =9.466307e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   35.7143
   92.9403
   92.2667
   97.2222
   90.0000
   98.7897
  100.0000
   99.5402
   94.4444
   85.5682
   97.5203
   96.0821
   89.7849
   98.4279
   97.1347
   90.4762


AverageAccuracy =

   90.9945

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.3e-06       10-      40  1.4126e+03  2.5953e+01  1.6789e-05

indexes =

  Columns 1 through 13

    89    73   120    73   116    65   145   148   175   152   144   141   179

  Columns 14 through 26

   139    69    55    71     2    71    64    77   160   167    48    39    70

  Columns 27 through 30

    19   189   173   186

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.0917


Accuracy =

   94.8220


Accuracy =

   95.1996


Accuracy =

   95.6095


Accuracy =

   95.2535


Accuracy =

   95.2211


Accuracy =

   95.1456


Accuracy =

   95.2211


Accuracy =

   95.0162


Accuracy =

   95.0701


Accuracy =9.507012e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   59.5238
   92.6471
   93.6085
   97.6636
   96.8109
   97.5721
   96.1538
  100.0000
   94.4444
   91.0023
   97.8369
   89.9628
   95.1351
   97.4628
   90.2299
   91.6667


AverageAccuracy =

   92.6075

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06        8-      40  1.5276e+03  2.5391e+01  4.8755e-05
    1T  1.6e-06       43-      35  8.4506e+02  2.7199e+01  1.1817e-05
    1T  7.2e-06       20-      37  1.6745e+03  2.2132e+01  5.4123e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       33-      42  1.9048e+03  2.7893e+01  6.0128e-05
    1T  2.9e-06       43-      41  1.7114e+03  2.7627e+01  1.6720e-05

indexes =

  Columns 1 through 13

   146    73    48   106    40    26    16   139   131    83   172   191    19

  Columns 14 through 26

   189   181   107   138   111   129    84   102   136   158    15    49    38

  Columns 27 through 30

    92   191   141   169

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.3445


Accuracy =

   94.5276


Accuracy =

   94.1075


Accuracy =

   94.2368


Accuracy =

   94.0860


Accuracy =

   94.5599


Accuracy =

   94.2691


Accuracy =

   94.3876


Accuracy =

   94.3553


Accuracy =

   94.3984


Accuracy =9.439836e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   66.6667
   93.8176
   90.0266
   82.7103
   94.5205
   97.7341
  100.0000
  100.0000
   88.8889
   88.4835
   98.5644
   89.7004
   96.2366
   94.5757
   97.4432
   91.6667


AverageAccuracy =

   91.9397

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06        6-      42  1.4115e+03  2.4170e+01  1.7022e-05
    1T  4.9e-06       22-      44  3.0282e+03  3.3746e+01  3.1128e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       32-      35  1.1056e+03  2.4959e+01  3.8269e-05
    1T  6.1e-06       19-      39  1.2500e+03  2.5224e+01  3.7715e-05

indexes =

  Columns 1 through 13

   153   147   110    11   105   105   157   113   150    20   124    66    77

  Columns 14 through 26

    37   132   193   187    36    36   122   195   129    16    78    26     5

  Columns 27 through 30

    40   181    73   139

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.8265


Accuracy =

   94.6001


Accuracy =

   94.4061


Accuracy =

   94.7079


Accuracy =

   94.5894


Accuracy =

   94.9019


Accuracy =

   94.6109


Accuracy =

   94.7618


Accuracy =

   94.5786


Accuracy =

   94.6864


Accuracy =9.468635e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   65.1163
   93.9722
   97.2112
   91.1628
   97.9358
   97.5758
   80.7692
  100.0000
   66.6667
   84.0547
   96.2528
   94.2379
   89.8396
   97.4717
   95.4286
   92.8571


AverageAccuracy =

   90.0345

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [64x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       35-      41  1.0770e+03  2.9644e+01  4.0630e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       35-      41  1.0770e+03  2.9644e+01  4.0630e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       35-      41  1.0770e+03  2.9644e+01  4.0630e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       35-      41  1.0770e+03  2.9644e+01  4.0630e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       18-      41  1.7555e+03  2.7308e+01  5.4526e-05
    1T  4.6e-06       35-      37  1.2686e+03  2.6611e+01  4.0294e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       35-      42  2.1416e+03  2.7871e+01  8.5124e-05

indexes =

  Columns 1 through 13

   114    78    84    92    49   194   181   188    37    97    76   155    82

  Columns 14 through 26

    52    73   114    36     8   197   187    64   178   149   137   180    21

  Columns 27 through 30

    54   161     7    42

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.1043


Accuracy =

   94.2660


Accuracy =

   93.8349


Accuracy =

   93.5439


Accuracy =

   94.1798


Accuracy =

   93.8025


Accuracy =

   93.7271


Accuracy =

   93.9211


Accuracy =

   94.1474


Accuracy =

   93.5870


Accuracy =9.358698e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   59.5238
   93.2767
   83.1776
   93.4579
   99.0868
   94.2337
  100.0000
  100.0000
  100.0000
   91.1364
   96.3563
   93.1099
   91.3978
   95.3712
   89.4286
   91.7647


AverageAccuracy =

   91.9576

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       15-      42  1.7873e+03  2.9161e+01  3.2834e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-06        7-      34  7.0870e+02  2.7259e+01  2.4563e-05
    1T  5.0e-06       31-      42  1.2995e+03  3.5584e+01  2.5245e-05
    1T  9.2e-06       13-      42  8.8616e+02  2.9049e+01  5.1244e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-07        6-      37  1.1865e+03  2.3966e+01  5.1109e-06

indexes =

  Columns 1 through 13

     6   167   195    30   192    70   147   168   147    21   164   170    39

  Columns 14 through 26

    18   170   172   192    61    65   140   183    55   140   186   148   114

  Columns 27 through 30

   118    93   103    16

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.2178


Accuracy =

   93.2824


Accuracy =

   92.3243


Accuracy =

   93.0348


Accuracy =

   92.4965


Accuracy =

   93.4331


Accuracy =

   92.7441


Accuracy =

   93.3147


Accuracy =

   93.2824


Accuracy =

   92.4427


Accuracy =9.244267e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   76.1905
   88.0216
   83.3333
   85.5814
   93.3941
   97.4242
   96.1538
   99.3039
  100.0000
   89.7843
   93.9856
   92.1788
   93.5829
   97.9021
   94.9008
   86.9048


AverageAccuracy =

   91.7901

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06        4-      37  9.6891e+02  3.2878e+01  6.7820e-05
    1T  9.8e-06        1-      42  2.3930e+03  3.3798e+01  6.7637e-05
    1T  2.7e-06        8-      40  1.1094e+03  3.9509e+01  1.9817e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-07       25-      39  7.3718e+02  2.7302e+01  2.0570e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       33-      40  7.7988e+02  3.2212e+01  3.3885e-05

indexes =

  Columns 1 through 13

   177    22    82   139    77    45    49    44   130    67    87    18    27

  Columns 14 through 26

     7     6   123   151   126   188    44   129   101   112   199   185   113

  Columns 27 through 30

    86   161   134    64

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.6813


Accuracy =

   94.2743


Accuracy =

   94.1665


Accuracy =

   94.4792


Accuracy =

   93.8430


Accuracy =

   93.9724


Accuracy =

   94.3067


Accuracy =

   94.4361


Accuracy =

   93.8861


Accuracy =

   93.8107


Accuracy =9.381065e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   66.6667
   94.1222
   92.1333
   84.5794
   97.7169
   98.1818
  100.0000
   95.8333
  100.0000
   87.3864
   94.4570
   90.7063
   89.3048
   99.5629
   91.1175
   85.7143


AverageAccuracy =

   91.7177

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       38-      41  1.1230e+03  3.0991e+01  8.2242e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        9-      40  9.6107e+02  2.9970e+01  1.0983e-05
    1T  5.3e-06       22-      42  1.4906e+03  3.2298e+01  1.4375e-05
    1T  7.9e-06        4-      38  8.4270e+02  2.8163e+01  2.2959e-03

indexes =

  Columns 1 through 13

   100    80    69    45    69    79   186   110   171    17    81    23    12

  Columns 14 through 26

   131    66    14   106   100    51    52    22   192   121     9   106    62

  Columns 27 through 30

   107   125    40   183

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.6563


Accuracy =

   94.3116


Accuracy =

   94.8287


Accuracy =

   94.0746


Accuracy =

   94.5809


Accuracy =

   94.2685


Accuracy =

   94.5486


Accuracy =

   94.7102


Accuracy =

   94.2362


Accuracy =

   94.3870


Accuracy =9.438699e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   94.7409
   92.9333
   94.3925
   95.4338
  100.0000
   96.1538
   97.2222
   38.8889
   90.9091
   91.3219
   91.9776
   96.2162
   98.6063
   99.4269
   97.6471


AverageAccuracy =

   92.0931

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

    45   118   160    44   142    31    30   166   172   181    65    70   103

  Columns 14 through 26

     4    72    85   155    76    45    54   168   191    78    31    14   118

  Columns 27 through 30

    16    14   189   147

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.6968


Accuracy =

   94.4187


Accuracy =

   94.3972


Accuracy =

   94.5480


Accuracy =

   93.9446


Accuracy =

   94.5480


Accuracy =

   94.1278


Accuracy =

   94.3864


Accuracy =

   94.6342


Accuracy =

   94.8605


Accuracy =9.486047e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   94.1085
   92.5433
   98.6047
   92.2197
   98.4917
  100.0000
   96.5438
   94.4444
   91.6290
   94.6396
   92.7239
   98.9247
   98.0786
   95.7020
   94.1176


AverageAccuracy =

   94.9054

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       41-      39  1.0554e+03  2.9264e+01  5.5469e-05
    1T -5.0e-06       41-      34  8.1450e+02  2.6383e+01  3.5605e-05

indexes =

  Columns 1 through 13

   184    14    26    95    19   120    47   182   178    52    61    75    21

  Columns 14 through 26

    45    75    72   111   144    33   134   147   163    35   160    29    29

  Columns 27 through 30

    74    66   148   137

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.0614


Accuracy =

   93.0506


Accuracy =

   92.9859


Accuracy =

   92.9535


Accuracy =

   92.6513


Accuracy =

   92.9211


Accuracy =

   93.4930


Accuracy =

   93.1154


Accuracy =

   93.2341


Accuracy =

   93.4283


Accuracy =9.342829e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   90.3176
   88.6515
   81.3953
   91.7431
   99.6992
   92.3077
   97.9215
   55.5556
   86.3481
   95.4443
   92.3221
   96.2366
   98.5127
   98.2808
   88.0952


AverageAccuracy =

   90.8020

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       39-      34  7.2580e+02  2.6965e+01  2.5296e-05
    1T -7.5e-06       21-      41  1.1247e+03  2.9228e+01  6.6220e-05
    1T  4.8e-06       27-      40  1.2853e+03  2.7474e+01  1.0660e-04

indexes =

  Columns 1 through 13

    28   195     9    80   194    96    35    42   142    47   170   170    75

  Columns 14 through 26

    55   144    81   149    85     9    62   168   148    95   162    72   185

  Columns 27 through 30

   168    93    35   104

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.3541


Accuracy =

   93.0853


Accuracy =

   92.8272


Accuracy =

   93.2788


Accuracy =

   93.3326


Accuracy =

   93.4402


Accuracy =

   93.5692


Accuracy =

   93.9778


Accuracy =

   93.0638


Accuracy =

   93.5477


Accuracy =9.354769e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   52.3810
   93.1274
   86.4542
   92.1659
   89.7025
   98.4871
  100.0000
   97.4596
   77.7778
   87.5847
   95.9009
   92.0370
   98.3784
   99.3918
   88.0342
   92.8571


AverageAccuracy =

   90.1087

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       32-      29  1.0122e+03  3.3946e+01  2.8501e-05
    1T -1.2e-07       45-      36  8.2205e+02  3.2005e+01  5.4307e-07

indexes =

  Columns 1 through 13

   119    41    30   122   157    22   149    11   199   134   133   127    97

  Columns 14 through 26

   149     2    36   190    23   110   155    53    39    92    87   146   132

  Columns 27 through 30

   116    74    44   164

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.3325


Accuracy =

   94.3648


Accuracy =

   94.1278


Accuracy =

   94.2571


Accuracy =

   94.4510


Accuracy =

   93.7614


Accuracy =

   94.3433


Accuracy =

   94.2032


Accuracy =

   94.0200


Accuracy =

   94.2679


Accuracy =9.426786e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   64.2857
   94.5778
   93.3599
   86.9767
   95.8621
   96.9880
   92.3077
   99.5381
   55.5556
   88.3959
   94.1494
   94.5794
   88.7097
   97.9930
   96.2963
   98.8235


AverageAccuracy =

   89.8999

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       24-      37  1.0473e+03  2.8058e+01  2.3252e-05
    1T  8.2e-06       24-      41  1.4075e+03  2.7174e+01  7.4765e-04
    1T  8.2e-06       24-      41  1.4075e+03  2.7174e+01  7.4765e-04
    1T  8.2e-06       24-      41  1.4075e+03  2.7174e+01  7.4765e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       24-      41  1.4075e+03  2.7174e+01  7.4765e-04
    1T  8.2e-06       24-      41  1.4075e+03  2.7174e+01  7.4765e-04
    1T  8.2e-06       24-      41  1.4075e+03  2.7174e+01  7.4765e-04

indexes =

  Columns 1 through 13

    53     3     8    61    58    56   127   177   149   126    88   101   168

  Columns 14 through 26

   130    90    72   145    54   105   157    75    66    94    36   139    89

  Columns 27 through 30

   188   132    49     1

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   92.5870


Accuracy =

   92.1668


Accuracy =

   92.6086


Accuracy =

   91.9405


Accuracy =

   92.5978


Accuracy =

   92.1021


Accuracy =

   92.3823


Accuracy =

   92.6517


Accuracy =

   92.8025


Accuracy =

   92.8779


Accuracy =9.287792e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   28.5714
   89.9303
   84.6871
   97.1963
   93.3638
   98.4871
   88.4615
   97.2414
   77.7778
   85.6981
   96.6292
   91.0448
   88.1081
   97.2052
   95.7143
   95.2381


AverageAccuracy =

   87.8347

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06        6-      40  1.4167e+03  2.8989e+01  1.0469e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-07       31-      41  7.6945e+02  3.7811e+01  2.2464e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       24-      37  9.5994e+02  3.4774e+01  1.3100e-05
    1T -1.8e-06       43-      37  1.1637e+03  3.1381e+01  3.3251e-06

indexes =

  Columns 1 through 13

    57   176   121   196   159    70   114    40   199    30   124    13   116

  Columns 14 through 26

    57     3    55    90   136   134   200   171   173    37    29   109   137

  Columns 27 through 30

   170   167   113   124

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.8516


Accuracy =

   93.8516


Accuracy =

   94.0454


Accuracy =

   93.7762


Accuracy =

   93.5501


Accuracy =

   94.1531


Accuracy =

   93.9916


Accuracy =

   94.0347


Accuracy =

   94.1531


Accuracy =

   93.9378


Accuracy =9.393776e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   93.6680
   86.0000
   86.4486
   97.9452
   98.1928
   96.1538
   97.9215
   88.8889
   88.6364
   96.8525
   88.9925
   97.2973
   99.9130
   82.5215
   84.5238


AverageAccuracy =

   92.0032

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=6:6:6
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [36x45]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       13-      35  2.0638e+03  3.0567e+01  3.6870e-05
    1T  6.8e-06       44-      40  1.0721e+03  3.9134e+01  2.1459e-05
    1T  8.8e-06       26-      35  6.6176e+02  3.5502e+01  5.4051e-04

indexes =

  Columns 1 through 13

   149    53   108   163    99   103    71   120    45   166   153   133    98

  Columns 14 through 26

   153   170    51   165    39     7   140     3   186    71   109   136   142

  Columns 27 through 30

    27   197    32    56

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.0583


Accuracy =

   95.4683


Accuracy =

   95.1554


Accuracy =

   95.5546


Accuracy =

   95.4035


Accuracy =

   95.4899


Accuracy =

   95.3172


Accuracy =

   95.5762


Accuracy =

   94.9396


Accuracy =

   94.8748


Accuracy =9.487484e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   66.6667
   96.3481
   90.7877
   69.5853
   96.7890
   97.5684
   57.6923
   98.6207
   61.1111
   92.0273
   95.5896
   94.9438
   98.3784
   98.6945
   97.9885
   94.0476


AverageAccuracy =

   87.9274

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.505206s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       20-      42  3.6208e+03  3.2908e+01  2.3635e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       31-      39  3.4803e+03  2.9404e+01  2.7937e-05
    1T  4.2e-06       31-      42  3.5405e+03  2.7402e+01  2.6412e-05

indexes =

  Columns 1 through 13

   139    26     8   193    87    64    49     2   138   173    12   165   175

  Columns 14 through 26

    95    11    88    41    94    73   138   172    73   139     1    94   200

  Columns 27 through 30

    91   119   165    83

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.1826


Accuracy =

   93.5918


Accuracy =

   93.9041


Accuracy =

   93.6780


Accuracy =

   93.5057


Accuracy =

   93.4518


Accuracy =

   93.5703


Accuracy =

   93.6564


Accuracy =

   93.8503


Accuracy =

   93.8072


Accuracy =9.380722e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   88.3217
   85.6383
   94.4700
   94.2922
   96.8085
   53.8462
   97.4596
   66.6667
   90.1249
   97.7037
   90.3346
  100.0000
   99.4769
   93.4286
   89.2857


AverageAccuracy =

   89.7173

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.498398s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       32-      44  4.8728e+03  3.2445e+01  8.2465e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       29-      43  2.9762e+03  3.0398e+01  2.7476e-05

indexes =

  Columns 1 through 13

    47   141   145    65   133   183    30   189    57   126   192    85   148

  Columns 14 through 26

    60    97     6    16     4   125   116   176    67   137   148   195   200

  Columns 27 through 30

    35    34    86    32

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.4066


Accuracy =

   93.8914


Accuracy =

   93.6328


Accuracy =

   93.6436


Accuracy =

   93.6436


Accuracy =

   93.9991


Accuracy =

   93.2881


Accuracy =

   93.4281


Accuracy =

   93.4605


Accuracy =

   93.0618


Accuracy =9.306184e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   92.5154
   82.2193
   93.9535
   96.5675
   94.4109
  100.0000
  100.0000
   72.2222
   85.1305
   96.7494
   84.0149
   90.3226
   98.9565
   99.7135
   77.6471


AverageAccuracy =

   90.7824

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.501236s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       27-      44  3.4586e+03  2.7474e+01  2.4643e-05

indexes =

  Columns 1 through 13

    12    13    65   162   113     2    61    82    39   196    42    14   197

  Columns 14 through 26

   161   102   102    72   183    88   141    48    89    23    95   120   154

  Columns 27 through 30

   103   162   102    53

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.0425


Accuracy =

   93.0749


Accuracy =

   93.2795


Accuracy =

   93.4410


Accuracy =

   93.0964


Accuracy =

   93.0964


Accuracy =

   93.0533


Accuracy =

   93.2795


Accuracy =

   93.1718


Accuracy =

   93.0533


Accuracy =9.305331e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   89.3189
   85.9043
   80.8411
   95.8998
   93.9394
  100.0000
   99.0719
   50.0000
   87.4007
   97.3944
   85.6877
   90.8108
   99.3908
   95.6897
   95.2381


AverageAccuracy =

   90.4117

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.502683s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       12-      39  3.2302e+03  2.8226e+01  3.2477e-05
    1T -3.5e-06       20-      41  2.4982e+03  2.5511e+01  2.1175e-05
    1T  9.4e-06       12-      39  2.9168e+03  2.6590e+01  4.9821e-04

indexes =

  Columns 1 through 13

    14    29   189   199    61   188    15   100   113    70    82   190   130

  Columns 14 through 26

   105   130    42   107    37   138   171   134   171   143   168   195    52

  Columns 27 through 30

   121   162    10   189

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.0106


Accuracy =

   94.5276


Accuracy =

   93.8597


Accuracy =

   93.9459


Accuracy =

   94.1183


Accuracy =

   94.0321


Accuracy =

   94.3230


Accuracy =

   93.9244


Accuracy =

   93.8813


Accuracy =

   94.2475


Accuracy =9.424755e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   95.2087
   84.4000
   85.5140
   92.6606
   97.1212
   34.6154
  100.0000
   47.3684
   91.6100
   96.4478
   93.8318
   98.3957
   98.0769
   94.3343
   86.9048


AverageAccuracy =

   86.6854

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.557714s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       13-      44  3.0893e+03  2.7852e+01  2.0508e-05

indexes =

  Columns 1 through 13

    27   107   176     1    48    20   109   153   162    61    11    13    32

  Columns 14 through 26

   140   185    38   166    79    35   164   158    21   125   120   193   137

  Columns 27 through 30

   154    63   175     8

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   92.8009


Accuracy =

   93.4260


Accuracy =

   92.9626


Accuracy =

   93.0704


Accuracy =

   93.3829


Accuracy =

   93.1350


Accuracy =

   92.8117


Accuracy =

   93.5122


Accuracy =

   93.2967


Accuracy =

   93.1997


Accuracy =9.319970e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   90.8810
   90.2926
   92.0930
   96.7816
   97.2769
         0
   98.6143
   44.4444
   82.5397
   96.7087
   89.5717
   94.0541
   98.3435
   97.4286
   75.0000


AverageAccuracy =

   83.1090

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.572787s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       21-      42  2.9538e+03  2.4534e+01  1.2471e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       32-      42  2.7173e+03  2.6451e+01  1.9693e-05

indexes =

  Columns 1 through 13

    83    24   109    69   109    26   135    15     8    48   183    50   140

  Columns 14 through 26

   149    52   124     8    10   124   141    41    52   119    33   145   182

  Columns 27 through 30

    33     1    47   102

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.1109


Accuracy =

   92.4865


Accuracy =

   93.1970


Accuracy =

   93.4230


Accuracy =

   93.2078


Accuracy =

   93.4984


Accuracy =

   93.4230


Accuracy =

   92.9925


Accuracy =

   93.1432


Accuracy =

   93.3800


Accuracy =9.337998e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   81.3953
   92.2481
   86.3214
   88.7850
   89.6789
   95.7831
  100.0000
  100.0000
   52.6316
   84.9658
   97.6650
   94.4341
   85.4839
   98.7784
   95.4416
   67.8571


AverageAccuracy =

   88.2168

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.523737s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06
    1T  1.0e-06        1-      41  3.5739e+03  2.6943e+01  6.4138e-06

indexes =

  Columns 1 through 13

     2   121   109   100   175   120   142    18    15    71    37   195   132

  Columns 14 through 26

    54    21    56    98    61    71     2     7   114   145   165   136    44

  Columns 27 through 30

   122   128   169   109

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.0410


Accuracy =

   93.0949


Accuracy =

   92.6748


Accuracy =

   92.9980


Accuracy =

   93.2457


Accuracy =

   92.7179


Accuracy =

   93.3750


Accuracy =

   92.9872


Accuracy =

   92.2870


Accuracy =

   93.0303


Accuracy =9.303027e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   89.2664
   90.5207
   86.0465
   94.4954
   97.4281
   30.7692
   99.0805
   55.5556
   78.0931
   97.7498
   90.6542
  100.0000
   99.5648
   92.8367
   89.2857


AverageAccuracy =

   86.3639

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.53513s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       22-      44  3.6959e+03  2.6843e+01  1.7960e-05

indexes =

  Columns 1 through 13

    60   172     3   190    16   167   167   166   137    21   179   154    20

  Columns 14 through 26

   144    37    91   135   151    83    84    13    54   135    58   147   136

  Columns 27 through 30

    57   129    88   148

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   93.4253


Accuracy =

   92.9834


Accuracy =

   92.6277


Accuracy =

   93.3175


Accuracy =

   92.4337


Accuracy =

   92.8110


Accuracy =

   93.1774


Accuracy =

   92.8110


Accuracy =

   93.3499


Accuracy =

   92.9726


Accuracy =9.297262e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   90.7895
   94.5406
   92.9907
   94.3439
   97.2686
         0
   93.7644
   66.6667
   81.5700
   96.6682
   85.4478
   99.4624
   98.1675
   97.4212
   71.4286


AverageAccuracy =

   84.1403

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.55978s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       33-      43  4.3957e+03  2.9535e+01  2.3010e-05
    1T  4.2e-06       43-      44  5.0456e+03  2.8597e+01  8.6184e-06
    1T  6.6e-07       43-      42  3.8949e+03  2.8919e+01  7.5915e-06

indexes =

  Columns 1 through 13

   185    38    68    74    95   194    38   185    98   137   200   119    81

  Columns 14 through 26

   111    11   145   169   140    60   186   104    54    46   127    63    17

  Columns 27 through 30

    93    85    31   145

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   92.8040


Accuracy =

   92.7716


Accuracy =

   92.6745


Accuracy =

   92.7932


Accuracy =

   92.5019


Accuracy =

   92.3508


Accuracy =

   92.8795


Accuracy =

   92.7500


Accuracy =

   92.6421


Accuracy =

   92.4587


Accuracy =9.245873e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   92.0093
   87.2170
   72.0930
   93.3333
   95.7511
   65.3846
   93.7500
   27.7778
   81.9318
   97.2547
   85.9813
   95.1351
   98.8636
   96.3068
   97.6190


AverageAccuracy =

   85.9779

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=14:14:14
    R=45;
components=45;
trainingNum=45  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x45]             
B                    [1999x45]            
C                    [196x45]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.511322s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       26-      41  2.9262e+03  2.6953e+01  7.5054e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       18-      40  2.7211e+03  2.7961e+01  8.0689e-05

indexes =

  Columns 1 through 13

    86    18   164    70    34    23   134   127   188    23    35    30    86

  Columns 14 through 26

   184    78   167   190   159    63   179    81    65    52    36   141    20

  Columns 27 through 30

   123    98   166   176

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   92.7357


Accuracy =

   92.4882


Accuracy =

   92.1868


Accuracy =

   91.8102


Accuracy =

   92.4236


Accuracy =

   92.6065


Accuracy =

   92.5743


Accuracy =

   92.4021


Accuracy =

   92.3590


Accuracy =

   92.4344


Accuracy =9.243435e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   87.8764
   89.4947
   70.0935
   95.4338
   97.7307
    7.4074
   99.7691
   83.3333
   81.3636
   97.1275
   91.8367
   99.4624
   97.7293
   96.8571
   66.6667


AverageAccuracy =

   84.9876

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       16-      52  1.6437e+03  3.8184e+01  1.6439e-05
    1T  9.7e-06       38-      47  1.5093e+03  3.1016e+01  2.5904e-05

indexes =

  Columns 1 through 13

    93    99   128   154   158   124   146    91    46   194    65    25    41

  Columns 14 through 26

    14    42   150    14   153    28    96    60    31   158   189     7   126

  Columns 27 through 30

    79    48    14   192

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.5780


Accuracy =

   94.8259


Accuracy =

   95.1601


Accuracy =

   94.6966


Accuracy =

   94.8798


Accuracy =

   94.5888


Accuracy =

   95.1816


Accuracy =

   94.8690


Accuracy =

   95.1277


Accuracy =

   95.0307


Accuracy =9.503072e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   96.8192
   90.8609
   89.7196
   96.7816
   97.1342
  100.0000
  100.0000
   83.3333
   86.9762
   98.3784
   85.8473
  100.0000
   97.8166
   92.5501
   90.5882


AverageAccuracy =

   93.1337

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       20-      53  2.3217e+03  3.9038e+01  6.8198e-05
    1T -5.9e-06       10-      52  2.5903e+03  4.3362e+01  7.3118e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-07       33-      47  1.3610e+03  3.3777e+01  1.3910e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       32-      52  2.3778e+03  4.1093e+01  6.1584e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-07       37-      50  1.9568e+03  3.5581e+01  2.7989e-06

indexes =

  Columns 1 through 13

   121    64    47    66   140    75   156   128   118    99     9    66     5

  Columns 14 through 26

   143   138   152   106   149    37    27    91    16   102   173    12   188

  Columns 27 through 30

   145    51   126    87

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4697


Accuracy =

   95.5884


Accuracy =

   95.9659


Accuracy =

   95.5668


Accuracy =

   95.5021


Accuracy =

   95.9012


Accuracy =

   95.3835


Accuracy =

   95.8257


Accuracy =

   95.8904


Accuracy =

   95.5992


Accuracy =9.559918e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   45.2381
   94.5736
   93.7417
   90.1869
   93.5927
   96.0606
  100.0000
  100.0000
   88.8889
   87.3720
   98.4256
   96.4684
   98.3784
   99.2112
   97.7143
   92.8571


AverageAccuracy =

   92.0443

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06        3-      48  1.3063e+03  3.4224e+01  2.3285e-05
    1T  8.2e-06       35-      51  2.1101e+03  4.2263e+01  1.3718e-05
    1T  3.4e-07       47-      48  1.6073e+03  3.2995e+01  1.8278e-06
    1T  6.5e-06       54-      49  1.5392e+03  4.0984e+01  1.8288e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       50-      45  1.3162e+03  3.4084e+01  3.0850e-05

indexes =

  Columns 1 through 13

   148   109     1   169    73    16    63   178    62     4   191   100    61

  Columns 14 through 26

   117    93   149    25   130   124    67    47    27   178   149   109    72

  Columns 27 through 30

   102   110   131    84

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.6409


Accuracy =

   96.0284


Accuracy =

   95.3180


Accuracy =

   95.4257


Accuracy =

   95.6625


Accuracy =

   95.4257


Accuracy =

   95.5764


Accuracy =

   96.0822


Accuracy =

   95.7593


Accuracy =

   96.0177


Accuracy =9.601765e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   97.0588
   97.0667
   92.5581
   95.6720
   99.0909
  100.0000
  100.0000
   94.4444
   92.5255
   96.0036
   94.0631
   96.2567
   97.6357
   95.1289
   72.9412


AverageAccuracy =

   93.9862

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       18-      46  1.1599e+03  2.8785e+01  3.4044e-05
    1T -6.0e-06       34-      53  2.4978e+03  3.6301e+01  2.0223e-05

indexes =

  Columns 1 through 13

    67    76   102   108    78   103    79   113    43   101   191    58   117

  Columns 14 through 26

   135    11   183    56   138    55   123    70    17    76   115    66    58

  Columns 27 through 30

   151    24    66    82

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.2766


Accuracy =

   95.2443


Accuracy =

   95.2443


Accuracy =

   95.2335


Accuracy =

   95.2119


Accuracy =

   95.5031


Accuracy =

   95.1796


Accuracy =

   95.2011


Accuracy =

   95.5031


Accuracy =

   95.6217


Accuracy =9.562170e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   93.2870
   94.5333
   87.4419
   90.8467
   95.9091
  100.0000
   99.3056
  100.0000
   94.8747
   97.7888
   92.7509
   94.6524
   98.1659
   96.8481
   97.6190


AverageAccuracy =

   95.2812

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       54-      51  1.4084e+03  3.4591e+01  5.2937e-03
    1T  5.5e-06       36-      53  2.5239e+03  3.2799e+01  2.3197e-05
    1T -8.7e-06       44-      50  1.5503e+03  2.8923e+01  9.9703e-05
    1T -5.3e-06       36-      51  1.2553e+03  3.0897e+01  2.2201e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       55-      49  1.6209e+03  2.7635e+01  8.9565e-05
    1T -6.7e-06       24-      47  1.3754e+03  2.9803e+01  5.1093e-05

indexes =

  Columns 1 through 13

   192   179   152   186    72    30   200   140   158   172    45   109   120

  Columns 14 through 26

    60    91   190   155    83    83    53    48   100   117   147     4   120

  Columns 27 through 30

   181    53    32   177

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.2432


Accuracy =

   94.6097


Accuracy =

   94.3402


Accuracy =

   94.3402


Accuracy =

   94.3834


Accuracy =

   94.2001


Accuracy =

   94.2432


Accuracy =

   93.4670


Accuracy =

   94.0060


Accuracy =

   93.9306


Accuracy =9.393057e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   61.9048
   93.6434
   91.6000
   94.0092
   94.0639
   95.9215
   84.6154
   99.3039
   88.8889
   82.3059
   97.0310
   91.7757
   95.6757
   96.5248
   96.2644
   98.8095


AverageAccuracy =

   91.3961

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06        8-      50  1.8437e+03  3.7239e+01  1.3128e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       40-      49  1.5731e+03  3.7294e+01  6.0779e-05
    1T -8.9e-06       28-      51  2.6139e+03  3.6865e+01  3.2752e-05
    1T -3.0e-06       33-      46  1.1118e+03  3.8300e+01  9.7940e-06

indexes =

  Columns 1 through 13

     9   139     2   180   174    39    34   132    69    40   178    22   199

  Columns 14 through 26

    73    48    48    58   112    36    55    54    11   167    15   166    99

  Columns 27 through 30

    75   149   120   149

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4550


Accuracy =

   96.0164


Accuracy =

   95.7789


Accuracy =

   95.8113


Accuracy =

   95.8329


Accuracy =

   95.8221


Accuracy =

   95.7897


Accuracy =

   95.4982


Accuracy =

   96.0380


Accuracy =

   95.6386


Accuracy =9.563856e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   30.9524
   95.7364
   94.6738
   99.0654
   93.6073
   96.8182
   96.1538
  100.0000
   83.3333
   89.6119
   97.2510
   97.5791
   85.4839
   99.2112
   95.4023
   90.4762


AverageAccuracy =

   90.3348

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       44-      44  1.3320e+03  3.5431e+01  4.7826e-05
    1T  5.5e-06       22-      49  2.0605e+03  3.7785e+01  2.5433e-05

indexes =

  Columns 1 through 13

   193    95    58    77   168   161    58   136   159    95    79    25    42

  Columns 14 through 26

   146    37   168    73   170   111   107    58   171    49   109   167   159

  Columns 27 through 30

    55   192    41    73

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.7229


Accuracy =

   95.7983


Accuracy =

   95.9168


Accuracy =

   95.3997


Accuracy =

   95.3997


Accuracy =

   95.5290


Accuracy =

   96.0784


Accuracy =

   95.7337


Accuracy =

   95.8414


Accuracy =

   95.2273


Accuracy =9.522732e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   91.3514
   95.4606
   81.8605
   95.8716
   96.9880
   84.6154
   95.8333
   77.7778
   90.8267
   97.1647
   97.3881
   91.3514
   99.8252
   97.4359
   92.8571


AverageAccuracy =

   92.4665

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06        6-      54  2.8998e+03  3.9037e+01  3.0889e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       31-      48  1.2188e+03  3.3416e+01  2.0867e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       15-      50  2.0575e+03  3.4902e+01  3.9712e-05
    1T -8.3e-06       48-      43  1.2969e+03  4.1500e+01  6.9553e-05

indexes =

  Columns 1 through 13

    13    65    63   152   118   131     7   175   185    67    42    97    70

  Columns 14 through 26

    38    78   105    10    39   108   190    69   177   150    15   132    66

  Columns 27 through 30

    82   174   180    21

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4193


Accuracy =

   95.4947


Accuracy =

   95.2360


Accuracy =

   95.1175


Accuracy =

   95.2253


Accuracy =

   95.4193


Accuracy =

   95.2468


Accuracy =

   95.3762


Accuracy =

   95.0959


Accuracy =

   95.0097


Accuracy =9.500970e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   96.1330
   92.1123
   80.9302
   88.3295
   98.3384
  100.0000
  100.0000
  100.0000
   87.7551
   98.6055
   89.9254
   98.3957
   98.5140
   92.2636
   92.8571


AverageAccuracy =

   93.8909

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       48-      46  1.4925e+03  3.4464e+01  1.6350e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       29-      46  1.6468e+03  3.6064e+01  1.2314e-05
    1T  3.0e-07       24-      42  1.5294e+03  3.5725e+01  1.7534e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       40-      54  4.4278e+03  3.8065e+01  3.1658e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       10-      42  1.3821e+03  4.1708e+01  4.7326e-06
    1T -4.9e-06       18-      41  9.2334e+02  3.2792e+01  2.7711e-05
    1T  1.3e-06        5-      44  1.5564e+03  3.3671e+01  6.3563e-06
    1T  8.7e-06       24-      45  1.1888e+03  3.2666e+01  6.3732e-04

indexes =

  Columns 1 through 13

   150    58   145   144   184    72   102   108   167   122    82   192   194

  Columns 14 through 26

   144   174    38   193   165    18   146   189   153   174   198    24   128

  Columns 27 through 30

   192    56   139    23

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.7005


Accuracy =

   96.6897


Accuracy =

   96.2368


Accuracy =

   96.6034


Accuracy =

   96.4632


Accuracy =

   96.6789


Accuracy =

   96.4524


Accuracy =

   96.1721


Accuracy =

   96.6250


Accuracy =

   96.3878


Accuracy =9.638775e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   59.5238
   94.1222
   93.7333
   96.7290
   94.2792
   99.0909
   92.3077
  100.0000
   84.2105
   92.4036
   98.1990
   94.7761
   98.3784
   99.4760
   98.5673
   96.4286


AverageAccuracy =

   93.2641

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-07       26-      47  1.6021e+03  3.1258e+01  2.6988e-06

indexes =

  Columns 1 through 13

    85   179    32   116   197    99   104    58   191   171    46   147   103

  Columns 14 through 26

    11    71   120    51    81   100    70    98    51   105   153   179    94

  Columns 27 through 30

    99    84   120   139

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.3526


Accuracy =

   95.4065


Accuracy =

   95.7192


Accuracy =

   95.9025


Accuracy =

   95.6330


Accuracy =

   95.5143


Accuracy =

   95.6330


Accuracy =

   95.8810


Accuracy =

   95.8163


Accuracy =

   95.5143


Accuracy =9.551434e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   66.6667
   94.8142
   94.1489
   85.9813
   94.9425
   98.3359
   69.2308
  100.0000
   83.3333
   93.1585
   96.8018
   95.3358
   92.4731
   99.5633
   88.6686
   97.6190


AverageAccuracy =

   90.6921

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=55;
components=55;
trainingNum=55  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x55]             
B                    [1999x55]            
C                    [64x55]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       35-      51  2.8311e+03  3.7450e+01  3.9786e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       33-      47  1.3670e+03  3.0875e+01  2.5616e-05
    1T  9.1e-06       26-      50  1.9792e+03  3.7640e+01  3.3958e-05

indexes =

  Columns 1 through 13

    28   148   128   146    20    67    17    54    39   169    83   110   181

  Columns 14 through 26

    99   142   176    69    61   162    91   144    20    27    83    62   114

  Columns 27 through 30

   131    31    33   132

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.5716


Accuracy =

   95.7224


Accuracy =

   95.7548


Accuracy =

   95.7548


Accuracy =

   95.7224


Accuracy =

   95.4854


Accuracy =

   95.2915


Accuracy =

   95.4100


Accuracy =

   95.6039


Accuracy =

   95.7224


Accuracy =9.572244e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   93.4312
   89.3617
   94.9309
   96.5596
   97.8756
   84.6154
  100.0000
   83.3333
   90.2050
   98.2898
   96.6480
   91.3978
   99.3886
   96.5812
   92.8571


AverageAccuracy =

   93.7946

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       62-      51  1.2629e+03  3.8056e+01  7.5111e-06
    1T  9.2e-07       27-      52  1.3694e+03  3.8092e+01  2.8004e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       14-      62  3.4711e+03  5.4246e+01  5.0182e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       14-      49  1.6284e+03  3.5003e+01  5.2290e-06
    1T  9.3e-06        2-      55  1.4086e+03  3.9720e+01  3.2593e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       36-      62  2.9118e+03  5.0478e+01  1.2284e-05

indexes =

  Columns 1 through 13

   186    92     6    20   114    34   195   169    10   114   149   107    56

  Columns 14 through 26

   174     9   146   105    14   167   170   150   164   117    50    38   176

  Columns 27 through 30

   172   140    84   144

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2736


Accuracy =

   96.3920


Accuracy =

   96.1443


Accuracy =

   96.6613


Accuracy =

   96.0797


Accuracy =

   95.8428


Accuracy =

   96.2305


Accuracy =

   96.4351


Accuracy =

   96.1012


Accuracy =

   96.3920


Accuracy =9.639203e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   95.9199
   91.6112
   91.5888
   98.6239
   97.8852
  100.0000
   98.3834
   88.8889
   91.6951
   98.6499
   97.0205
   92.9730
   97.9058
   98.8604
   94.0476


AverageAccuracy =

   94.8367

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       53-      53  1.3020e+03  4.7276e+01  3.4744e-06
    1T  6.6e-06       15-      56  1.5551e+03  4.3355e+01  3.6158e-05

indexes =

  Columns 1 through 13

    45   107    58   187    73    41    67   139    73   174   184   119   148

  Columns 14 through 26

    16   184   143    55   179    79   121    48   138    11    32    18    36

  Columns 27 through 30

    27    80    24     4

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9569


Accuracy =

   96.3774


Accuracy =

   96.1617


Accuracy =

   96.2264


Accuracy =

   95.6873


Accuracy =

   96.1617


Accuracy =

   95.6765


Accuracy =

   96.0647


Accuracy =

   96.3774


Accuracy =

   95.9892


Accuracy =9.598922e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   44.1860
   94.4402
   94.4149
   95.3271
   97.9405
   99.2424
  100.0000
   99.3088
  100.0000
   94.7668
   96.7524
   91.8216
  100.0000
   99.4760
   90.5172
   92.8571


AverageAccuracy =

   93.1907

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       26-      62  2.9617e+03  3.8834e+01  2.2926e-05
    1T  3.0e-07       29-      47  1.4003e+03  3.5659e+01  5.5625e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       63-      57  1.3825e+03  3.6608e+01  1.6700e-05

indexes =

  Columns 1 through 13

   106   173     6   102   141    61    30   196    40    39    86    47    87

  Columns 14 through 26

     2    80   143    31    42   192    10    55   150    24   163    88    51

  Columns 27 through 30

   189    46   166   115

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9698


Accuracy =

   95.3772


Accuracy =

   95.8621


Accuracy =

   95.8190


Accuracy =

   95.4526


Accuracy =

   95.8944


Accuracy =

   95.8728


Accuracy =

   95.7435


Accuracy =

   95.9159


Accuracy =

   96.0022


Accuracy =9.600216e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   71.4286
   94.7981
   95.2191
   87.0370
   95.8810
   99.5448
   92.3077
   98.1481
   94.4444
   91.1565
   97.6158
   96.0967
   90.3743
   99.0385
   98.0057
   90.4762


AverageAccuracy =

   93.2233

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       39-      63  2.1591e+03  5.4843e+01  2.4628e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-07        1-      60  2.9200e+03  4.0752e+01  2.1029e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       36-      60  1.9662e+03  4.2713e+01  4.4248e-04
    1T  4.8e-06       22-      62  1.5660e+03  5.9225e+01  1.7029e-05
    1T  5.3e-06       27-      59  1.7730e+03  3.8001e+01  1.2502e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       42-      56  1.3108e+03  3.5962e+01  1.0007e-04

indexes =

  Columns 1 through 13

   159    93   192    64    15    99   103   169    21   153     7   193    15

  Columns 14 through 26

   100   176   115   149   118   136    36    44   115    50    13   175    64

  Columns 27 through 30

   173    29    42   103

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.4801


Accuracy =

   96.8891


Accuracy =

   96.2756


Accuracy =

   96.8461


Accuracy =

   96.9968


Accuracy =

   96.5985


Accuracy =

   96.8999


Accuracy =

   96.5554


Accuracy =

   96.4047


Accuracy =

   96.7061


Accuracy =9.670614e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   69.0476
   97.2931
   95.4727
   88.9401
   95.1945
   97.1299
  100.0000
  100.0000
  100.0000
   91.1263
   99.0553
   97.7695
  100.0000
   99.4783
   92.8571
   78.8235


AverageAccuracy =

   93.8868

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       15-      50  1.4918e+03  4.0162e+01  1.3108e-05

indexes =

  Columns 1 through 13

   195   197    35    53    67    65   103    36    33   196   113    17    12

  Columns 14 through 26

   143   166   105   121    15    32    69   140   161    94   127    89    14

  Columns 27 through 30

   164   165    81   133

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.6124


Accuracy =

   96.5692


Accuracy =

   96.7526


Accuracy =

   96.9900


Accuracy =

   96.4182


Accuracy =

   96.6771


Accuracy =

   96.7958


Accuracy =

   96.9144


Accuracy =

   96.6124


Accuracy =

   97.0008


Accuracy =9.700076e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   73.8095
   94.8916
   96.9251
   96.7290
   99.3151
   97.8788
   92.3077
   99.0741
   77.7778
   94.6469
   98.9644
   92.7103
   97.8495
   99.8250
   96.2963
   81.1765


AverageAccuracy =

   93.1361

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-07       37-      62  2.4818e+03  4.7547e+01  4.1319e-07
    1T  9.7e-06       61-      55  1.3254e+03  3.9789e+01  1.1457e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.9e-06       41-      53  1.0498e+03  3.5162e+01  4.5639e-03

indexes =

  Columns 1 through 13

   193   179   101    96   131   185    11    67     7   136   156    26    57

  Columns 14 through 26

    62    12   131   200   107   126    34   152    32    25   127   107     7

  Columns 27 through 30

    98   125   135    47

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1858


Accuracy =

   96.0672


Accuracy =

   96.3043


Accuracy =

   96.0349


Accuracy =

   96.1427


Accuracy =

   96.3258


Accuracy =

   96.0349


Accuracy =

   96.2612


Accuracy =

   95.8410


Accuracy =

   96.4767


Accuracy =9.647667e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   96.3594
   96.2667
   94.8837
   97.0183
   98.6384
  100.0000
  100.0000
   66.6667
   93.6436
   97.3944
   95.7169
   97.3118
   95.4625
   99.1404
   86.9048


AverageAccuracy =

   93.9689

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       58-      58  1.9294e+03  4.1558e+01  1.6476e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       33-      39  1.3603e+03  3.3124e+01  3.7033e-05
    1T -2.3e-06        5-      55  1.3272e+03  3.7839e+01  7.3885e-06
    1T -6.0e-06       21-      58  1.7153e+03  4.3007e+01  1.9904e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       21-      55  2.0152e+03  3.9421e+01  4.0035e-05

indexes =

  Columns 1 through 13

   199   175   195    78   172   172    99     1   165     8     9   120    69

  Columns 14 through 26

   173    11   108   186    39    95     9    73   140   192    92   141    55

  Columns 27 through 30

    53   165   134    24

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8634


Accuracy =

   95.4864


Accuracy =

   95.7988


Accuracy =

   95.5510


Accuracy =

   95.7341


Accuracy =

   95.5295


Accuracy =

   95.8419


Accuracy =

   95.7449


Accuracy =

   95.8419


Accuracy =

   95.8634


Accuracy =9.586341e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   59.5238
   94.5089
   96.4048
  100.0000
   91.9540
   98.4848
  100.0000
  100.0000
   88.8889
   91.9410
   98.1107
   90.3525
   93.0108
   97.5546
   97.7208
   90.4762


AverageAccuracy =

   93.0582

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       64-      51  2.0503e+03  3.7620e+01  3.2729e-05
    1T -3.5e-06       57-      56  1.6699e+03  4.6174e+01  9.4270e-06

indexes =

  Columns 1 through 13

    87   121     8   120   162   132    81   132   177   145    31   185    98

  Columns 14 through 26

   122     4    77    55    71    27   200    98   107    13    80   194   107

  Columns 27 through 30

   155    99   153    58

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.5305


Accuracy =

   96.7137


Accuracy =

   96.3797


Accuracy =

   96.5305


Accuracy =

   96.3905


Accuracy =

   96.4228


Accuracy =

   96.3905


Accuracy =

   96.7568


Accuracy =

   96.7245


Accuracy =

   96.6060


Accuracy =9.660597e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   98.1481
   94.5333
   85.7143
   98.6301
   96.8326
   88.4615
  100.0000
   72.2222
   93.7429
   98.1974
   93.8318
   89.7297
   99.7380
   92.3077
   96.4286


AverageAccuracy =

   93.0622

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       42-      52  1.1514e+03  4.1914e+01  1.4498e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05
    1T  1.7e-06       53-      57  1.5389e+03  4.1809e+01  4.1261e-06
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06        3-      50  1.5489e+03  4.2762e+01  3.7906e-05
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05
    1T -9.6e-06       50-      44  1.1828e+03  4.1320e+01  4.6342e-05

indexes =

  Columns 1 through 13

    51   185    99    89     2   175   160   114   174   123   136   200   177

  Columns 14 through 26

    70   132   184    99   190   116   154    55     2   140    85   130    53

  Columns 27 through 30

     9     5    31    62

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.9639


Accuracy =

   94.9639


Accuracy =

   94.9639


Accuracy =

   95.0394


Accuracy =

   94.8021


Accuracy =

   95.3952


Accuracy =

   95.3197


Accuracy =

   95.2874


Accuracy =

   95.1796


Accuracy =

   95.1688


Accuracy =9.516877e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   33.3333
   95.1826
   93.3244
   84.6512
   97.4713
   96.3746
   57.6923
   99.0805
   66.6667
   94.2111
   96.9003
   89.3458
  100.0000
   97.7253
   97.1429
   92.8571


AverageAccuracy =

   86.9975

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [1999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       28-      63  2.3665e+03  5.3266e+01  1.0279e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       25-      63  2.8645e+03  5.1742e+01  1.2644e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-07       31-      55  1.4714e+03  4.3984e+01  1.5947e-06
    1T  3.1e-06       47-      62  1.1687e+03  5.7099e+01  7.5546e-06

indexes =

  Columns 1 through 13

    49   161   139   156    26    99    22   116    60    10   181    60    26

  Columns 14 through 26

   118   138   114   157   152   148   104   117   101   135    96    68   107

  Columns 27 through 30

   104    62    71   161

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0030


Accuracy =

   96.1323


Accuracy =

   96.3154


Accuracy =

   95.8414


Accuracy =

   95.9168


Accuracy =

   95.8306


Accuracy =

   96.1215


Accuracy =

   96.2939


Accuracy =

   96.2400


Accuracy =

   96.2724


Accuracy =9.627236e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   54.7619
   95.9042
   96.8043
   95.3271
   95.9184
   99.3930
   84.6154
   99.3072
   88.8889
   92.9545
   97.2985
   95.3271
   98.9189
   98.8686
   88.5387
   91.7647


AverageAccuracy =

   92.1620

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=35;
components=35;
trainingNum=35  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        4-      61  1.2195e+03  4.2169e+01  1.5504e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       51-      66  2.2059e+03  5.3885e+01  4.0053e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       75-      61  2.9859e+03  4.2979e+01  2.7308e-05
    1T  2.8e-06       52-      61  1.3873e+03  4.1169e+01  1.6820e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       21-      67  2.2617e+03  4.6747e+01  6.9153e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       20-      58  1.7486e+03  5.0040e+01  6.4798e-05
    1T  3.8e-06       21-      65  1.8627e+03  5.5463e+01  3.3639e-06

indexes =

  Columns 1 through 13

   135   199    96   180   111   183   155    14   150    81    13    12    95

  Columns 14 through 26

   166   200    24    39    75    78    55   157    69   148    30   147   143

  Columns 27 through 30

   136   141   191   110

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.6257


Accuracy =

   96.5502


Accuracy =

   96.2484


Accuracy =

   96.3238


Accuracy =

   96.5610


Accuracy =

   95.6770


Accuracy =

   96.5179


Accuracy =

   96.4532


Accuracy =

   96.2915


Accuracy =

   96.5179


Accuracy =9.651790e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   96.2877
   97.8610
   95.8140
   97.0252
   96.3581
   84.6154
   98.8399
   72.2222
   95.4545
   97.4336
   91.8063
   99.4624
   99.9129
   87.1795
   95.2381


AverageAccuracy =

   93.0528

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       27-      62  1.2214e+03  5.3854e+01  2.4949e-05
    1T -1.4e-06       24-      66  4.2783e+03  5.1984e+01  2.3593e-06
    1T  3.9e-06       62-      61  1.5785e+03  5.4489e+01  3.5147e-06
    1T  6.0e-06       65-      68  2.0982e+03  4.8334e+01  3.0680e-05
    1T -2.8e-06       51-      71  1.2741e+03  5.3402e+01  4.2934e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        9-      67  1.8501e+03  4.7437e+01  3.5415e-03

indexes =

  Columns 1 through 13

    77   197    31   108     7   145    37    81   193    35   149   134   106

  Columns 14 through 26

   169    16    78    25    84   116   198   156    56   108    68    45   124

  Columns 27 through 30

    60   169   141   119

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2126


Accuracy =

   96.5569


Accuracy =

   96.8905


Accuracy =

   96.6538


Accuracy =

   96.9981


Accuracy =

   97.0303


Accuracy =

   96.9873


Accuracy =

   97.1379


Accuracy =

   96.9981


Accuracy =

   97.1702


Accuracy =9.717022e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   61.9048
   96.1420
   98.5353
   95.8140
   89.2202
   99.2481
   76.9231
  100.0000
  100.0000
   98.2974
   97.6619
   97.0149
   98.9247
   99.1297
   97.1510
   83.5294


AverageAccuracy =

   93.0935

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       47-      74  3.5462e+03  4.7958e+01  1.2620e-05

indexes =

  Columns 1 through 13

    35   167   171     8    65     3    74    78    11    95   159    83    82

  Columns 14 through 26

    97   118     2   160    79    93   136   105   134   165    74    65    66

  Columns 27 through 30

   197    82   170   115

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1821


Accuracy =

   96.1821


Accuracy =

   96.5056


Accuracy =

   96.0203


Accuracy =

   96.1281


Accuracy =

   96.5056


Accuracy =

   96.5056


Accuracy =

   96.5487


Accuracy =

   96.5272


Accuracy =

   96.1928


Accuracy =9.619284e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   42.8571
   92.6299
   93.7417
   85.1163
   97.7064
   98.6384
   92.3077
  100.0000
  100.0000
   96.7045
   98.1990
   95.1493
   99.4595
   99.3007
   95.1429
   84.5238


AverageAccuracy =

   91.9673

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       51-      65  1.5946e+03  6.3212e+01  3.4187e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       51-      71  3.0814e+03  7.0909e+01  3.1941e-05
    1T  3.0e-06       52-      63  1.3073e+03  5.6372e+01  2.6441e-06

indexes =

  Columns 1 through 13

   117   166   113   144   171   172   109    37    39    18    24   151    42

  Columns 14 through 26

    47   130    74   186     9    17    64    59    61   111   137   173    44

  Columns 27 through 30

   122   104   123   165

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.4986


Accuracy =

   96.3262


Accuracy =

   95.9384


Accuracy =

   96.6817


Accuracy =

   96.2616


Accuracy =

   95.9276


Accuracy =

   96.2831


Accuracy =

   96.4986


Accuracy =

   96.0030


Accuracy =

   96.2185


Accuracy =9.621849e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   96.5170
   95.5941
   96.2791
   96.5675
   98.3308
  100.0000
  100.0000
   83.3333
   89.2168
   97.5687
   95.9184
   92.4731
   97.2973
   99.1477
   85.7143


AverageAccuracy =

   94.5033

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-07       26-      66  1.9718e+03  5.5827e+01  3.5028e-06
    1T  9.9e-06       68-      74  1.2192e+03  6.0871e+01  1.1049e-05
    1T  4.6e-06       32-      68  1.6173e+03  4.9958e+01  2.3934e-05
    1T -7.3e-06       64-      73  1.3184e+03  6.1793e+01  9.2810e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06        9-      71  1.4068e+03  5.3388e+01  2.1579e-05
    1T  9.0e-07       62-      62  1.5138e+03  4.4448e+01  7.2506e-03

indexes =

  Columns 1 through 13

     5    81   158   192    54    28    83   164     7    30   156    19   135

  Columns 14 through 26

    57    17   137    89   184    36    83   102   142   119   186   146    36

  Columns 27 through 30

    33   176    57    92

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.6606


Accuracy =

   96.5959


Accuracy =

   96.7575


Accuracy =

   96.4343


Accuracy =

   96.7037


Accuracy =

   96.3805


Accuracy =

   96.6282


Accuracy =

   96.4128


Accuracy =

   96.6390


Accuracy =

   96.8976


Accuracy =9.689755e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   97.3643
   96.8085
   89.3023
   96.5675
   98.6364
  100.0000
   99.5360
  100.0000
   95.6965
   97.2985
   96.0821
   90.2703
   97.3958
   98.5673
   91.8605


AverageAccuracy =

   96.2890

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       57-      66  2.3920e+03  4.3364e+01  6.9225e-06
    1T  4.4e-06       62-      61  1.0105e+03  4.4514e+01  2.1495e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       74-      60  1.4479e+03  4.8495e+01  1.6486e-05

indexes =

  Columns 1 through 13

    68     2   133   166    24   101   119   138    74    82   125   153   142

  Columns 14 through 26

   168    82   197   110    86   130   178   177    44    74    11   106   110

  Columns 27 through 30

    40   147    71    63

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9681


Accuracy =

   95.6123


Accuracy =

   95.5369


Accuracy =

   95.8495


Accuracy =

   95.2781


Accuracy =

   96.0436


Accuracy =

   96.1082


Accuracy =

   95.6123


Accuracy =

   96.1621


Accuracy =

   95.9250


Accuracy =9.592497e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   94.8062
   97.7364
   83.2558
   94.4954
   96.6616
  100.0000
  100.0000
   94.4444
   93.5520
   96.8933
   94.6296
   90.3226
   98.4238
   97.7143
   90.4762


AverageAccuracy =

   94.6180

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       18-      73  1.9202e+03  6.7951e+01  1.0105e-05

indexes =

  Columns 1 through 13

    84     1   193    24    13   156   166   160   137   121   139   113    73

  Columns 14 through 26

   144    54   110   180   106     3    70   195    24   108    31    40    18

  Columns 27 through 30

    16   193    11   102

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.0924


Accuracy =

   96.8770


Accuracy =

   97.1355


Accuracy =

   97.3293


Accuracy =

   96.8124


Accuracy =

   97.3185


Accuracy =

   97.3185


Accuracy =

   97.4478


Accuracy =

   97.0170


Accuracy =

   97.5555


Accuracy =9.755546e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   98.6079
   96.8296
   99.0654
   96.8037
   98.4848
   92.3077
  100.0000
   50.0000
   92.9705
   98.9644
   95.5224
   88.1081
   99.3031
  100.0000
   98.8095


AverageAccuracy =

   92.9206

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       30-      59  1.2807e+03  4.7320e+01  5.9390e-05
    1T  7.8e-06       42-      62  1.4825e+03  5.1777e+01  2.0090e-04
    1T  7.5e-06       54-      43  1.4445e+03  4.0383e+01  2.1513e-05
    1T  7.5e-06       15-      67  2.4201e+03  5.8566e+01  4.4954e-05
    1T  7.0e-06       35-      63  1.5200e+03  5.2484e+01  8.3361e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       59-      62  1.2548e+03  4.6441e+01  2.3938e-05
    1T  3.1e-06       14-      73  7.7379e+02  6.5698e+01  1.3348e-06
    1T  5.1e-06       31-      68  1.4324e+03  5.8293e+01  1.1170e-05

indexes =

  Columns 1 through 13

   150   112   184   135   118   148    95    65   189   125    84   100   144

  Columns 14 through 26

   133    61    29     1   135    12   167    25   140    58   198   121    20

  Columns 27 through 30

   112     6    37    10

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9617


Accuracy =

   95.9078


Accuracy =

   95.7571


Accuracy =

   96.1232


Accuracy =

   95.9186


Accuracy =

   95.7786


Accuracy =

   96.0478


Accuracy =

   96.3924


Accuracy =

   96.2955


Accuracy =

   96.1986


Accuracy =9.619858e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.6977
   93.9535
   95.0667
   79.4393
   98.1777
   98.0363
   80.7692
  100.0000
   72.2222
   93.3941
   97.7477
   94.6396
  100.0000
   99.5641
   99.1453
   83.9080


AverageAccuracy =

   92.2976

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       60-      59  1.3799e+03  4.7345e+01  1.6356e-05
    1T  6.6e-06       42-      66  1.2511e+03  4.1977e+01  8.8838e-03
    1T  9.2e-06       34-      73  8.7226e+02  6.0380e+01  2.9532e-05
    1T  3.6e-06       31-      66  9.8826e+02  4.8924e+01  3.1376e-03

indexes =

  Columns 1 through 13

    92     3   114    53    66   197    84    24    48   192    15   152   107

  Columns 14 through 26

    52   121   127   165   187    73   163    65     1    93     4    57   124

  Columns 27 through 30

   195   163   119    49

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.5209


Accuracy =

   96.1439


Accuracy =

   96.7686


Accuracy =

   96.5640


Accuracy =

   96.6502


Accuracy =

   96.9517


Accuracy =

   96.1978


Accuracy =

   96.8656


Accuracy =

   96.8871


Accuracy =

   96.7148


Accuracy =9.671478e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   96.9136
   97.0822
   84.5794
   99.7706
   96.9834
   92.3077
  100.0000
   77.7778
   92.9385
   98.5128
   94.4030
   97.3118
   98.4307
   90.8571
   98.8235


AverageAccuracy =

   94.4956

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       38-      69  1.0027e+03  7.1875e+01  4.0870e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       34-      62  1.3794e+03  5.4933e+01  5.9593e-06
    1T  7.7e-06       66-      69  2.4548e+03  5.1662e+01  3.2434e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       65-      61  2.0365e+03  5.1781e+01  2.6819e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       72-      60  1.4112e+03  6.8085e+01  3.4766e-05
    1T  4.8e-06       20-      61  1.5491e+03  4.7843e+01  6.8974e-06
    1T -8.5e-06       68-      74  3.4298e+03  6.9020e+01  6.7331e-06

indexes =

  Columns 1 through 13

   134    49   151    84   127   179     1    16   110    12     9   183   172

  Columns 14 through 26

    79   168    58   197   150    55   146   171    63    53   100   126   115

  Columns 27 through 30

    41    64   102   115

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4198


Accuracy =

   96.4005


Accuracy =

   95.8401


Accuracy =

   95.5922


Accuracy =

   96.1418


Accuracy =

   95.8940


Accuracy =

   95.9263


Accuracy =

   96.0987


Accuracy =

   95.9586


Accuracy =

   95.8077


Accuracy =9.580774e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   96.0557
   94.1411
   89.7674
   94.7368
   98.7842
   84.6154
   97.9310
   88.8889
   89.7377
   97.7948
   96.8460
   94.6237
   97.2028
   96.0114
   83.5294


AverageAccuracy =

   93.7917

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       67-      64  1.5228e+03  5.0263e+01  5.6762e-05

indexes =

  Columns 1 through 13

    77   109   116   102   174   104    32   115   185   193    15   116    11

  Columns 14 through 26

   170   182    18   108    29     7   128    62    10    87    36    60    90

  Columns 27 through 30

    75   137   152   195

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.1000


Accuracy =

   97.4342


Accuracy =

   97.4019


Accuracy =

   96.7874


Accuracy =

   96.8521


Accuracy =

   97.4342


Accuracy =

   97.2618


Accuracy =

   97.4235


Accuracy =

   96.8521


Accuracy =

   97.1647


Accuracy =9.716473e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   95.9042
   99.1989
   97.2222
   90.3890
   99.3958
   84.6154
   99.3072
   66.6667
   95.4390
   98.6023
   98.1413
   93.5484
   98.3435
   93.6782
   94.1176


AverageAccuracy =

   94.0356

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       14-      79  3.1617e+03  5.7484e+01  9.1654e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-07       59-      80  2.3010e+03  6.4264e+01  6.7062e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       74-      72  1.5595e+03  5.2840e+01  2.4144e-06
    1T -8.0e-07       63-      67  1.4397e+03  4.5904e+01  1.6958e-06
    1T -9.4e-06       42-      72  1.2179e+03  4.8466e+01  7.2449e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06        3-      68  1.2330e+03  5.4094e+01  1.3400e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       70-      69  1.3404e+03  5.4829e+01  7.4047e-06
    1T  1.8e-06       65-      70  1.2573e+03  5.1342e+01  4.0433e-06

indexes =

  Columns 1 through 13

   126     7    96    60    61    39    49   131   198   191    48   184    77

  Columns 14 through 26

   125   109    35    43    22   160   137    55   134    34   152   170   183

  Columns 27 through 30

    90    97   111    78

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.2868


Accuracy =

   97.2976


Accuracy =

   97.2330


Accuracy =

   97.5129


Accuracy =

   96.6624


Accuracy =

   96.9961


Accuracy =

   97.3622


Accuracy =

   97.0715


Accuracy =

   96.7270


Accuracy =

   97.3514


Accuracy =9.735142e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   71.4286
   97.6888
   94.5695
   98.1481
   95.4442
   98.7897
   96.1538
   99.7685
  100.0000
   94.4318
   98.6949
   97.7570
   95.7219
   99.0385
   98.2808
   83.3333


AverageAccuracy =

   94.9531

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       16-      68  8.6475e+02  5.3509e+01  7.5016e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       15-      75  1.4116e+03  5.8379e+01  2.7131e-06
    1T  1.7e-06       69-      57  1.2936e+03  4.9854e+01  6.5461e-06

indexes =

  Columns 1 through 13

   183   168    92    61    54   131   199   151   148    49   178    96   178

  Columns 14 through 26

   184   107    97   117    56    42    40    83    47    50   144   105   196

  Columns 27 through 30

   186   138    99    79

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.8389


Accuracy =

   96.2240


Accuracy =

   96.8173


Accuracy =

   96.8281


Accuracy =

   96.7526


Accuracy =

   96.9900


Accuracy =

   96.7418


Accuracy =

   96.8173


Accuracy =

   96.8497


Accuracy =

   97.0871


Accuracy =9.708706e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   98.4508
   97.0745
   89.7196
   92.6941
   98.6364
   80.7692
  100.0000
   83.3333
   92.2463
   99.0536
   97.0149
  100.0000
   97.5503
   95.7020
   95.2381


AverageAccuracy =

   94.0986

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       26-      74  1.3153e+03  5.3376e+01  1.5403e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       20-      74  1.0294e+03  7.7740e+01  5.2747e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03
    1T  4.8e-06       26-      74  1.1819e+03  5.1177e+01  1.7715e-05
    1T  1.6e-06       75-      73  1.2970e+03  5.4385e+01  1.2116e-05
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03
    1T  1.2e-06       63-      52  2.2519e+03  4.8720e+01  7.1403e-03

indexes =

  Columns 1 through 13

    67   108   110   112   172   170   198   127   187   139   162    13    46

  Columns 14 through 26

    24    52   185    23   151   180   175   155   136   112   199   133     1

  Columns 27 through 30

     7   103    57   145

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2823


Accuracy =

   95.8621


Accuracy =

   95.8944


Accuracy =

   96.1422


Accuracy =

   95.8082


Accuracy =

   95.8836


Accuracy =

   95.7759


Accuracy =

   96.4009


Accuracy =

   96.0129


Accuracy =

   96.1961


Accuracy =9.619612e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   64.2857
   96.8266
   96.2567
   70.0461
   97.2414
   97.8852
   96.1538
   99.3072
   94.4444
   96.5870
   98.0674
   94.2272
   90.2703
   98.5179
   94.2857
   83.3333


AverageAccuracy =

   91.7335

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       41-      82  3.1380e+03  5.8807e+01  7.0707e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       12-      83  2.8727e+03  6.4899e+01  1.2358e-05
    1T  3.3e-06       50-      74  1.6980e+03  5.1326e+01  7.2904e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-07       57-      72  1.6566e+03  5.1957e+01  1.2800e-05

indexes =

  Columns 1 through 13

    54    12   126    49   117   120    57    38   131    87     2   129   125

  Columns 14 through 26

   165    34    18   143     4    79   105    64    34   160   173    61    46

  Columns 27 through 30

   148    43    65    19

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0194


Accuracy =

   96.2783


Accuracy =

   96.3215


Accuracy =

   96.1057


Accuracy =

   96.2891


Accuracy =

   96.2460


Accuracy =

   96.2999


Accuracy =

   96.2567


Accuracy =

   95.9655


Accuracy =

   96.3430


Accuracy =9.634304e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   96.9767
   92.8000
   96.7290
   96.3218
   96.6667
   92.3077
  100.0000
  100.0000
   94.3117
   99.4152
   93.6330
   86.0215
   96.8449
   91.8079
   93.0233


AverageAccuracy =

   94.6847

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       35-      75  2.0823e+03  5.7117e+01  6.4692e-05
    1T -9.3e-06       27-      80  3.5681e+03  6.4495e+01  5.7901e-03
    1T -8.6e-06       78-      69  1.3047e+03  4.8091e+01  1.2114e-05

indexes =

  Columns 1 through 13

    99   122   149    77    98   147   124   179     5    89    26    49   130

  Columns 14 through 26

   140    73   154    10   114    38    56   171   124    44   174    23    86

  Columns 27 through 30

   104    14   134    97

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2392


Accuracy =

   96.0560


Accuracy =

   95.8621


Accuracy =

   95.8944


Accuracy =

   95.9806


Accuracy =

   96.2823


Accuracy =

   95.9806


Accuracy =

   95.6573


Accuracy =

   96.2500


Accuracy =

   96.2500


Accuracy =9.625000e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   92.8019
   99.3342
   99.5370
   94.9541
   98.4871
  100.0000
   99.3103
   55.5556
   86.9318
   98.6023
   97.3929
   98.9189
   98.7826
   95.4155
   84.5238


AverageAccuracy =

   93.6355

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06       71-      83  1.9594e+03  7.0696e+01  5.9649e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       62-      75  2.0538e+03  5.5587e+01  3.2617e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       32-      72  9.4150e+02  5.3803e+01  2.9633e-05
    1T -6.5e-06       24-      83  1.0384e+03  6.6312e+01  7.6450e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       12-      77  1.4752e+03  4.8928e+01  1.8155e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      74  1.7969e+03  4.8873e+01  2.1671e-05

indexes =

  Columns 1 through 13

    61   125   126   114    42    86   114   172   187    76    91   131   160

  Columns 14 through 26

   112   172    63    53   135   186    27    15    18   195    69    83   127

  Columns 27 through 30

    65   118    34   158

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.2749


Accuracy =

   96.8656


Accuracy =

   96.8979


Accuracy =

   96.7579


Accuracy =

   96.4132


Accuracy =

   96.7363


Accuracy =

   96.6717


Accuracy =

   96.8440


Accuracy =

   96.7471


Accuracy =

   96.8979


Accuracy =9.689789e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   95.8301
   95.5882
   91.6279
   93.5780
   99.2436
  100.0000
  100.0000
   83.3333
   91.8367
   98.5631
   97.7612
   91.8919
   99.6510
   99.4302
   96.4286


AverageAccuracy =

   94.8811

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       40-      79  2.3466e+03  5.1019e+01  1.6552e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06        9-      84  3.0703e+03  6.4747e+01  6.8975e-06
    1T -2.2e-06       18-      84  3.2428e+03  6.4741e+01  2.9592e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       58-      76  2.0845e+03  5.3811e+01  3.4643e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       63-      70  1.9286e+03  4.6255e+01  2.3688e-05
    1T -1.5e-06       63-      71  1.2362e+03  5.6643e+01  2.1626e-06

indexes =

  Columns 1 through 13

   168    44     5   135   175   116   143    28   131   113   181    98   197

  Columns 14 through 26

    33   180   186    75   183   175   117    49   158    42   121   141    68

  Columns 27 through 30

   194    97    53   164

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.9083


Accuracy =

   96.2835


Accuracy =

   96.2620


Accuracy =

   96.6929


Accuracy =

   97.1022


Accuracy =

   97.1561


Accuracy =

   96.5959


Accuracy =

   96.7683


Accuracy =

   96.8652


Accuracy =

   96.8437


Accuracy =9.684369e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   96.5971
   92.8191
   96.2617
   97.7011
   98.7915
   84.6154
   99.5381
   38.8889
   93.9704
   98.6067
   94.0410
   99.4595
   99.4764
   97.7273
   77.3810


AverageAccuracy =

   91.3196

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       20-      75  2.2082e+03  5.9272e+01  1.4918e-05
    1T  3.2e-06       20-      75  2.2082e+03  5.9272e+01  1.4918e-05
    1T  3.2e-06       20-      75  2.2082e+03  5.9272e+01  1.4918e-05
    1T  3.2e-06       20-      75  2.2082e+03  5.9272e+01  1.4918e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       75-      83  1.0429e+03  6.5757e+01  6.5659e-06
    1T  9.8e-06       64-      83  4.3479e+03  6.4799e+01  1.0419e-05
    1T  3.9e-06       54-      79  2.2615e+03  5.9393e+01  8.7414e-06
    1T -3.9e-06       25-      79  1.9817e+03  5.7330e+01  2.3305e-06

indexes =

  Columns 1 through 13

   104    68   107   113   156   188   154   101   194    26   176   161   154

  Columns 14 through 26

   111   160   165    97    46   137    69   179    51   139    70   149    58

  Columns 27 through 30

    32    81    16   159

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.2068


Accuracy =

   95.4545


Accuracy =

   95.1530


Accuracy =

   95.5192


Accuracy =

   95.6915


Accuracy =

   95.6377


Accuracy =

   95.7992


Accuracy =

   95.7346


Accuracy =

   95.5192


Accuracy =

   95.7669


Accuracy =9.576691e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   50.0000
   93.8033
   96.2865
   96.7593
   90.8467
   98.0392
  100.0000
  100.0000
   94.4444
   97.2665
   97.3399
   94.8052
   83.8710
   97.6542
   97.9885
   67.0588


AverageAccuracy =

   91.0102

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=85;
components=85;
trainingNum=85  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x85]             
B                    [1999x85]            
C                    [64x85]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       76-      77  2.4153e+03  6.0208e+01  8.8658e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       13-      82  2.7618e+03  5.4330e+01  4.5301e-06
    1T  6.0e-06       58-      79  2.5540e+03  5.6239e+01  4.9762e-06
    1T  6.2e-06        9-      83  3.2086e+03  5.8822e+01  4.3572e-06

indexes =

  Columns 1 through 13

   188    56    10   151   195    37   155    71   118    37    17    79    46

  Columns 14 through 26

    53   100   170    41    98    11    63    25   121   163   140    33   149

  Columns 27 through 30

   115   138   104    67

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.9328


Accuracy =

   96.6961


Accuracy =

   96.7176


Accuracy =

   96.5347


Accuracy =

   96.5454


Accuracy =

   96.7822


Accuracy =

   96.3732


Accuracy =

   96.5562


Accuracy =

   96.1365


Accuracy =

   96.6315


Accuracy =9.663151e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   30.9524
   95.6757
   96.9456
   84.5794
   91.9908
   98.7823
   96.1538
  100.0000
  100.0000
   96.3801
   97.3022
   96.6543
   98.3957
   99.4764
   98.8636
   94.1176


AverageAccuracy =

   92.2669

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       42-      68  1.3873e+03  5.0456e+01  8.6596e-06
    1T -1.3e-06       38-      72  1.8905e+03  5.1096e+01  1.1437e-06

indexes =

  Columns 1 through 13

    82   148   157   146   175   193    35    40    98    66    54    46   131

  Columns 14 through 26

    85    91   117   157   163    10   159   184   173   135   161    60    96

  Columns 27 through 30

    71   133   151   120

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0729


Accuracy =

   96.4290


Accuracy =

   96.0514


Accuracy =

   96.2024


Accuracy =

   96.1592


Accuracy =

   96.4505


Accuracy =

   95.8572


Accuracy =

   96.1700


Accuracy =

   96.3750


Accuracy =

   96.3642


Accuracy =9.636422e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   78.5714
   95.6823
   97.9947
   88.3721
   96.5675
   94.8407
   96.1538
   99.0762
   88.8889
   96.7008
   96.7989
   98.3240
   81.1828
   99.0351
   96.2857
   90.4762


AverageAccuracy =

   93.4344

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       56-      70  1.0686e+03  6.2163e+01  4.3969e-06
    1T  4.4e-06        5-      65  9.5253e+02  5.4693e+01  6.5951e-06
    1T  9.0e-06       13-      69  1.3312e+03  4.9029e+01  3.1830e-05

indexes =

  Columns 1 through 13

   107   106    55   187    34    19   113    17   146    15   158   182    90

  Columns 14 through 26

    89   188   136    20    89    35   198   193   148   178   192    62   122

  Columns 27 through 30

   192    95   183    67

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8845


Accuracy =

   95.9491


Accuracy =

   95.5613


Accuracy =

   95.8953


Accuracy =

   95.5074


Accuracy =

   95.3674


Accuracy =

   95.7660


Accuracy =

   95.7552


Accuracy =

   95.5936


Accuracy =

   95.8737


Accuracy =9.587373e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   54.7619
   95.6723
   95.4727
   88.3721
   96.3554
   97.2727
  100.0000
  100.0000
   88.8889
   95.1192
   95.6796
   96.4684
   97.3118
   97.6399
   98.8506
   77.6471


AverageAccuracy =

   92.2195

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       12-      67  2.6332e+03  4.7682e+01  4.6589e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       37-      58  1.4008e+03  4.9311e+01  8.1611e-06
    1T  4.4e-06       42-      69  2.7227e+03  6.0363e+01  1.5480e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       34-      67  1.4980e+03  4.7727e+01  1.4801e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       65-      65  2.3587e+03  4.8967e+01  1.2212e-05

indexes =

  Columns 1 through 13

   109     3    48    15   100   198   138    26   182    80   144   180   129

  Columns 14 through 26

   120   196    78   163    95    29   111   108   181   160    63    64    78

  Columns 27 through 30

    29   189     8     4

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1518


Accuracy =

   96.6584


Accuracy =

   96.4105


Accuracy =

   96.0440


Accuracy =

   96.6368


Accuracy =

   96.7446


Accuracy =

   96.2057


Accuracy =

   96.4644


Accuracy =

   96.6045


Accuracy =

   96.5183


Accuracy =9.651827e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   69.0476
   96.2848
   96.9210
   95.7944
   97.4771
   97.5794
   80.7692
  100.0000
   77.7778
   94.4318
   98.2014
   95.3358
   96.2366
   98.1675
   89.2045
   83.3333


AverageAccuracy =

   91.6602

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       15-      66  1.8911e+03  5.5408e+01  2.9643e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-07       45-      74  2.4547e+03  6.4530e+01  6.2869e-07
    1T  8.4e-06       42-      58  2.0461e+03  5.1848e+01  1.4956e-05

indexes =

  Columns 1 through 13

    13   197    18    80    39   168   178    48    94   187   187   179    24

  Columns 14 through 26

   196    21   123   111   100    98    65   185    39    21   112    53   199

  Columns 27 through 30

   133    79     4    62

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.4686


Accuracy =

   96.3501


Accuracy =

   96.6085


Accuracy =

   96.2317


Accuracy =

   96.4470


Accuracy =

   96.3824


Accuracy =

   96.4793


Accuracy =

   96.3824


Accuracy =

   96.7270


Accuracy =

   96.1779


Accuracy =9.617786e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   96.8364
   96.2865
   83.6449
   97.9358
   98.0273
  100.0000
   99.5381
   55.5556
   92.8409
   96.7626
   90.1304
   96.7742
   98.5140
   99.4318
   97.7011


AverageAccuracy =

   93.1535

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       16-      66  2.9402e+03  5.5075e+01  7.2322e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       45-      70  2.0156e+03  6.3422e+01  5.9696e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       67-      55  1.3138e+03  4.4391e+01  1.3368e-05
    1T -8.6e-06       67-      71  2.1328e+03  6.3169e+01  6.7140e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       33-      64  1.3073e+03  5.1416e+01  4.7578e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       49-      62  1.5120e+03  4.6026e+01  1.2533e-04
    1T -4.5e-06       35-      62  1.2100e+03  4.7051e+01  1.0347e-02

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-07       73-      58  1.6368e+03  4.5132e+01  7.9144e-06
    1T  7.3e-07        5-      57  1.3002e+03  4.6170e+01  2.1874e-06

indexes =

  Columns 1 through 13

   180    78   192   184   176    11    99   163    28   199   153   173    49

  Columns 14 through 26

    44     1   138    98    64   113   151    85   116   143    43   166    87

  Columns 27 through 30

    24    98    87    90

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9388


Accuracy =

   95.7988


Accuracy =

   95.9280


Accuracy =

   95.9604


Accuracy =

   95.8526


Accuracy =

   96.0896


Accuracy =

   95.7880


Accuracy =

   95.9927


Accuracy =

   95.7449


Accuracy =

   96.0465


Accuracy =9.604654e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   50.0000
   96.2848
   95.8667
  100.0000
   97.4943
   99.3949
  100.0000
  100.0000
   83.3333
   91.4773
   96.3196
   90.3346
   98.3871
   99.1259
   94.8276
   89.4118


AverageAccuracy =

   92.6411

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       41-      71  3.5932e+03  5.8343e+01  1.9387e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       26-      61  1.2242e+03  4.3450e+01  8.9839e-06
    1T -1.6e-06       51-      66  1.6577e+03  4.8367e+01  4.9107e-06
    1T -6.7e-06        3-      67  1.4138e+03  4.6039e+01  1.3945e-05
    1T  3.1e-06        8-      68  1.7569e+03  4.8970e+01  1.3604e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       11-      64  1.7981e+03  4.2364e+01  1.0121e-05

indexes =

  Columns 1 through 13

   146   123   112   107   121   152   166   128    90    68    35   145    99

  Columns 14 through 26

    78   183     3   141   177   104    73    52   133    35   198   120   131

  Columns 27 through 30

   147   131   149   162

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.5615


Accuracy =

   97.4536


Accuracy =

   97.3457


Accuracy =

   97.0760


Accuracy =

   96.8278


Accuracy =

   97.2054


Accuracy =

   97.4752


Accuracy =

   97.4320


Accuracy =

   97.5507


Accuracy =

   97.3133


Accuracy =9.731334e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   98.9938
   97.2037
   80.9302
   90.3890
   98.3384
  100.0000
   98.8399
   88.8889
   96.6970
   98.5579
   95.8879
   97.2973
   99.1259
   95.4155
  100.0000


AverageAccuracy =

   96.0353

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       34-      56  1.3990e+03  4.5759e+01  4.9536e-05

indexes =

  Columns 1 through 13

   109   176    37   108   142   194   107   145    87   110     6    82   166

  Columns 14 through 26

    69   112    33   195   172   153    64    76   132    72    81    27    67

  Columns 27 through 30

     1   125    72   184

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1410


Accuracy =

   96.4536


Accuracy =

   97.0033


Accuracy =

   96.5398


Accuracy =

   96.3458


Accuracy =

   96.5075


Accuracy =

   96.7985


Accuracy =

   96.4213


Accuracy =

   96.4428


Accuracy =

   97.0357


Accuracy =9.703568e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   95.7430
   96.7957
   96.7442
   94.4954
   98.6364
   96.1538
  100.0000
   94.4444
   97.1687
   96.9915
   97.7612
   88.6486
   99.5618
   98.2808
   88.0952


AverageAccuracy =

   95.0296

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   153    26   169    92   153   120    60   107    11    10    14    66    33

  Columns 14 through 26

    11   101   161    56   186   183   195   152   120   186   199    34    17

  Columns 27 through 30

   190   129   164   118

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9815


Accuracy =

   95.6798


Accuracy =

   95.5936


Accuracy =

   95.6583


Accuracy =

   96.0461


Accuracy =

   95.4536


Accuracy =

   96.2077


Accuracy =

   95.5182


Accuracy =

   96.0461


Accuracy =

   95.4536


Accuracy =9.545357e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   86.0465
   91.8919
   96.1538
   74.5370
   96.5753
   94.1176
  100.0000
   99.7691
   83.3333
   94.3182
   99.0523
   94.9721
   83.8710
   99.0368
   96.5812
   78.5714


AverageAccuracy =

   91.8017

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       42-      68  3.6165e+03  4.3083e+01  1.2899e-05
    1T  3.7e-06       11-      68  1.1653e+03  4.9079e+01  9.8871e-06

indexes =

  Columns 1 through 13

    83    31    26   135    26    36    47   121   106     7     5   111    37

  Columns 14 through 26

     7   127   185   110    70   108    60   106   111     3    93     2    71

  Columns 27 through 30

    66    24    50    88

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8459


Accuracy =

   95.5553


Accuracy =

   95.8674


Accuracy =

   95.7706


Accuracy =

   95.6952


Accuracy =

   95.8997


Accuracy =

   95.8997


Accuracy =

   95.9643


Accuracy =

   95.9427


Accuracy =

   96.1365


Accuracy =9.613646e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   73.8095
   97.4537
   95.7503
   91.1628
   98.3908
   96.6817
   65.3846
   97.2414
   83.3333
   93.6364
   98.0700
   94.7664
   93.0851
   97.6419
   92.2636
   79.7619


AverageAccuracy =

   90.5271

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       47-      68  1.4942e+03  4.9332e+01  1.7501e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       11-      72  4.0432e+03  5.9934e+01  9.1020e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       53-      65  1.4172e+03  4.6149e+01  3.1854e-03
    1T  9.4e-06       34-      57  1.0373e+03  4.1139e+01  1.6108e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       73-      67  2.1395e+03  4.2828e+01  3.1744e-05

indexes =

  Columns 1 through 13

   141   106   105   168   189   166    26   180    66   143   156   137    36

  Columns 14 through 26

    60   126    67   108   192   161   156    47    27    45    24   179   164

  Columns 27 through 30

   154   183   132    61

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.4201


Accuracy =

   96.3338


Accuracy =

   96.0966


Accuracy =

   96.3123


Accuracy =

   95.9457


Accuracy =

   96.4524


Accuracy =

   96.2368


Accuracy =

   96.0319


Accuracy =

   96.4524


Accuracy =

   96.0966


Accuracy =9.609661e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   95.8851
   96.1333
   88.8889
   95.2055
   99.2401
   96.1538
   99.7685
  100.0000
   90.7029
   97.3435
   93.6685
   94.6237
   99.2133
   96.2857
   84.8837


AverageAccuracy =

   94.3093

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       68-      68  3.2059e+03  4.9614e+01  3.3531e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      60  9.9230e+02  4.3614e+01  1.5491e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06        6-      73  3.1258e+03  5.1058e+01  3.6153e-06
    1T  9.5e-06       58-      68  1.3026e+03  4.2312e+01  8.8134e-05
    1T  8.6e-07        7-      62  3.2477e+03  4.7417e+01  2.2906e-06

indexes =

  Columns 1 through 13

   140   104    58   102    21    94    62    43    86    67   118    99   167

  Columns 14 through 26

   200    12   192   142   162    98   157    51   185   144   117   185    79

  Columns 27 through 30

     9   107    59    69

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8024


Accuracy =

   96.1145


Accuracy =

   95.8454


Accuracy =

   95.8024


Accuracy =

   96.0715


Accuracy =

   95.7163


Accuracy =

   94.9091


Accuracy =

   96.2975


Accuracy =

   95.4687


Accuracy =

   96.1791


Accuracy =9.617910e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   96.7618
   92.9333
   98.1395
   96.5986
   99.2459
  100.0000
   97.7011
   78.9474
   93.5301
   96.8905
   92.9499
   98.9247
   97.7293
   97.4138
   76.4706


AverageAccuracy =

   94.4910

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        5-      72  1.4513e+03  7.6579e+01  5.6446e-06

indexes =

  Columns 1 through 13

    64    50   132   152   146   199   178   152   151   158    63    64   118

  Columns 14 through 26

     1   199    35    42    10    17   194   199   192   163   132    24   161

  Columns 27 through 30

    75   139   152   178

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9137


Accuracy =

   96.4420


Accuracy =

   96.0863


Accuracy =

   95.9677


Accuracy =

   96.0647


Accuracy =

   96.2803


Accuracy =

   96.1833


Accuracy =

   95.9137


Accuracy =

   96.1941


Accuracy =

   96.1617


Accuracy =9.616173e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   52.3810
   94.6759
   97.0628
   84.1121
   95.6720
   98.3359
   88.4615
  100.0000
  100.0000
   94.7668
   97.0747
   94.7664
   96.2162
   97.9878
   98.2857
   96.4286


AverageAccuracy =

   92.8892

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       22-      71  3.5631e+03  4.6551e+01  1.3668e-05
    1T -6.3e-06       42-      67  1.4224e+03  4.8835e+01  1.3306e-05

indexes =

  Columns 1 through 13

   113    39   198    53   115    63   114   178    46   181    79    54    49

  Columns 14 through 26

   176    81   145    17     2   165   121   200   107    12    75   102   198

  Columns 27 through 30

   185   199   128   132

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9560


Accuracy =

   96.3334


Accuracy =

   96.1070


Accuracy =

   96.2040


Accuracy =

   95.7511


Accuracy =

   96.0962


Accuracy =

   96.0207


Accuracy =

   96.1501


Accuracy =

   96.1393


Accuracy =

   96.0746


Accuracy =9.607463e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   96.9814
   95.0535
   85.5814
   92.9224
   97.1168
   92.3077
   98.8426
  100.0000
   95.2109
   97.3921
   92.3507
   88.1720
   98.0820
   97.7077
   92.8571


AverageAccuracy =

   94.8873

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       24-      74  3.8700e+03  4.8142e+01  6.0587e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       38-      65  1.5584e+03  4.2692e+01  5.6635e-06

indexes =

  Columns 1 through 13

   109    77   146    73   106    64    78    77    26   180    37   159    13

  Columns 14 through 26

     9   151    22   180     5   115   111    77    66    43     6   152   195

  Columns 27 through 30

   132   167    37    63

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4433


Accuracy =

   95.6264


Accuracy =

   95.7126


Accuracy =

   95.3786


Accuracy =

   95.7772


Accuracy =

   96.0681


Accuracy =

   95.0232


Accuracy =

   94.9801


Accuracy =

   95.5295


Accuracy =

   95.9173


Accuracy =9.591727e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   95.9846
   92.2975
   93.5185
   92.4658
   98.0333
   53.8462
   99.7691
   83.3333
   89.5097
   99.0991
   96.8284
   96.7568
   99.3043
   89.1117
   92.8571


AverageAccuracy =

   91.1518

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       57-      66  1.3319e+03  4.3394e+01  1.9279e-04
    1T  1.2e-06       44-      57  8.6233e+02  4.5868e+01  5.3516e-06

indexes =

  Columns 1 through 13

   192   190   156    81   163    55    12   164    44   180   155   171   190

  Columns 14 through 26

    91     1    38   190    55    75   165    66    69    46    12    84   180

  Columns 27 through 30

   150    50   135    84

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9905


Accuracy =

   96.1091


Accuracy =

   95.4732


Accuracy =

   96.2707


Accuracy =

   96.1845


Accuracy =

   95.6779


Accuracy =

   95.8612


Accuracy =

   96.0552


Accuracy =

   95.9905


Accuracy =

   95.9797


Accuracy =9.597974e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   50.0000
   96.6718
   97.0628
   90.7407
   96.8037
   98.3333
  100.0000
   99.3072
   38.8889
   87.8409
   97.2560
   93.8662
   94.6237
   99.8252
   96.2751
   97.6190


AverageAccuracy =

   89.6946

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       73-      73  2.5074e+03  6.7010e+01  2.5329e-06
    1T  2.7e-07       32-      67  2.0879e+03  5.7343e+01  2.7791e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.6e-06        6-      62  1.5403e+03  6.1197e+01  9.6132e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       59-      66  1.6681e+03  5.3561e+01  1.7626e-04

indexes =

  Columns 1 through 13

    30    27    84   128   197    54   193    79    20    34   124    13    49

  Columns 14 through 26

   166    98   150    45   173    94   113   157    82     2   140    50    59

  Columns 27 through 30

   107   135   119   131

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.6752


Accuracy =

   95.9556


Accuracy =

   95.5781


Accuracy =

   95.7722


Accuracy =

   95.2330


Accuracy =

   95.7183


Accuracy =

   95.7830


Accuracy =

   95.6752


Accuracy =

   95.8261


Accuracy =

   95.4702


Accuracy =9.547023e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   26.1905
   95.6488
   94.5479
   88.8372
   92.4658
   97.8788
   92.3077
  100.0000
   88.8889
   94.1980
   96.7176
   89.1589
   96.2162
   98.7730
   96.0000
  100.0000


AverageAccuracy =

   90.4893

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
{Operation terminated by user during sdf_core/JHJx_cpd (line 955)


In sdf_core/JHJx (line 679)
        JHJx = model.factorizations{i}.JHJx(i,tmpa,tmpb);

In nls_gndl/JHJx (line 243)
    y = dF.JHJx(z,x);

In mpcg (line 59)
    else r = A(x)-b; end

In nls_gndl (line 376)
                mpcg(@JHJx,-grad,options.CGTol,options.CGMaxIter,dF.PC, ...

In sdf_core (line 335)
[z,output] = options.Algorithm(@objfun,dF,model.variables,options);

In sdf_nls (line 145)
    [sol, output] = sdf_core(model,options{:});

In FactorizeTensor (line 18)
sol = sdf_nls(model);
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06        5-      71  2.4103e+03  7.5555e+01  2.9893e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-07        1-      71  1.3565e+03  7.4026e+01  7.3489e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       74-      71  4.1642e+03  5.5226e+01  1.1056e-05

indexes =

  Columns 1 through 13

   174   168   150   158   104   149   179   182   113    84    38   149    98

  Columns 14 through 26

   111    57    47    72   172    17   111   131    15    26   124    64    24

  Columns 27 through 30

    89    63   141    94

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.3372


Accuracy =

   97.3911


Accuracy =

   97.5744


Accuracy =

   97.2294


Accuracy =

   97.2294


Accuracy =

   97.3696


Accuracy =

   97.1108


Accuracy =

   97.3588


Accuracy =

   97.3911


Accuracy =

   97.2941


Accuracy =9.729409e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   52.3810
   96.9791
   98.5353
   93.9535
   98.4018
   98.6364
   88.4615
  100.0000
  100.0000
   96.5870
   98.1958
   92.1642
   96.2366
   97.7372
   98.8571
  100.0000


AverageAccuracy =

   94.1954

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       14-      57  1.7831e+03  4.4306e+01  9.8068e-05
    1T  9.0e-06       51-      52  1.9586e+03  4.8136e+01  1.5505e-05
    1T  8.1e-06       38-      49  1.3551e+03  3.9335e+01  1.4271e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       35-      54  1.1311e+03  4.4730e+01  1.7621e-05

indexes =

  Columns 1 through 13

   143   199    20   191    90    24   120    99   121    99   132   193     3

  Columns 14 through 26

   158    38   125    14     6   182   163   178    57    90   152   198   113

  Columns 27 through 30

    56   139   142    89

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2019


Accuracy =

   96.2664


Accuracy =

   96.1588


Accuracy =

   96.2879


Accuracy =

   96.3955


Accuracy =

   96.6107


Accuracy =

   96.5892


Accuracy =

   95.8898


Accuracy =

   96.0943


Accuracy =

   96.3740


Accuracy =9.637400e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   67.4419
   97.2222
   95.0928
   97.1963
   91.4943
   98.7934
  100.0000
   98.6175
  100.0000
   97.9522
   96.3113
   86.9888
  100.0000
   99.4774
   95.4416
   98.8235


AverageAccuracy =

   95.0533

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       30-      52  1.0407e+03  3.8880e+01  6.0565e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      58  1.2524e+03  4.5007e+01  8.2434e-06
    1T  6.9e-06        5-      59  2.0866e+03  4.9415e+01  2.4644e-05

indexes =

  Columns 1 through 13

    73    36    95    64   170   117   188    71    72   128     8    95    58

  Columns 14 through 26

   141   145   103    10   181   165   187   167    48     1    18    92    18

  Columns 27 through 30

   150    54   175   162

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1646


Accuracy =

   95.6475


Accuracy =

   95.7445


Accuracy =

   95.7875


Accuracy =

   95.7337


Accuracy =

   95.7660


Accuracy =

   95.9815


Accuracy =

   95.9707


Accuracy =

   95.4320


Accuracy =

   95.7768


Accuracy =9.577677e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   97.7554
   94.1567
   80.4651
   96.1098
   97.5831
   96.1538
   97.9310
  100.0000
   90.7955
   97.8857
   94.4030
   90.8602
   99.0385
   94.2529
   69.4118


AverageAccuracy =

   93.2525

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   124   161   130   117    46   138   172   159    39   106     2    45   122

  Columns 14 through 26

    33    87    67   113    82   186    89   161     2   151   148    17   113

  Columns 27 through 30

   101   101    43   153

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1684


Accuracy =

   96.2763


Accuracy =

   96.3303


Accuracy =

   96.2439


Accuracy =

   95.4021


Accuracy =

   95.8662


Accuracy =

   96.1684


Accuracy =

   96.1468


Accuracy =

   96.0820


Accuracy =

   96.5138


Accuracy =9.651376e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   96.9767
   96.6667
   95.3704
   93.1193
   97.4281
  100.0000
   99.3056
  100.0000
   92.1233
   98.6937
   94.3925
   85.9459
   98.6888
   95.1429
   84.5238


AverageAccuracy =

   95.5236

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       38-      57  2.2828e+03  5.5652e+01  5.6859e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       23-      51  1.4028e+03  4.3054e+01  3.5198e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       39-      49  1.2225e+03  4.7291e+01  1.8473e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       29-      53  1.3063e+03  4.7153e+01  1.1167e-05

indexes =

  Columns 1 through 13

     9   145   163    94    80    93     6    54     4    61    71    32    37

  Columns 14 through 26

   193   123   195   113   159   113   165   140    73    56    15   124    68

  Columns 27 through 30

   179    76    88   163

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2799


Accuracy =

   96.1182


Accuracy =

   96.0319


Accuracy =

   95.7947


Accuracy =

   96.0211


Accuracy =

   96.0858


Accuracy =

   96.0427


Accuracy =

   95.7300


Accuracy =

   96.2152


Accuracy =

   96.0858


Accuracy =9.608583e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   95.1276
   95.9893
   85.0467
   87.6712
   99.2447
  100.0000
  100.0000
  100.0000
   92.1323
   97.6148
   98.7013
   92.9730
   99.4755
   97.9943
   76.1905


AverageAccuracy =

   94.2898

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06        4-      61  3.4515e+03  5.8145e+01  2.1264e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.0e-06       57-      50  1.1669e+03  4.2042e+01  7.4512e-06

indexes =

  Columns 1 through 13

   141    50   119   193   190   146   132   199   132    85   166    30   157

  Columns 14 through 26

   192   142   194    37     6    16    17     6    49    98   133    85    40

  Columns 27 through 30

    56    90    29    27

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0755


Accuracy =

   96.0323


Accuracy =

   96.1509


Accuracy =

   96.0216


Accuracy =

   95.7305


Accuracy =

   96.1078


Accuracy =

   96.4420


Accuracy =

   96.0431


Accuracy =

   95.6765


Accuracy =

   95.8922


Accuracy =9.589218e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   95.1863
   95.6059
   78.6047
   98.6239
   94.1088
   53.8462
  100.0000
   94.4444
   96.7120
   97.2523
   93.8547
   88.1720
   98.5153
   99.7143
   84.5238


AverageAccuracy =

   90.9299

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       44-      59  2.9475e+03  4.2534e+01  1.3199e-05
    1T -5.8e-06       54-      51  1.0060e+03  4.0754e+01  8.3623e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06        5-      59  3.1035e+03  5.4325e+01  5.5318e-06

indexes =

  Columns 1 through 13

   103   115   182    12   178   191     9   159   184    39   127    55    23

  Columns 14 through 26

    51   159    89   134   136   121   111    54   199    37    32   136   160

  Columns 27 through 30

    48    54    23    46

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   94.9871


Accuracy =

   95.3213


Accuracy =

   95.4722


Accuracy =

   95.2242


Accuracy =

   95.6986


Accuracy =

   95.2997


Accuracy =

   95.3644


Accuracy =

   95.5369


Accuracy =

   95.5045


Accuracy =

   94.7068


Accuracy =9.470677e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   93.9488
   87.2510
   87.9070
   95.2055
   99.6965
   96.1538
  100.0000
   72.2222
   88.9898
   97.2997
   95.7090
   91.9355
   97.9039
   92.3077
   83.3333


AverageAccuracy =

   92.1939

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       21-      54  1.4074e+03  3.6159e+01  3.3509e-06

indexes =

  Columns 1 through 13

    86   162   180    96    90    49   122    51    62    67    78    22   134

  Columns 14 through 26

    14   113    49    85     4    78     1    26     5   198   177     3    55

  Columns 27 through 30

    33   196   143   110

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4860


Accuracy =

   95.8639


Accuracy =

   96.2419


Accuracy =

   95.8315


Accuracy =

   95.7559


Accuracy =

   96.1987


Accuracy =

   95.7667


Accuracy =

   96.4039


Accuracy =

   95.9719


Accuracy =

   96.1015


Accuracy =9.610151e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   93.4211
   97.8610
   82.8704
   98.6207
   95.5860
   69.2308
   99.7685
   72.2222
   97.0320
   97.5676
   91.9926
   93.0108
   97.6357
   98.5673
   95.2381


AverageAccuracy =

   92.2414

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       45-      49  1.0020e+03  4.3352e+01  9.7840e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-06       49-      34  1.1412e+03  4.0641e+01  2.1290e-05
    1T -9.5e-06       41-      44  1.2921e+03  4.2844e+01  1.6717e-05

indexes =

  Columns 1 through 13

   196     2   132   163    40   103    80   197    40   111    56    54   154

  Columns 14 through 26

   166   135    88    89   169     9   132    36   102   150    21    49   167

  Columns 27 through 30

   112   172    18    45

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3630


Accuracy =

   96.5573


Accuracy =

   96.2120


Accuracy =

   96.2335


Accuracy =

   96.0501


Accuracy =

   96.4818


Accuracy =

   96.5249


Accuracy =

   96.3630


Accuracy =

   96.2335


Accuracy =

   96.6544


Accuracy =9.665444e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   69.0476
   96.5944
   95.7333
   85.5814
   97.2477
   98.3308
   69.2308
   99.7685
   88.8889
   94.0842
   97.4313
   97.3881
   98.9247
   99.0376
   97.4138
   87.0588


AverageAccuracy =

   91.9851

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       31-      62  2.9005e+03  5.1413e+01  4.1780e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       29-      64  1.2390e+03  5.2926e+01  2.1634e-05
    1T  8.6e-06       39-      50  1.3901e+03  5.0054e+01  3.7979e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       38-      62  2.1359e+03  5.9370e+01  1.4296e-04
    1T  3.7e-06        2-      54  1.1739e+03  3.9052e+01  2.0361e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-07       49-      64  4.1214e+03  5.0877e+01  6.5529e-07

indexes =

  Columns 1 through 13

   112   164    15   163    35    85    34   195   121   128   146    82   164

  Columns 14 through 26

   153   177   165    16   149    58    31   110   113    38   132   108    17

  Columns 27 through 30

   166   161   188   152

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0224


Accuracy =

   95.7098


Accuracy =

   95.9254


Accuracy =

   96.1841


Accuracy =

   95.8607


Accuracy =

   95.5481


Accuracy =

   95.8715


Accuracy =

   96.0440


Accuracy =

   95.9470


Accuracy =

   95.6128


Accuracy =9.561281e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   52.3810
   96.8291
   90.5836
   84.7222
   93.1350
   98.1791
   96.1538
  100.0000
  100.0000
   94.2111
   96.7989
   94.9627
   96.2162
   98.2533
   95.4416
   91.6667


AverageAccuracy =

   92.4709

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       25-      61  2.6480e+03  5.0439e+01  2.4920e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-07       11-      62  9.6365e+02  5.3186e+01  1.3303e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        3-      51  1.4586e+03  3.8942e+01  2.1404e-03

indexes =

  Columns 1 through 13

    79   147    23    22     9   125    82   188    74   103   144    91   129

  Columns 14 through 26

   150   185   157   125   190   192    56   114    46    54    94   118    17

  Columns 27 through 30

   162   114    78   108

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3458


Accuracy =

   96.1087


Accuracy =

   96.5937


Accuracy =

   96.2811


Accuracy =

   96.2164


Accuracy =

   96.3027


Accuracy =

   96.2488


Accuracy =

   96.3242


Accuracy =

   96.2057


Accuracy =

   96.3242


Accuracy =9.632424e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   90.4762
   95.1276
   95.8831
   95.8140
   94.7126
   99.2424
  100.0000
  100.0000
   72.2222
   88.9647
   98.7399
   92.3792
   95.6989
   98.8626
   96.0000
  100.0000


AverageAccuracy =

   94.6327

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      59  2.7268e+03  4.7748e+01  7.0732e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       12-      57  1.6984e+03  4.6465e+01  1.1880e-06
    1T  8.5e-06       41-      63  3.7446e+03  5.7330e+01  7.3455e-06

indexes =

  Columns 1 through 13

    78   186    90   106    12    50    68    60    79    65   200   104    76

  Columns 14 through 26

   154    66   172   196   185   111    28    15    46   128    76   165    45

  Columns 27 through 30

    57    45    31   184

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3186


Accuracy =

   96.5985


Accuracy =

   96.8676


Accuracy =

   96.8353


Accuracy =

   96.3294


Accuracy =

   96.5339


Accuracy =

   96.4693


Accuracy =

   96.4047


Accuracy =

   96.5124


Accuracy =

   96.8030


Accuracy =9.680301e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   97.9954
   96.1487
   87.0968
   97.7117
   98.6405
   92.5926
   99.7696
   83.3333
   91.8089
   98.1540
   92.3650
   92.9730
   99.1266
   97.7143
   95.3488


AverageAccuracy =

   95.0487

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       49-      46  1.3439e+03  4.8333e+01  3.2814e-05

indexes =

  Columns 1 through 13

   158    79   134    29    10    81   141     4   104   186   167    34    43

  Columns 14 through 26

    93    74   175   122    92     3    57   109   141    53    94    44    29

  Columns 27 through 30

   105   158    37   195

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.3581


Accuracy =

   95.5950


Accuracy =

   95.6058


Accuracy =

   95.4227


Accuracy =

   95.5197


Accuracy =

   95.5089


Accuracy =

   95.4012


Accuracy =

   95.4766


Accuracy =

   95.8751


Accuracy =

   95.6166


Accuracy =9.561659e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   76.1905
   95.0541
   92.5631
   84.6512
   96.1276
   96.5257
  100.0000
   99.5402
   50.0000
   87.4715
   99.1430
   94.0520
   98.3784
   99.8258
   99.1429
   71.7647


AverageAccuracy =

   90.0269

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       14-      58  2.3812e+03  5.0172e+01  6.5575e-03
    1T -6.4e-06       58-      54  1.4155e+03  4.9585e+01  1.0192e-05

indexes =

  Columns 1 through 13

    41   124   195    22    64   136   126   153   142    72   162    65    47

  Columns 14 through 26

   133   186     4     3   161    60    27   159     1    20   170    64   100

  Columns 27 through 30

   140    40    43   134

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4487


Accuracy =

   95.1359


Accuracy =

   95.1359


Accuracy =

   95.4918


Accuracy =

   95.2761


Accuracy =

   95.5026


Accuracy =

   95.5349


Accuracy =

   95.0712


Accuracy =

   95.2114


Accuracy =

   95.0388


Accuracy =9.503883e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   66.6667
   96.1330
   90.3872
   84.1860
   94.2529
   97.7307
   96.1538
  100.0000
  100.0000
   83.1435
   98.2914
   94.7664
   88.6486
   99.3881
   99.1404
   95.3488


AverageAccuracy =

   92.7648

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       50-      56  1.4924e+03  4.1245e+01  2.7329e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       14-      58  1.9898e+03  4.5884e+01  2.1726e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       63-      56  1.2184e+03  3.7949e+01  1.7965e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-07       14-      63  2.0062e+03  4.9499e+01  2.8962e-06

indexes =

  Columns 1 through 13

    10    63    62   146    46   130    68   111    50    92   119   197   119

  Columns 14 through 26

   121   173   187    45    86   198   126    25    59   139    27    57    69

  Columns 27 through 30

   161   148    67    86

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9353


Accuracy =

   96.2372


Accuracy =

   96.0323


Accuracy =

   96.2372


Accuracy =

   96.3989


Accuracy =

   96.1294


Accuracy =

   96.1833


Accuracy =

   96.1078


Accuracy =

   95.9677


Accuracy =

   96.4744


Accuracy =9.647439e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   69.0476
   95.8107
   98.5333
   75.7009
   97.9452
   98.1846
   69.2308
  100.0000
   84.2105
   92.4915
   97.7518
   98.1273
   90.9574
   98.9510
   98.2857
   95.2381


AverageAccuracy =

   91.2792

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       49-      61  3.0554e+03  5.6542e+01  1.0328e-05
    1T  6.7e-06       49-      61  3.0554e+03  5.6542e+01  1.0328e-05
    1T  6.7e-06       49-      61  3.0554e+03  5.6542e+01  1.0328e-05
    1T  6.7e-06       49-      61  3.0554e+03  5.6542e+01  1.0328e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       57-      59  2.0387e+03  4.8745e+01  5.4637e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       22-      57  4.3540e+03  4.4563e+01  1.1959e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       22-      57  4.3540e+03  4.4563e+01  1.1959e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       22-      57  4.3540e+03  4.4563e+01  1.1959e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       22-      57  4.3540e+03  4.4563e+01  1.1959e-05
    1T -7.2e-06       24-      57  1.7347e+03  4.9553e+01  1.3121e-05
    1T -5.8e-06       15-      54  1.9011e+03  4.6700e+01  1.2269e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       41-      57  1.5487e+03  5.2759e+01  8.2563e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       37-      52  1.5477e+03  4.3225e+01  1.2320e-05

indexes =

  Columns 1 through 13

   187    57    26   189    75   113   180   189   104    70   155   113   166

  Columns 14 through 26

    78   128    78   161    12   170   157    39    55   111   110    15   171

  Columns 27 through 30

   146   138   126   110

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.4922


Accuracy =

   96.4166


Accuracy =

   96.3519


Accuracy =

   96.1252


Accuracy =

   96.1468


Accuracy =

   96.1360


Accuracy =

   96.1252


Accuracy =

   95.9417


Accuracy =

   96.3950


Accuracy =

   96.4922


Accuracy =9.649217e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

  100.0000
   97.1229
   96.5563
   89.2523
   97.2477
   98.1873
   96.1538
   99.7685
   84.2105
   90.5575
   97.6083
   94.3925
   99.4595
   98.3377
   97.1429
   83.5294


AverageAccuracy =

   94.9704

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-06       49-      56  1.7038e+03  4.1612e+01  1.8547e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       10-      56  1.7791e+03  4.4695e+01  1.8010e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06        9-      61  1.6302e+03  4.1931e+01  5.6283e-03
    1T  3.5e-06        5-      59  1.2450e+03  4.2059e+01  1.4981e-05
    1T -7.4e-06       43-      64  2.4657e+03  5.2074e+01  1.3136e-05
    1T -6.8e-06       45-      54  1.0153e+03  5.1702e+01  2.3502e-05
    1T  8.6e-06       64-      58  1.7592e+03  4.4989e+01  7.3438e-05

indexes =

  Columns 1 through 13

    16   164   153    55     9   108    86   124    61   138   154    43    33

  Columns 14 through 26

   125     8   167    42    27    96   132   170    74    85   125   179    45

  Columns 27 through 30

    13   179    66   196

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.9266


Accuracy =

   97.0128


Accuracy =

   96.9050


Accuracy =

   96.7001


Accuracy =

   96.9589


Accuracy =

   96.9373


Accuracy =

   96.7648


Accuracy =

   96.7540


Accuracy =

   96.9481


Accuracy =

   96.5276


Accuracy =9.652755e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   94.8877
   95.8831
   99.5370
   94.9772
   98.6364
   88.4615
  100.0000
   88.8889
   91.5909
   98.7370
   91.6045
   94.5946
   99.1243
   96.8661
   89.2857


AverageAccuracy =

   95.0434

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       19-      59  1.7701e+03  4.8368e+01  7.8133e-05
    1T -1.0e-06       41-      56  1.2463e+03  4.0170e+01  4.1060e-03
    1T  2.9e-06       47-      45  1.3900e+03  3.7418e+01  5.5768e-03

indexes =

  Columns 1 through 13

    86    43   179    80    32    27   127    27    15   151    88   152     1

  Columns 14 through 26

   103   179    28    41    98   105    10   164   154   147   179    31   146

  Columns 27 through 30

    34    36   186   165

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1973


Accuracy =

   95.7772


Accuracy =

   95.8419


Accuracy =

   96.1327


Accuracy =

   96.2728


Accuracy =

   96.2835


Accuracy =

   96.1219


Accuracy =

   96.2728


Accuracy =

   96.1435


Accuracy =

   96.3589


Accuracy =9.635894e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   76.1905
   95.8237
   94.8000
   88.4793
   92.1839
   98.4894
   92.3077
  100.0000
   77.7778
   92.7520
   98.5599
   94.9907
   91.9355
   99.3881
   96.8391
   95.2941


AverageAccuracy =

   92.8632

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-07       22-      56  2.3767e+03  4.0027e+01  4.7047e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       62-      58  2.8383e+03  4.9399e+01  1.9552e-06

indexes =

  Columns 1 through 13

   108    72    11   107   121    19   115    81    64   182    66   181    33

  Columns 14 through 26

   157   172   150    12    14    46    83   143    92    88   158    67   143

  Columns 27 through 30

    69   148    19   149

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.0043


Accuracy =

   94.4660


Accuracy =

   95.0689


Accuracy =

   95.2842


Accuracy =

   94.8751


Accuracy =

   94.8966


Accuracy =

   94.7567


Accuracy =

   94.8536


Accuracy =

   94.6813


Accuracy =

   95.0689


Accuracy =9.506891e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   71.4286
   95.8430
   92.1543
   96.7442
   96.5831
   93.3333
   96.1538
   99.0741
   77.7778
   86.7882
   99.0995
   91.2801
   96.2162
   99.3019
   90.3409
   69.0476


AverageAccuracy =

   90.6979

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-07       35-      56  3.7120e+03  4.5115e+01  9.5689e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       54-      42  1.5741e+03  4.5410e+01  1.0860e-05
    1T  3.7e-06       15-      56  1.9158e+03  4.7200e+01  2.1011e-05
    1T -3.3e-07       63-      58  1.1166e+03  5.5643e+01  1.9502e-03
    1T  1.8e-06       26-      63  2.6205e+03  5.9284e+01  1.6362e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06        7-      58  1.8454e+03  4.5615e+01  6.9059e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05
    1T  5.2e-06       25-      54  1.6642e+03  4.7453e+01  9.5511e-05

indexes =

  Columns 1 through 13

   182   158    60   149    19   188    99   193   144    73    94   200    33

  Columns 14 through 26

     8    39   116   115    54   171   167   176    94    15   165   139    19

  Columns 27 through 30

   187   149   117    49

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1372


Accuracy =

   96.3746


Accuracy =

   96.0078


Accuracy =

   95.2741


Accuracy =

   95.9430


Accuracy =

   95.8999


Accuracy =

   95.9215


Accuracy =

   96.1804


Accuracy =

   96.2667


Accuracy =

   95.7380


Accuracy =9.573802e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   94.9729
   95.6059
   90.1869
   97.0252
   97.1168
   92.3077
   99.7680
  100.0000
   90.5575
   95.5836
   95.8879
  100.0000
   99.2133
   98.5673
   81.1765


AverageAccuracy =

   94.3076

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=60  ;



pcount=1;

if(train_on_image==1)

rand_num=3000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [2999x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       40-      48  9.2311e+02  3.5117e+01  3.0140e-05
    1T  3.8e-06       52-      59  1.7687e+03  4.3053e+01  9.8204e-06
    1T  4.4e-06       11-      64  1.4421e+03  4.8641e+01  6.1765e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       56-      54  1.5102e+03  3.9573e+01  1.6581e-05

indexes =

  Columns 1 through 13

   186    12   121   164   125    97   150    76    51   127   182   168   140

  Columns 14 through 26

   147   129   102   152    26   184   177    53   124   179   129   191   171

  Columns 27 through 30

    45     7     1    61

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.6217


Accuracy =

   95.9560


Accuracy =

   95.9236


Accuracy =

   96.0099


Accuracy =

   95.6001


Accuracy =

   95.7295


Accuracy =

   95.6325


Accuracy =

   95.2766


Accuracy =

   95.6648


Accuracy =

   95.9021


Accuracy =9.590208e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   86.0465
   94.1176
   90.1333
   81.8605
   97.2665
   98.6405
  100.0000
   99.5370
   83.3333
   95.0913
   97.3447
   93.2710
   96.8085
   99.3001
   99.4253
   94.0476


AverageAccuracy =

   94.1390

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3499x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       59-      64  2.1518e+03  6.9227e+01  3.3947e-06
    1T  2.1e-06        5-      49  1.0671e+03  4.7299e+01  2.5640e-03

indexes =

  Columns 1 through 13

   157    15     8   121   121    11    32   104    10   181    62   107   105

  Columns 14 through 26

   100     6    89   130   134   135    82   190   123    83    20    95   155

  Columns 27 through 30

    62    34    99   198

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0655


Accuracy =

   96.1087


Accuracy =

   96.2596


Accuracy =

   96.0548


Accuracy =

   96.2272


Accuracy =

   96.5183


Accuracy =

   95.7853


Accuracy =

   95.8931


Accuracy =

   96.0224


Accuracy =

   96.2703


Accuracy =9.627035e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   54.7619
   95.7463
   93.7500
   96.2963
   96.5517
   98.3409
   96.1538
  100.0000
   88.8889
   90.2162
   98.7843
   95.7328
   93.0481
   99.3870
   95.9770
   78.5714


AverageAccuracy =

   92.0129

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3499x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.300394s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       42-      55  2.1960e+03  5.7779e+01  1.4538e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       17-      51  2.6598e+03  4.2351e+01  1.2313e-05
    1T  9.8e-07       26-      54  1.4333e+03  4.3853e+01  4.3536e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-07       19-      56  3.1884e+03  4.4561e+01  3.4529e-03

indexes =

  Columns 1 through 13

   172    55    20    99     9    45   112     7    95   116    55    63    48

  Columns 14 through 26

   120     9   106    98    34   196    77   110   147    47    89    54    24

  Columns 27 through 30

   150   194   177   139

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.7633


Accuracy =

   95.8172


Accuracy =

   95.8064


Accuracy =

   95.7417


Accuracy =

   95.9789


Accuracy =

   95.7633


Accuracy =

   95.6339


Accuracy =

   95.8711


Accuracy =

   95.6339


Accuracy =

   96.0004


Accuracy =9.600043e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   66.6667
   94.2813
   97.5968
   98.1308
   96.5831
   96.8182
  100.0000
  100.0000
   72.2222
   91.1162
   97.6180
   93.1099
   89.2473
   97.9860
   99.1404
   92.8571


AverageAccuracy =

   92.7109

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3499x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       64-      44  1.1262e+03  4.6883e+01  1.0174e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-07       24-      60  1.0964e+03  5.8596e+01  2.3575e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       20-      62  9.5014e+02  5.8873e+01  2.9532e-06
    1T -6.9e-07        9-      41  1.3511e+03  5.2081e+01  2.4009e-06
    1T  9.2e-06       14-      53  1.2038e+03  4.5786e+01  2.7298e-05

indexes =

  Columns 1 through 13

   115    38   180    91   132   181    28   157   105   161    22    50    22

  Columns 14 through 26

     6    96   121   124   160   104    97   130   169   139   167    67   117

  Columns 27 through 30

   170   151   156   161

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3131


Accuracy =

   96.1621


Accuracy =

   95.8926


Accuracy =

   95.8711


Accuracy =

   96.2053


Accuracy =

   96.3885


Accuracy =

   95.8603


Accuracy =

   96.3993


Accuracy =

   96.0759


Accuracy =

   95.5261


Accuracy =9.552609e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   91.8020
   94.6595
   91.1628
   97.2665
   94.4193
   92.3077
  100.0000
   77.7778
   97.1526
   97.7948
   90.4673
   90.8602
   97.3776
   94.5559
   97.6190


AverageAccuracy =

   93.7788

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=65;
components=65;
trainingNum=65  ;



pcount=1;

if(train_on_image==1)

rand_num=3500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3499x65]            
C                    [64x65]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       57-      54  9.9001e+02  4.1492e+01  1.2341e-03
    1T  8.5e-06       54-      58  1.7586e+03  4.8369e+01  1.0837e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       10-      64  8.5772e+02  5.7328e+01  4.8959e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       38-      56  1.8011e+03  5.1828e+01  2.6963e-04
    1T  6.1e-06       25-      55  1.3468e+03  5.0879e+01  7.5252e-03
    1T  6.6e-06        1-      52  1.4380e+03  4.4880e+01  3.5704e-05

indexes =

  Columns 1 through 13

    38    81   105   177   125    37   187   104     2   181    93    29   133

  Columns 14 through 26

   112   138    71    21    86     5    96    75   160   176    32    72   140

  Columns 27 through 30

   198    90    48   194

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9021


Accuracy =

   95.7188


Accuracy =

   95.8697


Accuracy =

   96.0099


Accuracy =

   95.6001


Accuracy =

   95.8050


Accuracy =

   96.0207


Accuracy =

   95.6972


Accuracy =

   96.0099


Accuracy =

   95.8589


Accuracy =9.585895e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   64.2857
   95.1125
   92.8000
   95.8140
   94.3052
   97.1168
   57.6923
   98.1777
   94.4444
   92.8328
   96.8426
  100.0000
   86.0963
   98.8626
   99.4253
   94.1176


AverageAccuracy =

   91.1204

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=65;
components=65;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.538261s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       33-      60  3.2682e+03  5.0659e+01  1.5366e-05

indexes =

  Columns 1 through 13

     6    82   173   190   186   162    51    86   125   126    70    51   178

  Columns 14 through 26

    44   129   152    47   192   109    20    71   143     6    14   125    32

  Columns 27 through 30

    97    10    30    24

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.2688


Accuracy =

   95.0860


Accuracy =

   95.3656


Accuracy =

   95.0430


Accuracy =

   95.4839


Accuracy =

   95.3656


Accuracy =

   95.1935


Accuracy =

   95.4301


Accuracy =

   95.5484


Accuracy =

   95.3333


Accuracy =9.533333e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   78.5714
   95.7463
   89.8936
   86.1751
   97.5057
   94.7289
  100.0000
   99.5392
  100.0000
   92.1502
   96.3628
   94.5996
   94.6524
   98.6087
   99.1404
   90.4762


AverageAccuracy =

   94.2594

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=65;
components=65;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x65]             
B                    [3999x65]            
C                    [100x65]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.528628s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06        2-      63  4.0854e+03  6.2573e+01  2.0497e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06        4-      56  1.7910e+03  4.5267e+01  1.4294e-05

indexes =

  Columns 1 through 13

   170    39    45    41   157    41   100   162    85   105    33    93     2

  Columns 14 through 26

   144   121   128     3    91    43   116   114    21   140   166    34    60

  Columns 27 through 30

   163    22    64   140

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.6728


Accuracy =

   96.0710


Accuracy =

   95.9203


Accuracy =

   95.7912


Accuracy =

   95.6943


Accuracy =

   95.3283


Accuracy =

   95.4682


Accuracy =

   95.7158


Accuracy =

   95.7374


Accuracy =

   95.8127


Accuracy =9.581270e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   94.5004
   95.3519
   91.6279
   93.3790
   99.3921
   65.3846
   97.6959
   94.4444
   90.5085
   97.3447
   94.2272
   98.9247
   98.7815
   98.0000
   90.6977


AverageAccuracy =

   92.7246

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=75;
components=75;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [3999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.563284s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       23-      70  2.7118e+03  6.5004e+01  4.8833e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      64  3.2349e+03  6.6235e+01  4.6476e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       20-      60  3.9473e+03  6.1285e+01  8.9863e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       61-      63  2.3530e+03  5.6542e+01  6.6261e-06

indexes =

  Columns 1 through 13

   160    66   150    46   148    19   152   151    13    60   180   197   105

  Columns 14 through 26

    67    86    44   115   162   147   127   107   110    85    64   117   117

  Columns 27 through 30

     2    15   177   115

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8581


Accuracy =

   95.6639


Accuracy =

   95.8257


Accuracy =

   95.8365


Accuracy =

   95.7825


Accuracy =

   95.6423


Accuracy =

   95.7933


Accuracy =

   95.5992


Accuracy =

   95.6208


Accuracy =

   95.7286


Accuracy =9.572862e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   94.3455
   94.9333
   87.9630
   96.3218
   97.8756
   88.4615
   97.9215
   66.6667
   95.5782
   96.4944
   92.7239
   98.3784
   99.6494
   93.3908
   79.7619


AverageAccuracy =

   91.3386

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=75;
components=75;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [3999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.559785s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       35-      66  3.7197e+03  5.6896e+01  2.0456e-05

indexes =

  Columns 1 through 13

    52    48   150    26   169   126   165   200    62    26    58    63   187

  Columns 14 through 26

   140    96   195    38    75    75   171   121    83   125   124    31   111

  Columns 27 through 30

    17   101    20   190

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1949


Accuracy =

   95.9577


Accuracy =

   95.6451


Accuracy =

   95.7314


Accuracy =

   95.8500


Accuracy =

   96.4320


Accuracy =

   96.4213


Accuracy =

   96.0871


Accuracy =

   96.5398


Accuracy =

   96.4536


Accuracy =9.645359e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   96.8340
   96.2667
   91.2442
   93.3941
   96.2064
  100.0000
   98.3759
  100.0000
   97.5057
   96.3481
   95.1493
   96.2366
   99.4760
   93.6782
   90.5882


AverageAccuracy =

   95.1410

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=75;
components=75;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [3999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.550673s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       34-      64  3.4493e+03  5.7032e+01  5.1939e-05
    1T  2.3e-06       68-      73  3.7286e+03  6.4919e+01  8.9922e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-06       29-      62  2.2558e+03  5.6015e+01  7.0314e-06

indexes =

  Columns 1 through 13

   117    83    59    13    46   120   134   177   167   151   114   125   155

  Columns 14 through 26

    17    27    47    70   191    69    69   195     5    84    43    13     2

  Columns 27 through 30

    37   111   179   184

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1862


Accuracy =

   95.7552


Accuracy =

   96.2400


Accuracy =

   96.2939


Accuracy =

   96.1108


Accuracy =

   96.2077


Accuracy =

   95.4212


Accuracy =

   95.9491


Accuracy =

   96.1108


Accuracy =

   96.4771


Accuracy =9.647705e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   94.1267
   97.8723
   93.4884
   99.7701
   97.4242
   92.3077
   99.0762
   83.3333
   94.8689
   95.6385
   96.0821
   95.7219
   99.8258
   99.1453
   82.1429


AverageAccuracy =

   94.6051

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=75;
components=75;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [3999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.534708s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       36-      69  4.8343e+03  5.0362e+01  1.1211e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       40-      62  2.1274e+03  5.7626e+01  9.5575e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       65-      63  2.2191e+03  5.1540e+01  1.4246e-05

indexes =

  Columns 1 through 13

    88   151    52   181   157   158    64     2    37    14    70   145   147

  Columns 14 through 26

    90    60   196   148   132   193    47   199    35   123    52     2   189

  Columns 27 through 30

    76   172    27   172

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1505


Accuracy =

   96.2152


Accuracy =

   96.1937


Accuracy =

   95.5898


Accuracy =

   96.0427


Accuracy =

   96.3123


Accuracy =

   96.0858


Accuracy =

   96.3123


Accuracy =

   96.5495


Accuracy =

   96.0535


Accuracy =9.605348e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   94.9690
   96.6622
   88.4793
   97.5000
   97.7307
   76.9231
   98.3796
   50.0000
   89.6237
   98.3326
   97.7612
   97.2973
   99.3892
   89.4286
   84.5238


AverageAccuracy =

   90.9137

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=75;
components=75;
trainingNum=50  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [3999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.50871s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       66-      66  2.1013e+03  5.7961e+01  3.5451e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       73-      61  2.8017e+03  5.3196e+01  7.2872e-05
    1T  2.2e-07        5-      57  1.5076e+03  4.7682e+01  1.7434e-06

indexes =

  Columns 1 through 13

    67    24     8    47    41   155   111     8   123   142   115    34    84

  Columns 14 through 26

   195    14    20   115   110    28    69   124   156    36   197    70   164

  Columns 27 through 30

    88    89   129   146

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8922


Accuracy =

   95.8814


Accuracy =

   95.3747


Accuracy =

   96.1402


Accuracy =

   95.7305


Accuracy =

   95.6226


Accuracy =

   95.8059


Accuracy =

   95.9137


Accuracy =

   95.7951


Accuracy =

   96.0863


Accuracy =9.608625e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   92.5097
   93.7417
   94.8598
   96.5596
   98.1900
  100.0000
   96.0648
   44.4444
   94.4191
   99.5483
   96.8343
   85.7143
   99.1266
   96.2857
   76.1905


AverageAccuracy =

   90.3401

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=10:10:10
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=4000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [3999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.501039s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-07       24-      69  2.6003e+03  5.5175e+01  7.6747e-07
    1T -1.5e-06       22-      56  1.5973e+03  5.2999e+01  2.0610e-06

indexes =

  Columns 1 through 13

   176    18    92   133     5   145    30   131   128   122   167    28   140

  Columns 14 through 26

    84   143   126    20   131    69    12   175   178   126    68   146    40

  Columns 27 through 30

   105    71   108   191

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1858


Accuracy =

   96.2612


Accuracy =

   96.2289


Accuracy =

   95.8302


Accuracy =

   95.9272


Accuracy =

   96.1534


Accuracy =

   96.2396


Accuracy =

   96.0134


Accuracy =

   95.8517


Accuracy =

   96.0349


Accuracy =9.603491e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   94.4229
   96.3904
   83.2558
   95.8810
   94.3854
   73.0769
  100.0000
  100.0000
   94.1913
   98.8784
   91.4339
  100.0000
   98.4293
   94.8571
   88.3721


AverageAccuracy =

   93.5270

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       58-      66  9.9728e+02  4.2322e+01  2.0982e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.9e-06       46-      63  1.2524e+03  4.3924e+01  3.3665e-05
    1T  6.1e-06       29-      68  1.8948e+03  4.9792e+01  2.8967e-05

indexes =

  Columns 1 through 13

   120    74    59   185    40    80   128   192    33   126   131    74    49

  Columns 14 through 26

   126    89   141   111    63   189   156    81    14    96   149   191     3

  Columns 27 through 30

    82   104    62   182

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3211


Accuracy =

   96.1377


Accuracy =

   96.3534


Accuracy =

   95.5767


Accuracy =

   95.6306


Accuracy =

   96.0298


Accuracy =

   96.2887


Accuracy =

   96.2348


Accuracy =

   95.6090


Accuracy =

   95.4364


Accuracy =9.543640e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   59.5238
   95.4370
   94.9401
   96.7290
   93.8215
   94.0909
  100.0000
   99.3088
   52.6316
   95.3303
   96.5253
   90.2804
   92.9730
   97.0280
   98.0057
  100.0000


AverageAccuracy =

   91.0391

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       50-      57  9.9153e+02  4.6579e+01  5.6824e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06        8-      65  1.3731e+03  5.6120e+01  7.3990e-05
    1T  4.1e-06       34-      63  1.3467e+03  4.3423e+01  3.1665e-05

indexes =

  Columns 1 through 13

    12   108    91    22    15   143    78    67   194   188    14   117   172

  Columns 14 through 26

   136    32    52   151    67    70    42    40    46    61    21    64    96

  Columns 27 through 30

   104   170    15   180

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0431


Accuracy =

   96.7116


Accuracy =

   96.3450


Accuracy =

   96.0431


Accuracy =

   96.0108


Accuracy =

   96.0216


Accuracy =

   96.1402


Accuracy =

   95.9569


Accuracy =

   95.8167


Accuracy =

   96.3666


Accuracy =9.636658e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   47.6190
   97.4478
   96.0106
   85.7143
   89.4495
   98.3283
  100.0000
  100.0000
   88.8889
   92.8246
   98.2425
   97.0205
   98.9247
   97.9930
   95.4416
   96.4286


AverageAccuracy =

   92.5209

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'indian_pines' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       34-      70  2.8306e+03  5.1463e+01  2.1209e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-07       55-      65  1.8937e+03  5.0240e+01  1.5018e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       43-      69  3.1182e+03  4.7361e+01  1.8967e-05
    1T  7.1e-06       73-      63  1.4031e+03  4.3934e+01  6.2939e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-07       45-      68  1.4727e+03  5.9678e+01  1.8292e-06

indexes =

  Columns 1 through 13

   166   177    62    93   194   176    44    55   187   146   185   116   153

  Columns 14 through 26

    77   180   141   137    90   144    90   198   182   160   198    59   131

  Columns 27 through 30

    44   163   102    60

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.7754


Accuracy =

   96.0125


Accuracy =

   95.4629


Accuracy =

   95.7970


Accuracy =

   95.5491


Accuracy =

   95.8293


Accuracy =

   95.9802


Accuracy =

   95.9155


Accuracy =

   95.9263


Accuracy =

   95.7646


Accuracy =9.576463e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   85.7143
   94.0495
   98.6631
   74.2991
   96.3636
   98.9410
   73.0769
   99.5370
  100.0000
   89.6708
   99.5050
   88.2900
   93.0481
   98.0736
   98.5714
   90.4762


AverageAccuracy =

   92.3925

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-07       19-      69  5.9901e+02  1.9025e+01  2.6293e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       68-      64  8.8094e+02  1.7341e+01  2.2802e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       13-      68  3.6298e+02  2.0669e+01  4.3067e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.0e-06        7-      54  6.3078e+02  3.8523e+01  1.1747e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       60-      64  1.9678e+02  1.9486e+01  5.1076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       52-      71  4.5465e+02  2.7812e+01  3.9212e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        3-      70  2.3030e+02  2.3246e+01  1.5905e-06
    1T  8.8e-06       20-      72  2.7301e+02  2.3752e+01  1.0195e-03
    1T -9.1e-06       62-      67  3.5340e+02  1.9946e+01  2.5330e-03
    1T  6.5e-06       40-      61  1.8564e+02  2.3714e+01  2.4210e-03
    1T -7.0e-06       15-      64  7.8769e+02  2.4395e+01  2.6001e-03
    1T  1.9e-06       28-      67  2.6592e+02  2.2535e+01  1.5670e-05
    1T  2.4e-06       71-      66  2.4989e+02  2.1793e+01  1.4508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-06        1-      55  2.6092e+02  2.0228e+01  6.5600e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       39-      66  1.9218e+02  2.3091e+01  2.7367e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       14-      53  2.6936e+02  1.8882e+01  4.8565e-06
    1T  1.6e-07       71-      65  4.9231e+02  1.7889e+01  3.9023e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-07       37-      66  2.2941e+02  2.3025e+01  1.7328e-07

indexes =

  Columns 1 through 13

   197    73    38   150    92    63   140   144    20    55   199   154   200

  Columns 14 through 26

    97   152   158   154    39   190    66   174    70   111    12    71   152

  Columns 27 through 30

    57    43   114    31


Accuracy =

   97.7196


Accuracy =

   97.7041


Accuracy =

   97.7351


Accuracy =

   97.8306


Accuracy =

   97.8100


Accuracy =

   97.7971


Accuracy =

   97.7764


Accuracy =

   97.6318


Accuracy =

   97.8487


Accuracy =

   97.8229


Accuracy =9.782289e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.8994
  100.0000
   86.9016
   95.7163
   98.4413
   98.9895
   96.5890
   93.6937
   89.1482


AverageAccuracy =

   95.3755

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       65-      66  1.1868e+03  3.1605e+01  9.5147e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       11-      66  8.2757e+02  2.4720e+01  1.1646e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06        6-      60  2.0443e+02  1.8863e+01  2.3719e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-07       26-      59  7.9948e+02  2.9362e+01  9.7834e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       43-      68  2.9738e+02  2.3831e+01  1.5091e-04
    1T  5.9e-06       45-      58  1.3994e+03  2.7323e+01  2.8244e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       31-      64  1.5303e+02  1.9384e+01  3.1650e-04
    1T -1.2e-06       37-      64  2.9452e+02  1.7156e+01  5.5836e-04
    1T -2.4e-06       32-      67  6.1976e+02  3.4063e+01  3.2032e-03
    1T  5.8e-06       69-      62  8.9299e+02  3.0086e+01  3.0758e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       59-      66  4.7300e+02  1.9413e+01  1.1843e-03
    1T  8.7e-07       54-      63  2.4012e+02  1.8169e+01  1.2950e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-07       42-      62  2.3496e+02  2.1491e+01  3.0670e-03
    1T  7.5e-06       47-      64  4.2542e+02  2.2238e+01  4.1032e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       22-      67  3.7289e+02  2.2673e+01  4.1844e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       32-      63  2.5476e+02  2.4320e+01  1.7094e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-07       37-      64  2.1827e+02  2.0480e+01  5.2085e-04
    1T  7.9e-06       29-      62  3.9870e+02  2.2518e+01  4.8228e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03
    1T  6.4e-06       71-      67  1.7513e+02  2.4680e+01  1.9399e-04
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        4-      66  2.5304e+02  2.5983e+01  4.2149e-03

indexes =

  Columns 1 through 13

   151    99    70   194    97    77    16    45    39   199   105   188   194

  Columns 14 through 26

    93   197   142   154     4   129   179    71    90   172    57   168    55

  Columns 27 through 30

    54    52    46     7


Accuracy =

   97.8544


Accuracy =

   98.0454


Accuracy =

   97.7382


Accuracy =

   97.9370


Accuracy =

   97.8621


Accuracy =

   97.8905


Accuracy =

   97.7537


Accuracy =

   97.7950


Accuracy =

   97.9086


Accuracy =

   97.8621


Accuracy =9.786212e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.9187
   99.9171
   88.1703
   96.0317
   98.4375
   98.8789
   96.2594
   94.9716
   91.7249


AverageAccuracy =

   95.8122

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       52-      69  4.6871e+02  2.6833e+01  1.1689e-06
    1T  7.0e-06       52-      69  4.6871e+02  2.6833e+01  1.1689e-06
    1T  7.0e-06       52-      69  4.6871e+02  2.6833e+01  1.1689e-06
    1T  7.0e-06       52-      69  4.6871e+02  2.6833e+01  1.1689e-06
    1T  8.0e-06       26-      61  8.5333e+02  2.8700e+01  2.8385e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       14-      63  7.5899e+02  2.5020e+01  2.9605e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       66-      65  5.9324e+02  2.2538e+01  2.0024e-06
    1T  6.6e-06       30-      70  4.2113e+02  2.8007e+01  1.5619e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       50-      65  3.7226e+02  2.3977e+01  3.9879e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       24-      61  3.5989e+02  2.5083e+01  2.2831e-04
    1T -1.6e-06       36-      63  2.4435e+02  2.3568e+01  3.5340e-03
    1T -8.9e-06       54-      67  2.9032e+02  3.8590e+01  1.3226e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       45-      62  6.1760e+02  2.3996e+01  2.8137e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       38-      69  1.3866e+02  2.6468e+01  3.8077e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-06       15-      66  2.7523e+02  2.2881e+01  3.1954e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       42-      64  3.5723e+02  2.4617e+01  2.8179e-03
    1T -8.0e-06       22-      64  8.0949e+02  2.8304e+01  1.5311e-03
    1T -7.2e-07       35-      54  2.8628e+03  5.0345e+01  3.3760e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       35-      65  2.3899e+02  3.1208e+01  3.2038e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       22-      67  1.8974e+02  2.5904e+01  4.1457e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       58-      61  4.0263e+02  2.2757e+01  4.3300e-06
    1T  6.6e-06       23-      61  1.9735e+02  2.3369e+01  4.1691e-03
    1T -6.7e-06       53-      68  4.5348e+02  2.2345e+01  3.0994e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       29-      64  2.4158e+02  2.3387e+01  1.3501e-06

indexes =

  Columns 1 through 13

    34   160    15    14   180    14   156   155     4   105    61     6    63

  Columns 14 through 26

   181    96   200     5    91    70   101   136    68   189   186   140   154

  Columns 27 through 30

   149   183   157   119


Accuracy =

   97.8436


Accuracy =

   97.9082


Accuracy =

   97.8333


Accuracy =

   97.9159


Accuracy =

   97.8798


Accuracy =

   97.9237


Accuracy =

   97.8307


Accuracy =

   97.9598


Accuracy =

   97.8901


Accuracy =

   97.8591


Accuracy =9.785910e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.6331
   99.9763
   89.0584
   94.4464
  100.0000
   99.2979
   97.7556
   92.2175
   92.6829


AverageAccuracy =

   96.0076

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       73-      66  4.7997e+02  2.1905e+01  1.6883e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       70-      64  1.4776e+02  2.5087e+01  9.3629e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       42-      59  1.1206e+03  2.7250e+01  1.5268e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       46-      64  2.9332e+02  1.8204e+01  9.5566e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-07       22-      65  2.5682e+02  2.0503e+01  2.4982e-03
    1T  2.0e-06       27-      61  3.0931e+02  2.3355e+01  1.5361e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       14-      66  2.8195e+02  2.7384e+01  5.2171e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       66-      48  1.4712e+02  1.9367e+01  3.1594e-06
    1T  7.0e-07       54-      49  3.0789e+02  2.3561e+01  7.3834e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.5e-06       38-      66  2.9918e+02  2.4512e+01  3.1598e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       71-      65  2.3165e+02  2.0672e+01  5.3954e-07
    1T  3.2e-06       48-      63  4.2336e+02  2.9129e+01  2.0325e-04
    1T  2.4e-06       17-      63  3.8202e+02  2.2247e+01  1.9387e-03
    1T  5.8e-06       21-      64  3.4641e+02  2.0457e+01  1.2644e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       24-      65  3.0813e+02  2.6873e+01  1.5275e-06
    1T -5.6e-06       72-      63  2.3303e+02  2.0880e+01  4.0333e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       29-      63  2.1753e+02  2.6432e+01  5.5673e-07
    1T  6.8e-06       16-      63  3.1479e+02  2.3109e+01  3.7214e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       33-      65  1.5983e+02  2.6506e+01  2.4076e-03
    1T  9.8e-06       45-      65  4.4284e+02  2.6912e+01  5.2538e-06

indexes =

  Columns 1 through 13

    85   128   121   181   131    40    78   100   187    83   103    82    85

  Columns 14 through 26

   164   134   180    93    40    67    53   132    62    78    43   176    58

  Columns 27 through 30

   101    29   165   122


Accuracy =

   97.7371


Accuracy =

   97.7759


Accuracy =

   97.7139


Accuracy =

   97.7010


Accuracy =

   97.8017


Accuracy =

   97.7294


Accuracy =

   97.7707


Accuracy =

   97.7707


Accuracy =

   97.6751


Accuracy =

   97.7526


Accuracy =9.775263e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.2161
   99.8045
   89.3931
   94.9910
   98.3539
   98.7258
   96.7688
   93.7013
   92.6316


AverageAccuracy =

   95.8429

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       35-      63  5.0998e+02  2.7637e+01  4.3269e-06
    1T  2.3e-06       59-      61  1.8273e+02  3.0189e+01  8.3831e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06       43-      61  2.3604e+02  2.3466e+01  2.7212e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       18-      61  6.3882e+02  2.6306e+01  4.7946e-06
    1T  4.6e-07       52-      62  6.2753e+02  4.9334e+01  3.1067e-06
    1T  1.2e-06       37-      64  1.6175e+02  2.3013e+01  2.8556e-03
    1T  5.4e-06       58-      60  1.9061e+02  2.5220e+01  3.7511e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       31-      69  1.6870e+02  3.4833e+01  1.9331e-03
    1T -9.5e-06       41-      60  3.7960e+02  2.4176e+01  2.7656e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       27-      64  4.1309e+02  2.9012e+01  1.3246e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-07       29-      62  3.3563e+02  2.9064e+01  4.8737e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        7-      68  2.4811e+02  2.9365e+01  1.5227e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06        2-      56  2.3324e+02  3.3379e+01  5.4918e-07
    1T  2.3e-06       24-      65  1.8762e+02  2.6388e+01  6.3481e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       43-      68  2.6831e+02  2.7680e+01  7.0528e-07
    1T -7.6e-06       18-      68  5.0493e+02  2.8304e+01  1.7455e-03
    1T -8.5e-06       11-      68  2.8547e+02  2.5647e+01  2.9503e-03

indexes =

  Columns 1 through 13

   105    37    66   189    12   174   108    36   190   156   196   143    46

  Columns 14 through 26

    36    10    78    86     3    52    26   200   141   162    84   181   154

  Columns 27 through 30

   101    24     5   187


Accuracy =

   98.0105


Accuracy =

   98.0415


Accuracy =

   98.0157


Accuracy =

   97.9666


Accuracy =

   98.0906


Accuracy =

   98.1139


Accuracy =

   98.0829


Accuracy =

   98.0415


Accuracy =

   97.9537


Accuracy =

   98.0415


Accuracy =9.804155e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.6660
   99.9822
   87.6777
   95.8573
   97.9458
   99.6046
   94.4306
   95.3999
   92.6402


AverageAccuracy =

   95.8005

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       11-      65  1.1163e+03  2.2168e+01  8.0910e-04
    1T  2.8e-06       16-      63  2.1942e+02  2.2157e+01  2.5944e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       52-      60  1.4359e+03  2.2681e+01  2.0784e-03
    1T  9.8e-06       46-      67  4.7900e+02  4.6979e+01  1.7152e-04
    1T -9.6e-06       73-      67  2.9590e+02  2.2060e+01  3.3807e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       44-      64  1.6387e+02  2.9431e+01  1.3785e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       73-      62  1.2702e+03  2.6817e+01  2.6521e-03
    1T -5.1e-06       67-      55  1.5778e+02  2.6412e+01  1.1118e-03
    1T -9.2e-06       42-      66  3.2147e+02  2.8697e+01  1.1881e-03
    1T  4.4e-06       47-      66  5.8397e+02  2.8079e+01  2.4196e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       17-      61  3.7086e+02  2.3641e+01  7.0454e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       39-      69  7.4465e+02  2.8359e+01  8.8746e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       53-      62  3.2463e+02  2.6807e+01  7.0342e-05
    1T  3.4e-06       66-      66  1.9180e+02  2.3318e+01  1.4900e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       29-      66  2.6342e+02  2.5237e+01  1.1667e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       27-      58  2.5610e+02  2.3966e+01  1.1626e-06
    1T  9.6e-06       31-      62  3.9742e+02  2.7271e+01  2.1176e-06
    1T  2.1e-06       38-      68  1.9605e+02  2.6584e+01  1.7544e-07

indexes =

  Columns 1 through 13

   123    75    23    64    98    52    71    50   127   159    77   166    13

  Columns 14 through 26

   101   155   144   152   104   135   129    24   196   199   112   115   198

  Columns 27 through 30

    64    20    78   131


Accuracy =

   98.3694


Accuracy =

   98.1291


Accuracy =

   98.2273


Accuracy =

   98.2583


Accuracy =

   98.2764


Accuracy =

   98.0206


Accuracy =

   98.2144


Accuracy =

   98.2661


Accuracy =

   98.0878


Accuracy =

   98.3436


Accuracy =9.834358e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.9165
   99.9348
   90.3785
   95.5957
   99.4239
   99.6924
   97.6686
   95.4286
   93.0913


AverageAccuracy =

   96.6811

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       75-      62  2.0568e+02  3.1224e+01  1.5913e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06        5-      64  2.5477e+02  2.2903e+01  8.0876e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       31-      67  2.0332e+02  2.6557e+01  1.9155e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       35-      60  3.3564e+02  2.4187e+01  1.4250e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       51-      62  2.2486e+02  2.4705e+01  5.1156e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       32-      61  9.1756e+02  3.7117e+01  1.8902e-06
    1T -1.5e-06       14-      66  4.0528e+02  2.7276e+01  1.8530e-03
    1T  8.7e-06       30-      62  2.8449e+02  2.4547e+01  6.2937e-07
    1T  5.2e-06       47-      66  5.0959e+02  2.7032e+01  1.2649e-06
    1T  3.7e-06       62-      68  9.0397e+02  3.4980e+01  2.0961e-03
    1T  2.3e-07       41-      66  1.0792e+03  4.0727e+01  1.3002e-03
    1T  5.0e-06       25-      68  1.9992e+02  2.8497e+01  3.6654e-03
    1T -6.3e-06       31-      60  1.1326e+03  2.8265e+01  1.2808e-03
    1T  5.7e-06       29-      66  1.9351e+02  2.9782e+01  1.2909e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       29-      66  3.4421e+02  2.1888e+01  2.6658e-03
    1T  7.5e-06        3-      65  1.7016e+02  3.9148e+01  1.1136e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.0e-06       49-      62  1.1404e+03  2.9724e+01  1.6203e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       42-      65  5.5948e+02  2.8059e+01  1.4989e-06
    1T -9.8e-07       39-      66  7.8049e+02  2.8758e+01  3.8087e-03
{Operation terminated by user during distcomp.remoteparfor/getCompleteIntervals
(line 225)


In parallel_function>distributed_execution (line 823)
        [tags, out] = P.getCompleteIntervals(chunkSize);

In parallel_function (line 590)
        R = distributed_execution(...

In create_centered_features_bands (line 5)
parfor i=1:rows
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06        1-      56  1.4923e+02  2.3500e+01  1.7000e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       33-      61  3.1584e+02  2.1421e+01  2.9824e-03
    1T -2.5e-06       36-      64  3.3359e+02  2.6981e+01  1.5313e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.4e-06       23-      65  1.1048e+03  2.5663e+01  2.8923e-03
    1T  4.6e-06       63-      61  2.5452e+02  2.8254e+01  4.8535e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       22-      60  1.3107e+03  2.6581e+01  2.5830e-06
    1T  4.8e-06       64-      66  2.9247e+02  2.4869e+01  1.2555e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       34-      67  1.9068e+02  3.2741e+01  5.1209e-07
    1T  3.8e-06       31-      67  4.8719e+02  2.6783e+01  1.7385e-03
    1T  1.6e-06       30-      66  1.5212e+02  4.2543e+01  1.7068e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       15-      65  1.9550e+02  3.3656e+01  1.8913e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       22-      67  2.0809e+02  3.1903e+01  1.2047e-06
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06        9-      68  5.6250e+02  3.2906e+01  4.1157e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03
    1T -3.5e-06       31-      66  3.4557e+02  2.7698e+01  3.2426e-03

indexes =

  Columns 1 through 13

    28    62   188    69    79   145    68    46    35    73   146   142    82

  Columns 14 through 26

    49   136    70   179   123    76    98    21    87   197    63   136    25

  Columns 27 through 30

    45   118    30     4


Accuracy =

   98.0111


Accuracy =

   98.0885


Accuracy =

   97.9801


Accuracy =

   97.7941


Accuracy =

   97.8974


Accuracy =

   97.9361


Accuracy =

   98.0266


Accuracy =

   97.8380


Accuracy =

   97.8277


Accuracy =

   97.9077


Accuracy =9.790773e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.8461
   99.9526
   89.8634
   95.4890
   98.9309
   99.3194
   97.6783
   93.4874
   92.3256


AverageAccuracy =

   96.0992

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       29-      67  7.3768e+02  1.9945e+01  1.6990e-07
    1T  4.4e-07       51-      66  3.2265e+02  2.3110e+01  4.7754e-08
    1T  7.3e-06       30-      54  9.4647e+02  2.2754e+01  8.6881e-06
    1T -6.1e-06       67-      65  2.2198e+02  1.9911e+01  3.2168e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       10-      61  8.6262e+02  2.1468e+01  2.2360e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       19-      62  2.9398e+02  2.0600e+01  8.6999e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       25-      63  2.0034e+02  1.9585e+01  1.6389e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       34-      63  1.7896e+02  2.3339e+01  1.7767e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       46-      60  3.4707e+02  2.0945e+01  2.8894e-03
    1T  6.9e-07        1-      64  3.6738e+02  2.0705e+01  2.1301e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-07        1-      64  3.6738e+02  2.0705e+01  2.1301e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-07        1-      64  3.6738e+02  2.0705e+01  2.1301e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-07        1-      64  3.6738e+02  2.0705e+01  2.1301e-07
    1T  6.2e-06       23-      65  4.5736e+02  2.6785e+01  1.0770e-06
    1T  9.2e-06       20-      62  1.1178e+03  3.2341e+01  4.1131e-06
    1T  1.8e-06       14-      65  1.8370e+02  2.4569e+01  1.0227e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06        9-      68  4.8806e+02  2.8503e+01  8.2722e-06
    1T -9.8e-06       69-      67  2.8778e+02  2.5046e+01  2.0422e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       46-      57  3.6573e+02  2.3135e+01  2.3459e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       47-      61  1.5484e+03  2.1145e+01  4.6288e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       23-      66  4.7102e+02  2.8029e+01  1.9807e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       45-      59  3.2048e+02  2.1619e+01  1.9621e-06
    1T  5.3e-06       70-      58  4.4092e+02  2.3999e+01  8.8006e-06
    1T  3.5e-06       71-      64  6.0017e+02  2.1830e+01  8.8401e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       16-      61  1.8875e+02  2.7208e+01  6.6366e-07
    1T -6.5e-06       75-      65  5.5934e+02  2.3164e+01  1.2211e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       45-      64  2.2886e+02  3.0773e+01  6.2112e-07
    1T -8.0e-06       64-      59  1.4979e+02  3.1478e+01  8.0786e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        1-      62  1.8060e+02  2.6565e+01  2.5740e-03

indexes =

  Columns 1 through 13

    52    10   107   155   125    36   130    36   169    55    16    75    91

  Columns 14 through 26

    44   105    28    96   140    49     2   185    10    40   171   109   134

  Columns 27 through 30

    44    60    25   200


Accuracy =

   97.5748


Accuracy =

   97.5877


Accuracy =

   97.5567


Accuracy =

   97.5619


Accuracy =

   97.4921


Accuracy =

   97.5877


Accuracy =

   97.5309


Accuracy =

   97.5954


Accuracy =

   97.6600


Accuracy =

   97.6548


Accuracy =9.765484e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.7848
   99.9941
   87.3551
   96.3564
   99.5078
   98.9888
   95.3488
   91.7566
   94.1793


AverageAccuracy =

   95.6969

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       22-      64  2.1692e+02  2.5613e+01  6.6150e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06        3-      54  8.1598e+02  1.7336e+01  2.7288e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       42-      57  1.0709e+03  3.3959e+01  1.6875e-06
    1T  3.4e-07       44-      65  3.4043e+02  2.3005e+01  5.9727e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       12-      67  1.3936e+02  2.5780e+01  1.5337e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       19-      67  4.1963e+02  2.4818e+01  2.1923e-03
    1T -5.5e-07       12-      60  1.9092e+02  2.5481e+01  2.1989e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       73-      64  1.8947e+02  2.3634e+01  2.3139e-03
    1T  1.3e-06        1-      61  2.2826e+02  2.3906e+01  4.1405e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-07       45-      63  1.6982e+02  2.3360e+01  1.7063e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       25-      66  6.2398e+02  3.3772e+01  8.5099e-04
    1T  9.4e-06       52-      61  1.3740e+02  3.2267e+01  2.2466e-06
    1T -8.8e-06        8-      68  3.2050e+02  2.4736e+01  3.6529e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       44-      67  2.6699e+02  2.4718e+01  9.5981e-07
    1T  3.8e-06       44-      65  2.0358e+02  2.4756e+01  2.6307e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       47-      66  2.0879e+02  2.5796e+01  4.6147e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       39-      63  4.8075e+02  2.2929e+01  1.0065e-03
    1T -2.7e-06       47-      60  1.5929e+02  2.1650e+01  3.9547e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      63  7.8556e+02  2.4377e+01  1.6421e-03
    1T  4.9e-06       20-      62  3.6812e+02  2.2416e+01  6.2053e-07

indexes =

  Columns 1 through 13

    45    19   120    86    61   188    18    35   148    33    45    69   176

  Columns 14 through 26

    62    94     9   120   115   153   176    18    55   163    22    31    96

  Columns 27 through 30

   157    33    18   167


Accuracy =

   97.5409


Accuracy =

   97.5642


Accuracy =

   97.5151


Accuracy =

   97.5254


Accuracy =

   97.5797


Accuracy =

   97.6237


Accuracy =

   97.5021


Accuracy =

   97.4375


Accuracy =

   97.4375


Accuracy =

   97.6263


Accuracy =9.762625e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.3642
   99.8279
   88.3096
   95.6004
   98.4413
   98.4808
   95.1867
   93.2773
   91.0256


AverageAccuracy =

   95.3905

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       18-      61  3.1086e+02  2.3810e+01  1.3567e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       68-      67  4.5427e+02  2.9378e+01  3.2042e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       65-      67  3.9077e+02  3.0175e+01  5.0251e-06
    1T  2.8e-06       66-      66  3.4074e+02  2.4678e+01  7.9543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06        2-      63  1.6048e+02  2.5715e+01  2.2641e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       32-      63  3.4728e+02  3.5401e+01  2.1938e-03
    1T  8.4e-06       29-      67  4.3288e+02  2.4423e+01  6.0025e-06
    1T -8.7e-06       72-      61  1.7411e+02  2.2847e+01  1.9978e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       54-      62  2.3744e+02  2.7010e+01  2.5542e-04
    1T  9.1e-06       33-      66  5.1700e+02  3.3987e+01  2.5076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       51-      68  2.6122e+02  2.9861e+01  6.9448e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       17-      63  2.7048e+02  2.6171e+01  2.2120e-06
    1T  8.2e-06       53-      45  3.7253e+02  2.3733e+01  3.4758e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-08       38-      49  2.3945e+02  2.5634e+01  5.8813e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       73-      63  2.3644e+02  2.5265e+01  2.3852e-03
    1T  8.8e-07       69-      67  5.7098e+02  2.6383e+01  3.6510e-03

indexes =

  Columns 1 through 13

    51    24   120   117   178    74    34   185   165   187    85   198   111

  Columns 14 through 26

    16   137    60   152    20    90   121    35   154     5   124    74   101

  Columns 27 through 30

   108   182    44   196


Accuracy =

   97.9827


Accuracy =

   97.8716


Accuracy =

   97.8510


Accuracy =

   97.8510


Accuracy =

   97.9439


Accuracy =

   97.8768


Accuracy =

   97.9233


Accuracy =

   97.9930


Accuracy =

   97.9414


Accuracy =

   97.8768


Accuracy =9.787679e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   98.2845
   99.8934
   89.2688
   95.4496
   98.6842
   99.4943
   97.3422
   93.1231
   91.7056


AverageAccuracy =

   95.9162

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       10-      66  3.7714e+02  2.9697e+01  2.3844e-03
    1T  7.3e-06       10-      51  1.1165e+03  4.2916e+01  5.1824e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06        9-      66  4.5049e+02  2.7115e+01  1.7210e-03
    1T  8.7e-06       59-      58  2.4969e+02  2.2826e+01  5.6333e-06
    1T  7.9e-06       68-      65  2.5639e+02  2.7608e+01  1.9991e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       16-      69  9.4965e+02  2.5790e+01  1.2987e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       58-      64  3.5045e+02  2.1963e+01  9.8147e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       24-      69  6.0684e+02  2.9907e+01  1.0627e-03
    1T -8.0e-06       28-      63  1.7535e+02  2.5417e+01  2.1011e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        7-      62  3.7086e+02  2.6820e+01  4.9238e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06        7-      60  1.5295e+02  3.2774e+01  4.7080e-04
    1T  7.1e-06       65-      59  2.5728e+02  2.3864e+01  3.7473e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06        2-      61  3.3840e+02  2.3984e+01  4.1180e-03
    1T  3.1e-08       67-      62  2.0573e+02  2.7354e+01  1.1112e-08
    1T  1.9e-06       43-      68  2.0573e+02  2.8403e+01  3.8452e-03
    1T  1.5e-06       34-      67  1.6379e+02  2.6040e+01  4.0215e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        1-      69  4.8995e+02  2.6669e+01  2.1805e-03
    1T -2.1e-06       51-      67  4.3289e+02  2.6033e+01  8.7096e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       50-      67  1.7223e+02  3.3002e+01  5.4564e-07

indexes =

  Columns 1 through 13

    13   107   158    46   153   173    22    68   133   193   167    70    68

  Columns 14 through 26

    67   136   149   166   110   151    56   167    67   113    85     4   191

  Columns 27 through 30

   143   196   152   178


Accuracy =

   97.7317


Accuracy =

   97.7007


Accuracy =

   97.6930


Accuracy =

   97.6801


Accuracy =

   97.6542


Accuracy =

   97.7498


Accuracy =

   97.7317


Accuracy =

   97.7240


Accuracy =

   97.7162


Accuracy =

   97.6930


Accuracy =9.769298e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.4679
   99.9348
   85.9548
   96.2135
   99.2611
   99.4939
   96.0100
   92.7519
   95.6826


AverageAccuracy =

   95.8634

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       60-      64  5.0475e+02  2.6154e+01  3.1491e-06
    1T -2.3e-08       42-      62  4.5507e+02  2.4516e+01  3.8493e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       48-      66  3.3423e+02  2.2879e+01  6.5907e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       49-      67  6.4067e+02  2.8333e+01  2.9610e-03
    1T -6.5e-06       21-      62  9.4595e+02  3.2694e+01  8.8558e-04
    1T  9.0e-06       12-      62  3.0545e+02  2.7608e+01  4.4330e-06
    1T  2.8e-06        7-      67  2.5053e+02  2.8344e+01  2.7178e-06
    1T  8.3e-07       63-      60  4.7777e+02  3.1840e+01  3.0000e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       53-      68  9.4349e+02  2.6524e+01  1.6950e-03
{Operation terminated by user during distcomp.remoteparfor/getCompleteIntervals
(line 225)


In parallel_function>distributed_execution (line 823)
        [tags, out] = P.getCompleteIntervals(chunkSize);

In parallel_function (line 590)
        R = distributed_execution(...

In create_centered_features_bands (line 5)
parfor i=1:rows
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       63-      35  3.5284e+02  6.9900e+01  7.8964e-03
    1T  5.3e-06       32-      57  2.1473e+02  2.8237e+01  2.5785e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       51-      64  5.2948e+02  3.6524e+01  2.1081e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        6-      20  2.3601e+02  4.3733e+01  1.9070e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       51-      62  2.1588e+02  3.1215e+01  1.6503e-05
    1T  1.1e-06       31-      67  5.7644e+02  3.1272e+01  4.3118e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.7e-06       33-      54  2.4660e+02  3.3874e+01  1.6592e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-08       41-      60  2.8509e+02  3.0507e+01  8.6011e-03
    1T -8.4e-06        8-      63  5.3748e+02  3.1545e+01  4.4509e-03
    1T  4.8e-06        5-      65  3.1842e+02  4.8085e+01  2.2140e-06
    1T -9.4e-06       62-      55  3.1167e+02  3.8067e+01  4.0862e-03
    1T  1.0e-05       40-      51  3.5726e+02  3.9970e+01  4.7592e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06        1-      56  2.8547e+02  5.5814e+01  3.2503e-06
    1T  8.6e-06       23-      62  8.5353e+02  4.2875e+01  7.7384e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       62-      53  2.9549e+02  3.9371e+01  2.1002e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06        4-      45  4.4107e+02  4.8184e+01  4.5259e-06
    1T  7.9e-06        4-      59  2.3393e+02  3.8842e+01  3.1001e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       50-      63  6.0488e+02  4.1299e+01  7.6094e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-07       50-      54  1.8861e+02  3.8087e+01  2.8442e-03
    1T  8.6e-06       29-      61  2.0830e+02  3.9237e+01  3.5020e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       41-      59  2.4397e+02  3.8016e+01  3.8463e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       28-      57  2.0329e+02  4.0935e+01  7.0682e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       30-      50  2.0939e+02  3.5317e+01  3.6736e-03
    1T  6.7e-06       10-      63  2.8127e+02  3.9067e+01  8.4208e-06
    1T -9.1e-06       31-      55  2.7079e+02  3.3328e+01  1.0555e-03
    1T  5.9e-06        6-      65  2.4987e+02  4.0619e+01  2.2201e-03
    1T -4.1e-06        1-      56  2.1768e+02  3.7011e+01  2.3490e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       54-      57  1.8501e+02  3.8444e+01  1.9763e-03
    1T -8.0e-06       73-      53  2.1220e+02  3.6055e+01  4.0043e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-07       26-      65  2.8320e+02  3.9155e+01  1.4305e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       59-      52  1.9857e+02  3.6767e+01  2.8408e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       73-      53  2.5369e+02  3.7563e+01  1.1385e-04
    1T  9.9e-06       12-      56  2.2522e+02  3.6313e+01  2.5452e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        2-      58  2.0689e+02  4.1333e+01  2.8973e-06
    1T  2.3e-06       58-      64  8.9204e+02  4.8308e+01  8.1338e-03
    1T  5.7e-06       21-      56  2.1210e+02  3.5515e+01  6.3661e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       27-      63  2.2994e+02  4.7328e+01  4.2804e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       34-      58  2.3899e+02  3.7250e+01  4.1950e-06
    1T  2.9e-06        9-      54  2.5210e+02  3.9656e+01  7.7711e-06
    1T -2.4e-06       59-      55  2.4166e+02  3.9352e+01  1.5802e-07
    1T -1.4e-06       20-      54  2.1574e+02  3.6611e+01  2.5745e-03

indexes =

  Columns 1 through 13

   121    70    52   166   134    97   128   194   146    90   144   117    73

  Columns 14 through 26

    69   123   189   126   163   143    60    18   160   102    97    67   153

  Columns 27 through 30

     1   157    51   188


Accuracy =

   97.5944


Accuracy =

   97.6597


Accuracy =

   97.5964


Accuracy =

   97.6822


Accuracy =

   97.6373


Accuracy =

   97.5985


Accuracy =

   97.6700


Accuracy =

   97.6005


Accuracy =

   97.6066


Accuracy =

   97.5556


Accuracy =9.755560e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.9450
   99.9407
  100.0000
   99.2051
   98.4755
   99.9721
   99.6910
   94.3278
  100.0000
   99.8989
  100.0000
   99.9426
  100.0000
   99.6901
   91.6274
  100.0000


AverageAccuracy =

   98.9198

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=70  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       25-      62  5.8002e+02  3.0245e+01  7.4833e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       49-      20  2.6814e+02  4.4508e+01  1.3445e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       47-      58  3.2174e+02  3.5481e+01  7.7039e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-08       24-      68  4.4626e+02  2.9775e+01  6.0728e-03
    1T  4.3e-06        9-      59  2.2713e+02  3.0046e+01  5.8165e-06
    1T  5.1e-06       14-      61  1.0462e+03  3.7844e+01  4.8510e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       37-      65  3.1602e+02  3.1520e+01  1.0048e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06        9-      59  3.1754e+02  3.6797e+01  1.2820e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       34-      57  3.5717e+02  3.5560e+01  8.5808e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       66-      56  3.5850e+02  3.3702e+01  5.3705e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       70-      42  4.0286e+02  4.6377e+01  7.1127e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       74-      58  3.2166e+02  2.9399e+01  2.1042e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       58-      64  2.1228e+02  3.1580e+01  3.0769e-06
    1T -8.6e-06        7-      63  3.4027e+02  3.0949e+01  6.6614e-03
    1T -2.3e-06       74-      56  1.9888e+02  3.0418e+01  5.4725e-03
    1T -9.5e-06       64-      60  5.1613e+02  3.3500e+01  4.1289e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       41-      58  3.3678e+02  2.8927e+01  8.0328e-03
    1T  2.2e-06       23-      56  4.6364e+02  3.6648e+01  2.8872e-06
    1T -8.6e-06       10-      57  3.1393e+02  3.8253e+01  7.1738e-03
    1T  8.0e-06        9-      62  2.9163e+02  3.4923e+01  2.7539e-03
    1T -8.9e-06       29-      40  3.2946e+02  3.7823e+01  1.1398e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-06       31-      59  2.1045e+03  3.2712e+01  9.1114e-03
    1T  1.2e-06       33-      53  2.2840e+02  3.3825e+01  4.5328e-07
    1T -6.6e-07       29-      57  3.4119e+02  3.3794e+01  5.5594e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       63-      57  5.9858e+02  3.6638e+01  4.4847e-06
    1T -5.4e-06       28-      44  5.2429e+02  4.9673e+01  4.5806e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       64-      54  3.5585e+02  3.2745e+01  8.7990e-03
    1T  7.4e-06       75-      53  2.1601e+02  3.5727e+01  1.1340e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       75-      49  2.2623e+02  3.6752e+01  2.6914e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       24-      57  2.5480e+02  3.8563e+01  3.5615e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       20-      57  2.1741e+02  3.5896e+01  5.4316e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       46-      49  2.9175e+02  3.2495e+01  5.2558e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        3-      66  2.0961e+02  3.4911e+01  9.9732e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06       64-      57  2.3018e+02  3.5634e+01  4.6220e-03
    1T -9.0e-06       62-      56  2.7435e+02  3.7193e+01  2.3509e-03
    1T  7.1e-06       20-      54  4.5578e+02  5.4775e+01  5.3847e-05
    2T  8.6e-06       75-      53  4.5578e+02  5.4775e+01  5.3628e-05
    1T  1.8e-06       61-      55  2.3986e+02  3.2404e+01  3.6631e-07
    1T  4.2e-06        3-      61  2.6338e+02  4.3015e+01  1.7461e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       28-      63  2.0309e+02  3.2715e+01  3.0231e-03
    1T -4.5e-06       71-      59  2.3640e+02  3.5173e+01  5.8238e-03
    1T -6.5e-06       10-      59  2.2179e+02  3.2358e+01  3.1059e-03
    1T  5.2e-06       74-      57  2.5253e+02  3.5176e+01  4.2707e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       15-      65  7.4356e+02  3.7160e+01  1.6752e-03
    1T  5.5e-06        3-      61  2.7133e+02  3.3700e+01  1.3333e-06
    1T  2.6e-06       24-      47  1.8754e+02  3.4162e+01  5.5571e-03
    1T  3.7e-06       27-      60  2.2943e+02  3.4486e+01  1.9114e-03
    1T -3.7e-06       73-      42  6.3028e+02  3.1310e+01  7.6439e-03

indexes =

  Columns 1 through 13

   170   142   168   176    38   159    40   137     2   193    71    57   168

  Columns 14 through 26

    64    87   188    99    76   167   192   164    72    87    38    50    24

  Columns 27 through 30

    86   114    24    86


Accuracy =

   97.6629


Accuracy =

   97.6548


Accuracy =

   97.6895


Accuracy =

   97.5792


Accuracy =

   97.6650


Accuracy =

   97.5956


Accuracy =

   97.5772


Accuracy =

   97.6609


Accuracy =

   97.5731


Accuracy =

   97.6037


Accuracy =9.760374e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.6698
  100.0000
  100.0000
   99.0476
   98.6799
   99.9721
   99.5678
   96.5852
  100.0000
   99.2915
   99.3802
  100.0000
  100.0000
   99.3821
   88.9513
  100.0000


AverageAccuracy =

   98.7830

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-07        3-      59  3.5976e+02  4.8148e+01  5.4897e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       40-      53  4.6714e+02  3.5393e+01  6.0740e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       29-      65  4.6851e+02  3.4680e+01  4.5338e-07
    1T  6.2e-06       10-      54  5.8328e+02  3.2839e+01  7.8426e-03
    1T  7.2e-06       32-      64  5.2930e+02  3.0650e+01  8.3008e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       45-      60  1.9473e+02  3.7608e+01  4.0755e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06        9-      49  9.1780e+02  6.4992e+01  4.6179e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06        5-      51  2.9456e+02  3.1471e+01  4.1119e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        8-      62  5.6361e+02  5.1002e+01  3.1917e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       35-      50  2.1330e+02  3.8303e+01  3.0381e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       13-      46  1.1685e+03  4.9009e+01  4.1550e-03
    1T  7.5e-07       65-      56  2.0309e+02  3.7383e+01  7.1279e-07
    1T -5.6e-06       53-      51  2.3299e+02  3.2510e+01  6.0507e-03
    1T  3.7e-06       25-      63  1.9203e+02  3.8512e+01  1.6396e-03
    1T  2.8e-06        3-      64  1.8122e+02  3.8242e+01  4.0235e-03
    1T  1.4e-06       73-      65  4.0965e+02  3.6762e+01  5.2297e-03
    1T -9.5e-06        6-      60  1.9177e+02  3.7805e+01  2.7188e-03
    1T -8.2e-06        4-      61  4.8831e+02  4.8700e+01  5.4259e-03
    1T -1.7e-06       58-      67  4.2958e+02  3.5411e+01  8.5714e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       26-      63  4.1126e+02  3.8065e+01  3.7163e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-07       56-      55  2.6365e+02  3.7036e+01  4.3830e-03
    1T  2.9e-07       52-      59  3.7253e+02  3.9161e+01  1.0659e-02
    1T  9.0e-06       58-      58  2.8711e+02  4.2725e+01  2.9391e-03
    1T  4.4e-07       24-      60  2.6477e+03  6.0258e+01  2.2404e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       43-      59  3.5986e+02  4.0345e+01  3.6616e-03
    1T  4.4e-06       68-      60  2.4811e+02  4.1111e+01  5.7325e-03
    1T  3.0e-06       16-      60  2.5184e+02  4.5324e+01  4.1503e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       47-      55  4.8246e+02  6.1603e+01  3.4220e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-07       32-      47  2.0756e+02  4.0277e+01  9.3515e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      62  2.5898e+02  4.3491e+01  1.3318e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06       25-      60  2.1529e+02  3.9849e+01  3.5429e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06        9-      51  2.3441e+02  4.4851e+01  5.0328e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       75-      50  2.2786e+02  4.3166e+01  4.9147e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       18-      59  7.8029e+02  3.8965e+01  2.5429e-05
    1T -2.6e-08        6-      61  7.4035e+02  4.3427e+01  2.0616e-09
    1T -7.1e-06       60-      54  1.9434e+02  4.5692e+01  1.9981e-03
    1T -1.5e-06       32-      57  2.1757e+02  3.9344e+01  1.9060e-07
    1T  1.1e-06        6-      66  5.3909e+02  4.3858e+01  5.3423e-03
    1T -9.6e-06       30-      64  2.0053e+02  4.3293e+01  2.5230e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-07       59-      43  2.6210e+02  3.7265e+01  3.3052e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       67-      51  2.1961e+02  3.9818e+01  9.3114e-06
    1T -6.1e-06       42-      56  2.5336e+02  3.9127e+01  4.0692e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       35-      55  3.5624e+02  3.7378e+01  3.8115e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        2-      54  1.2241e+03  4.2875e+01  4.4648e-03

indexes =

  Columns 1 through 13

    46   106   168   124   142   145   188   112   195     5   151    15   186

  Columns 14 through 26

   154    57   114    63    68    71    72    56    71   108    91    54    59

  Columns 27 through 30

   129    68   183    80


Accuracy =

   98.0631


Accuracy =

   98.0998


Accuracy =

   98.0835


Accuracy =

   98.0529


Accuracy =

   98.0468


Accuracy =

   98.1468


Accuracy =

   98.0713


Accuracy =

   98.0141


Accuracy =

   98.1917


Accuracy =

   98.0488


Accuracy =9.804882e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.6154
   99.9407
   99.7765
   99.1297
   99.3388
  100.0000
   99.8456
   95.9024
  100.0000
   99.6290
   98.9659
   99.9427
  100.0000
   99.5868
   93.0925
   99.2647


AverageAccuracy =

   99.0019

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
{Operation terminated by user during mtkrprod (line 375)


In sdf_core/grad_cpd (line 900)
            tmp = full(mtkrprod(E,z,n));

In sdf_core/grad (line 649)
        JHF = model.factorizations{i}.grad(i,tmp);

In nls_gndl (line 369)
            grad = serialize(dF.JHF(z));

In sdf_core (line 335)
[z,output] = options.Algorithm(@objfun,dF,model.variables,options);

In sdf_nls (line 145)
    [sol, output] = sdf_core(model,options{:});

In FactorizeTensor (line 18)
sol = sdf_nls(model);
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-07       59-      65  5.0414e+02  3.4356e+01  3.0683e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       14-      63  2.3699e+02  3.6168e+01  3.3862e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       34-      41  2.7273e+02  7.7980e+01  3.4801e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       58-      67  5.9174e+02  2.9031e+01  2.5018e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       12-      57  4.8470e+02  3.8004e+01  3.7157e-03
    1T  8.4e-06       48-      71  6.3147e+02  4.8487e+01  5.2154e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06        4-      67  4.9003e+02  3.1894e+01  2.5300e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       26-      64  1.0293e+03  2.9911e+01  1.1876e-03
    1T -6.4e-06       63-      55  4.9741e+02  2.9291e+01  2.0713e-03
    1T -3.8e-06       46-      68  4.6836e+02  4.8007e+01  8.2127e-03
    1T  2.7e-06       18-      60  2.1076e+02  3.4179e+01  4.2698e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.0e-06       42-      66  3.4657e+02  3.5455e+01  4.8697e-03
    1T  8.9e-06       40-      58  1.9721e+02  3.2499e+01  3.9263e-03
    1T  2.3e-06       64-      59  2.6626e+02  3.6816e+01  8.8219e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       54-      57  3.4650e+02  3.3311e+01  7.0369e-03
    1T  1.5e-06       70-      67  5.0039e+02  2.9671e+01  1.3713e-03
    1T -4.1e-06       51-      61  1.9573e+02  3.5079e+01  5.1497e-04
    1T  9.8e-06        3-      60  3.6993e+02  3.0158e+01  5.7524e-06
    1T -4.1e-06       18-      48  2.3826e+02  3.3585e+01  5.0635e-03
    1T  6.7e-06       40-      59  2.1911e+02  2.9885e+01  2.8377e-03
    1T -8.3e-06       72-      66  5.4038e+02  3.0114e+01  4.6919e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       10-      44  2.4175e+02  3.4764e+01  2.9343e-03
    1T -5.3e-06       63-      68  4.0129e+02  3.1858e+01  3.5983e-07
    1T -1.1e-06       54-      50  3.5963e+02  3.7422e+01  4.1887e-03
    1T  2.2e-06       58-      69  4.6772e+02  3.4398e+01  2.1650e-06
    1T  5.4e-06       61-      60  6.5397e+02  4.8090e+01  3.8091e-04
    1T  1.4e-06       15-      57  3.1778e+02  3.7029e+01  2.5709e-03
    1T -9.3e-06       74-      53  1.9451e+02  3.1037e+01  4.5367e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       66-      63  3.6914e+02  3.0922e+01  1.5737e-05
    1T  6.2e-06       41-      69  5.7481e+02  4.0878e+01  3.2520e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       74-      45  3.0187e+02  5.0755e+01  2.9298e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       39-      47  2.1499e+02  2.9907e+01  3.5665e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-08       65-      53  2.1337e+02  3.2662e+01  5.3840e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       38-      60  1.9329e+02  3.5032e+01  6.4264e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       69-      56  1.9999e+02  3.1525e+01  1.2585e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-07       65-      56  2.8322e+02  4.0642e+01  1.2510e-08
    1T  8.3e-06       38-      62  3.7518e+02  3.8667e+01  4.3760e-06
    1T  8.2e-07       53-      43  1.9385e+02  3.3035e+01  1.1397e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-07       11-      57  2.6171e+02  3.3091e+01  5.6594e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       10-      63  8.1441e+02  4.3601e+01  5.0887e-03
    1T -1.9e-06       35-      53  8.4151e+02  2.8822e+01  4.9443e-03
    1T  1.3e-06       18-      62  2.0183e+02  3.4527e+01  3.7968e-03
    1T -2.0e-06       33-      69  2.0251e+02  3.8222e+01  1.8312e-04
    1T  7.7e-06        9-      63  2.0279e+02  3.6300e+01  3.4957e-03
    1T  2.7e-06       50-      57  2.0988e+02  3.6427e+01  2.8092e-03
    1T  4.7e-06       28-      51  2.2795e+02  3.4525e+01  6.9020e-06
    1T  2.9e-06       51-      56  2.2824e+02  3.3934e+01  7.9764e-05
    1T  3.1e-06       59-      54  2.5507e+02  3.0956e+01  2.5894e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       55-      60  2.0360e+02  3.3687e+01  1.7784e-03
    1T -4.6e-06       35-      51  2.7503e+02  3.1973e+01  3.8290e-03
    1T -2.9e-06       69-      63  5.2779e+02  3.6407e+01  5.7392e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      56  1.8914e+02  3.3322e+01  4.0673e-06
    1T -5.5e-06       63-      50  2.5106e+02  3.2284e+01  4.3092e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-07       15-      59  1.9831e+02  3.2232e+01  4.2087e-07
    1T  7.0e-06       64-      55  2.1770e+02  3.1547e+01  4.9204e-03
    1T  6.0e-06       45-      49  2.3444e+02  3.0406e+01  5.2264e-06

indexes =

  Columns 1 through 13

    66   183     1   101    10   160    28    73    63   128    42    23   175

  Columns 14 through 26

    84   195    74   132    79    73    21    70     6    39   142    81     7

  Columns 27 through 30

    90    39    70    79


Accuracy =

   98.3787


Accuracy =

   98.4256


Accuracy =

   98.4501


Accuracy =

   98.4052


Accuracy =

   98.3889


Accuracy =

   98.4991


Accuracy =

   98.4256


Accuracy =

   98.4256


Accuracy =

   98.3705


Accuracy =

   98.4134


Accuracy =9.841338e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   98.7377
  100.0000
   99.6639
   99.2868
   98.8031
   99.9720
   99.9384
   96.8217
  100.0000
   99.5620
  100.0000
  100.0000
  100.0000
   97.8351
   94.7360
   99.8170


AverageAccuracy =

   99.0734

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       14-      56  4.5179e+02  3.1796e+01  6.5029e-03
    1T -7.3e-06       27-      59  1.9386e+02  4.5669e+01  1.5074e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       69-      64  4.5296e+02  3.5419e+01  4.1303e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06        3-      67  3.1982e+02  5.2162e+01  2.9932e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.1e-06       14-      46  1.9724e+02  2.7312e+01  5.8242e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06        5-      60  1.8659e+02  4.1548e+01  3.8902e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       65-      46  3.3442e+02  5.5454e+01  9.8558e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       44-      64  3.4654e+02  4.2720e+01  2.0516e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       44-      64  3.4654e+02  4.2720e+01  2.0516e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       61-      60  5.7556e+02  5.2560e+01  2.6956e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       25-      46  9.3254e+02  3.1361e+01  6.9356e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       57-      55  2.1209e+02  3.9144e+01  2.9269e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       43-      67  4.5048e+02  4.2466e+01  1.1183e-07
    1T -4.8e-06       50-      63  3.8476e+02  3.7031e+01  5.8399e-03
    1T  2.2e-07       65-      61  4.2515e+02  3.2598e+01  5.9851e-03
    1T -5.4e-06       18-      60  3.2196e+02  4.0401e+01  1.5933e-03
    1T  8.9e-06       15-      66  2.9044e+02  5.1678e+01  1.8241e-06
    1T  4.1e-06       65-      68  4.6757e+02  3.6542e+01  4.6268e-03
    1T -8.9e-06       72-      59  2.2056e+02  3.1904e+01  2.4795e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       21-      63  2.1020e+02  4.6336e+01  5.2234e-03
    1T  2.1e-06       74-      40  3.8992e+02  4.6876e+01  5.0618e-03
    1T  6.8e-07       60-      50  2.9388e+02  5.3659e+01  6.4233e-07
    1T  8.0e-06       41-      62  1.1670e+03  5.6732e+01  6.6553e-07
    1T -3.7e-06       23-      58  5.4960e+02  3.9473e+01  1.0953e-02
    1T  7.1e-06       63-      64  6.8845e+02  3.9779e+01  6.6787e-06
    1T  4.1e-06       44-      64  3.4654e+02  4.2720e+01  2.0516e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       44-      64  3.4654e+02  4.2720e+01  2.0516e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       66-      53  2.4797e+02  3.9616e+01  5.4312e-03
    1T  4.3e-06       21-      56  3.6192e+02  4.0849e+01  7.8886e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       13-      60  4.1570e+02  4.9616e+01  1.2385e-06
    1T  8.0e-06       51-      51  1.5135e+03  7.5861e+01  1.3801e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      54  2.6521e+02  7.3974e+01  7.3700e-06
    1T  4.8e-07        7-      59  2.3099e+02  4.4744e+01  3.6234e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-07       43-      50  1.9106e+02  4.6448e+01  1.5143e-06
    1T  9.5e-06       13-      48  2.1086e+02  4.8290e+01  5.3188e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       31-      53  2.2953e+02  4.3143e+01  1.8419e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       68-      52  2.5980e+02  4.8600e+01  4.0515e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       49-      58  2.3124e+02  4.5785e+01  4.4075e-03
    1T  5.7e-06        7-      58  2.3420e+02  4.5039e+01  3.7069e-06
    1T  3.5e-06        9-      50  2.3909e+02  4.3439e+01  1.7112e-03
    1T  5.5e-07       43-      54  2.5899e+02  4.5452e+01  4.3498e-03
    1T  9.2e-06       13-      55  4.3738e+02  4.7649e+01  3.5585e-06
    1T  1.5e-07       72-      57  1.8877e+02  4.4449e+01  3.8115e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       49-      55  2.1850e+02  4.3197e+01  2.6173e-03
    1T -9.2e-07       43-      49  2.1047e+02  4.7457e+01  5.1148e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06        4-      41  3.4514e+02  3.4693e+01  3.9163e-03
    1T  5.4e-06       53-      55  2.4818e+02  3.9826e+01  9.0515e-06
    1T  8.3e-06       40-      53  7.5239e+02  5.2151e+01  1.0631e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       75-      45  2.5619e+02  3.5913e+01  4.5302e-04

indexes =

  Columns 1 through 13

   181    23   152    68   186     8   156   167   144   176    88    40   137

  Columns 14 through 26

    48   113   156   194    77   151   127   117    59    72    12   200   123

  Columns 27 through 30

   116   187   140   175


Accuracy =

   97.9730


Accuracy =

   98.0403


Accuracy =

   98.0260


Accuracy =

   97.9791


Accuracy =

   97.9750


Accuracy =

   98.1383


Accuracy =

   98.0730


Accuracy =

   97.9975


Accuracy =

   97.9485


Accuracy =

   98.0240


Accuracy =9.802401e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.5052
   99.9407
  100.0000
   98.3360
   99.7932
  100.0000
   99.6604
   96.2636
   99.9822
   99.4611
   99.6898
  100.0000
  100.0000
   99.8969
   92.3672
   99.0826


AverageAccuracy =

   98.9987

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       28-      36  2.3436e+02  6.9314e+01  1.0349e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       57-      36  4.3737e+02  7.0539e+01  1.3059e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       15-      64  4.6896e+02  3.1064e+01  3.1215e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       61-      59  5.2195e+02  3.0653e+01  1.1122e-04
    1T  8.8e-06       52-      67  4.7888e+02  3.5943e+01  8.2310e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       67-      58  2.5792e+02  3.6524e+01  5.8779e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       28-      57  1.3335e+03  3.2866e+01  1.9296e-06
    1T  8.5e-06        2-      60  1.1950e+03  3.5261e+01  8.4878e-07
    1T  8.8e-06       62-      57  3.3349e+02  3.3302e+01  9.2302e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06        3-      60  3.8157e+02  3.2881e+01  5.0986e-07
    1T -4.8e-06       50-      60  2.5965e+02  3.4895e+01  7.5023e-03
    1T -5.1e-06       71-      67  4.9210e+02  3.1313e+01  1.5847e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       12-      66  3.4910e+02  3.1939e+01  3.7189e-03
    1T -5.8e-06       42-      58  4.4399e+02  2.7649e+01  5.1843e-07
    1T  9.8e-06       51-      64  3.4458e+02  2.9715e+01  3.6082e-03
    1T  5.6e-06       63-      54  4.1907e+02  3.3389e+01  9.8347e-03
    1T  8.2e-06       27-      58  3.8649e+02  3.4449e+01  8.1851e-03
    1T -5.3e-06       45-      43  3.5112e+02  3.6825e+01  4.4559e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       38-      49  2.1478e+02  3.6386e+01  2.3280e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       15-      47  2.7445e+02  3.6549e+01  4.8573e-03
    1T -6.7e-06       17-      38  3.0497e+02  4.7498e+01  3.4994e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       66-      54  2.3572e+02  3.5369e+01  5.2821e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-08       24-      43  2.3146e+02  3.0769e+01  3.4404e-03
    1T  1.3e-06        9-      53  1.9554e+02  3.5908e+01  4.5539e-03
    1T  4.0e-06       67-      56  2.2561e+02  3.5645e+01  1.6340e-03
    1T  9.0e-06       72-      48  2.1931e+02  3.9833e+01  1.1272e-06
    1T  8.8e-06       16-      55  2.1247e+02  3.9797e+01  3.1144e-05
    1T  5.0e-06       46-      67  2.2258e+02  4.0261e+01  4.8048e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       12-      47  2.3341e+02  3.7380e+01  3.0216e-03
    1T  7.7e-06       55-      55  2.5132e+02  4.3985e+01  1.3286e-03

indexes =

  Columns 1 through 13

    26    50    40   199   154   160   172    20   183   114     1   164   161

  Columns 14 through 26

   138    30    91   110    60   114   138   178    46    22    67    49   115

  Columns 27 through 30

   150    61    33   143


Accuracy =

   98.0062


Accuracy =

   97.9511


Accuracy =

   97.9531


Accuracy =

   98.0797


Accuracy =

   97.9695


Accuracy =

   97.9776


Accuracy =

   97.9042


Accuracy =

   98.0266


Accuracy =

   97.9980


Accuracy =

   97.9389


Accuracy =9.793886e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.9451
   99.9407
  100.0000
   98.8889
   99.0515
  100.0000
   99.9075
   96.5994
  100.0000
   99.5621
   99.3821
  100.0000
  100.0000
   98.6598
   91.0706
  100.0000


AverageAccuracy =

   98.9380

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       22-      66  5.0212e+02  2.8533e+01  5.3998e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       22-      66  5.0212e+02  2.8533e+01  5.3998e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       22-      66  5.0212e+02  2.8533e+01  5.3998e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       65-      37  4.1881e+02  6.3155e+01  6.2061e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       10-      49  3.0867e+02  3.4065e+01  4.9204e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       62-      61  4.1252e+02  3.5687e+01  5.0649e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       50-      67  5.8878e+02  2.9740e+01  6.3828e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       11-      53  3.9790e+02  3.5100e+01  3.9743e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       33-      62  4.2912e+02  3.3969e+01  8.9733e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       54-      63  3.6553e+02  3.0012e+01  1.3357e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       10-      65  4.9937e+02  2.9029e+01  1.2749e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.4e-06       22-      54  2.0644e+02  2.5591e+01  1.7631e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       10-      58  4.7987e+02  3.6410e+01  9.4911e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       11-      51  1.7538e+03  4.6121e+01  8.9540e-05
    1T -4.4e-06       57-      58  1.9856e+02  2.5952e+01  1.1066e-03
    1T  7.2e-06       37-      65  2.5815e+02  3.3963e+01  5.9710e-03
    1T  5.2e-06       22-      66  5.0212e+02  2.8533e+01  5.3998e-03
    1T  5.9e-07       36-      56  1.3946e+03  3.2583e+01  3.5230e-03
    1T -1.2e-06       29-      56  4.0049e+02  3.1801e+01  2.9550e-03
    1T  8.2e-06       35-      45  2.1370e+02  3.7665e+01  1.0028e-03
    1T  6.5e-06       34-      63  4.8902e+02  3.3035e+01  9.1091e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       65-      60  3.6884e+02  2.8488e+01  5.0928e-07
    1T  6.2e-07       52-      59  2.0990e+02  3.2654e+01  1.6991e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       23-      63  3.1070e+02  3.3621e+01  4.9960e-03
    1T  4.4e-06       50-      64  3.8190e+02  3.1600e+01  1.7175e-06
    1T  8.7e-06       15-      58  3.8213e+02  3.1735e+01  7.7946e-06
    1T  4.6e-06       36-      58  1.7381e+03  6.9194e+01  4.0993e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-07       27-      48  2.5990e+02  3.6384e+01  1.7066e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       10-      42  3.4653e+02  3.7359e+01  2.2878e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       34-      51  8.9775e+02  5.4793e+01  8.6014e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       56-      64  6.4737e+02  3.9146e+01  6.1591e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       64-      57  2.3515e+02  3.5825e+01  3.0909e-06
    1T -8.0e-06       58-      56  2.1580e+02  3.4926e+01  1.7887e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06        2-      43  1.2891e+03  4.8282e+01  2.5760e-06
    1T  5.0e-06       54-      57  2.0513e+02  3.4535e+01  3.4588e-03
    1T -5.8e-06       18-      56  2.0984e+03  4.6690e+01  6.0131e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-07       22-      71  2.0144e+02  3.3710e+01  3.7166e-07
    1T  4.2e-06       36-      63  1.0089e+03  3.9633e+01  2.7128e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-07       49-      60  2.8244e+02  3.1751e+01  2.0944e-07
    1T  2.0e-06       53-      66  1.9562e+02  3.4806e+01  1.9353e-06
    1T  9.6e-06       16-      54  2.2629e+02  3.2464e+01  1.3310e-06
    1T  5.0e-06       31-      67  2.5414e+02  3.4473e+01  2.6398e-03
    1T  5.9e-06       28-      51  2.3124e+02  3.5756e+01  2.4329e-06
    1T -9.2e-06       54-      62  1.7525e+02  3.3176e+01  2.6154e-03
    1T -3.6e-06       30-      53  1.9113e+02  3.5168e+01  4.0968e-03
    1T  3.5e-06       60-      63  2.9760e+02  3.3745e+01  2.2808e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       16-      58  2.1695e+02  3.5438e+01  5.4341e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       51-      53  2.0979e+02  3.1876e+01  2.9325e-03
    1T -9.1e-06       54-      59  2.5697e+02  3.3497e+01  2.5893e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06        8-      69  2.4087e+02  3.3707e+01  1.7998e-03
    1T  6.8e-06       66-      61  2.2047e+02  3.4896e+01  3.7282e-03
    1T  4.6e-06       48-      55  2.4570e+02  3.5327e+01  1.3174e-06
    1T -2.0e-06       17-      55  3.3266e+02  3.7389e+01  5.6250e-03
    1T -8.9e-06       26-      48  3.5266e+02  3.8082e+01  1.5165e-03

indexes =

  Columns 1 through 13

   165    42   186     9   128   141   164   144   148   126    50   111   104

  Columns 14 through 26

   147    39    36   135    81   171   112   117    79   111   172    67   144

  Columns 27 through 30

   134    98    39   195


Accuracy =

   97.5042


Accuracy =

   97.3878


Accuracy =

   97.4940


Accuracy =

   97.4225


Accuracy =

   97.3940


Accuracy =

   97.5410


Accuracy =

   97.3327


Accuracy =

   97.4450


Accuracy =

   97.3633


Accuracy =

   97.3654


Accuracy =9.736536e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.0110
   99.7328
   99.5521
   98.2554
   99.6287
  100.0000
   99.6602
   95.2334
   99.5192
   99.1219
   99.7927
   99.9427
  100.0000
   98.5507
   90.2755
   98.8984


AverageAccuracy =

   98.5734

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       55-      58  2.5576e+02  3.8377e+01  6.7232e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       40-      53  1.0552e+03  4.7025e+01  1.3120e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       75-      23  2.2833e+02  5.6243e+01  8.6096e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       48-      59  3.7756e+02  3.4898e+01  4.1520e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       47-      58  2.4385e+02  4.2503e+01  2.1467e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06       48-      67  3.6221e+02  3.3390e+01  6.0229e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       16-      58  5.3468e+02  3.8737e+01  8.0805e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       67-      58  2.3319e+02  3.7537e+01  5.9198e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       54-      58  2.1435e+02  4.9126e+01  1.1341e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       67-      46  2.6341e+02  4.0013e+01  1.2226e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-06       50-      66  4.2526e+02  3.7734e+01  6.7109e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       24-      52  9.0505e+02  4.1916e+01  6.4370e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       64-      65  2.7066e+02  3.9049e+01  4.0850e-07
    1T -7.5e-06       32-      58  3.0160e+02  3.9357e+01  2.0699e-03
    1T -3.9e-08       51-      59  1.8356e+02  3.5815e+01  3.1792e-03
    1T  2.4e-06        4-      55  1.1350e+03  3.9781e+01  9.3309e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       39-      49  2.8650e+02  3.8814e+01  2.7583e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       42-      56  5.5340e+02  3.2951e+01  9.9961e-06
    1T  5.9e-06       16-      56  4.2490e+02  3.4177e+01  1.2084e-06
    1T  8.1e-06       26-      54  3.8839e+02  4.0187e+01  4.7203e-03
    1T -1.5e-06        7-      60  2.3107e+02  4.3623e+01  5.0136e-03
    1T  8.0e-06        7-      51  4.9102e+02  5.3994e+01  1.0941e-02
    1T  8.5e-06       74-      59  4.3439e+02  4.6513e+01  5.5170e-03
    1T -9.6e-06       23-      49  2.6426e+02  3.8015e+01  5.5481e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-07       33-      57  7.8511e+02  3.6508e+01  5.3172e-03
    1T -1.9e-06       26-      62  5.1506e+02  3.3048e+01  2.8783e-03
    1T -9.5e-06       33-      67  3.5688e+02  3.3774e+01  5.5824e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       53-      65  1.8156e+02  4.1001e+01  3.7082e-03
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      46  2.0324e+02  4.2604e+01  4.9182e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       11-      46  2.1327e+02  3.8772e+01  2.4479e-03
    1T -7.7e-06        2-      60  2.1999e+02  3.5317e+01  1.4839e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        4-      46  9.3686e+02  3.7674e+01  3.8444e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       23-      63  4.8819e+02  3.4503e+01  2.7331e-06
    1T  4.0e-06       57-      58  2.0409e+02  4.2934e+01  6.4594e-07
    1T -8.4e-06       21-      56  3.4511e+02  3.6150e+01  8.3977e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       20-      59  3.8954e+02  4.2779e+01  2.7052e-07
    1T -4.3e-06       14-      53  3.2275e+02  3.8838e+01  2.1127e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       10-      54  1.8160e+02  4.4313e+01  1.6504e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       65-      51  2.6596e+02  4.0130e+01  1.6763e-03
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       35-      47  2.8695e+02  4.2504e+01  2.4318e-06
    1T  1.6e-06       10-      55  2.0470e+02  3.9435e+01  2.7662e-03
    1T  2.1e-06       50-      54  7.6069e+02  4.2866e+01  1.6537e-06
    1T -9.4e-06       75-      50  3.0151e+02  3.6264e+01  3.2365e-03
    1T  8.1e-06       62-      58  2.3002e+02  3.9127e+01  4.3987e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       30-      57  3.1540e+02  3.9954e+01  2.4874e-06
    1T  4.7e-06       65-      53  2.1892e+02  3.8393e+01  2.9277e-07
    1T  1.1e-06        4-      54  1.8555e+02  3.8563e+01  4.6308e-06
    1T  2.3e-06       36-      57  1.9706e+02  4.0539e+01  1.0782e-06

indexes =

  Columns 1 through 13

   149    18   184     5    20   123   199   139   163   171    42    35    43

  Columns 14 through 26

   129    79   149   136    36    96   165   187    74   124    87   194   165

  Columns 27 through 30

   160   178   176   133


Accuracy =

   97.5416


Accuracy =

   97.5987


Accuracy =

   97.5131


Accuracy =

   97.5457


Accuracy =

   97.5069


Accuracy =

   97.6069


Accuracy =

   97.4213


Accuracy =

   97.4947


Accuracy =

   97.4519


Accuracy =

   97.4621


Accuracy =9.746205e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.7800
   99.8814
   99.9442
   99.2868
   99.0500
  100.0000
   99.8765
   93.9441
   99.9287
   99.6966
   99.7927
   99.9428
   99.7602
   99.6907
   91.4958
  100.0000


AverageAccuracy =

   98.8794

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       56-      62  1.7375e+02  2.8346e+01  4.3693e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       26-      67  6.0657e+02  3.0238e+01  1.2774e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       17-      65  5.3581e+02  2.6669e+01  7.0117e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-08       54-      40  2.3543e+02  8.1034e+01  4.3918e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06        2-      71  4.3856e+02  2.9108e+01  4.1028e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06        2-      71  4.3856e+02  2.9108e+01  4.1028e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       42-      52  4.5226e+02  3.4007e+01  4.7332e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       57-      59  3.6220e+02  3.0460e+01  8.2211e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       51-      59  4.2232e+02  3.4001e+01  5.6802e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       38-      70  3.9692e+02  2.9717e+01  2.9236e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       20-      67  4.6182e+02  3.1971e+01  3.4311e-03
    1T  8.8e-06        2-      71  4.3856e+02  2.9108e+01  4.1028e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06        2-      71  4.3856e+02  2.9108e+01  4.1028e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       55-      63  3.9915e+02  2.8573e+01  1.1021e-05
    1T  9.1e-06       72-      45  6.2258e+02  4.8505e+01  1.8608e-05
    1T  9.3e-06       10-      53  4.5966e+02  2.4590e+01  5.7993e-03
    1T -6.8e-06       30-      58  6.5462e+02  4.1126e+01  2.8765e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       55-      60  7.3938e+02  3.8261e+01  2.4371e-06
    1T -9.5e-06       64-      60  8.2250e+02  3.1310e+01  3.5020e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       28-      47  2.3276e+02  3.3297e+01  4.2349e-06
    1T  8.7e-06       60-      66  4.1748e+02  3.2459e+01  5.7342e-03
    1T  1.3e-06       16-      58  3.5063e+02  3.3894e+01  4.0680e-07
    1T -2.6e-06       19-      51  3.0235e+02  3.6193e+01  2.1558e-07
    1T -5.0e-06       57-      65  2.0243e+02  3.2437e+01  4.9218e-03
    1T -4.1e-06       44-      62  4.0287e+02  3.8790e+01  3.5451e-07
    1T -9.3e-06       73-      58  2.6335e+02  2.8937e+01  3.2718e-03
    1T  9.4e-06       61-      61  5.0847e+02  3.2341e+01  1.5321e-05
    1T  4.5e-06       51-      59  2.1544e+02  2.9361e+01  2.7297e-03
    1T  6.9e-06       13-      60  4.2820e+02  3.3301e+01  6.6729e-03
    1T  1.8e-06       65-      63  3.9923e+02  3.0155e+01  5.1620e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       39-      60  3.4953e+02  3.0017e+01  9.5816e-03
    1T -2.7e-06       16-      61  2.2287e+02  3.3921e+01  2.8972e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       13-      67  4.2664e+02  3.4832e+01  9.1741e-03
    1T  8.3e-06       36-      55  2.4553e+02  3.4487e+01  6.0025e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       10-      53  2.1660e+02  3.8912e+01  5.0764e-03
    1T  7.8e-06       16-      62  3.6368e+02  3.4511e+01  4.3790e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-06       17-      58  2.0938e+02  3.2779e+01  2.6297e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       56-      47  2.0169e+02  3.4981e+01  4.9220e-03
    1T  3.5e-07       42-      51  2.2075e+02  3.1620e+01  5.1181e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       42-      53  2.0249e+02  3.2323e+01  2.7073e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       19-      61  2.9761e+02  3.2911e+01  4.5289e-03
    1T -5.3e-06       12-      57  2.4073e+02  3.0744e+01  4.4129e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        8-      55  2.3929e+02  3.2404e+01  2.7560e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       36-      62  3.7053e+02  3.3167e+01  5.1642e-03
    1T  5.0e-06       20-      48  2.2607e+02  3.1596e+01  6.7980e-07
    1T -4.6e-06       20-      63  2.8346e+02  4.2283e+01  3.2143e-03
    1T  8.9e-06       14-      60  2.1585e+02  3.5341e+01  1.7190e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       66-      56  2.1452e+02  3.8020e+01  8.9702e-07
    1T  6.1e-06       29-      61  4.7010e+02  3.3081e+01  1.5246e-06

indexes =

  Columns 1 through 13

    41   109   153   185    94    46    34   164   126   173   194    27    39

  Columns 14 through 26

    29   147    68    63    26    38    74   178   156   114   176    19   111

  Columns 27 through 30

   155   147   162   117


Accuracy =

   98.2599


Accuracy =

   98.2640


Accuracy =

   98.2966


Accuracy =

   98.3252


Accuracy =

   98.2660


Accuracy =

   98.2885


Accuracy =

   98.2885


Accuracy =

   98.2660


Accuracy =

   98.2273


Accuracy =

   98.2232


Accuracy =9.822317e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.1218
   99.9703
  100.0000
   99.2857
   98.9292
   99.9721
   99.9691
   97.0404
  100.0000
   99.7307
   99.7934
   99.9427
   99.8794
   99.3802
   92.4480
  100.0000


AverageAccuracy =

   99.0914

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       56-      57  3.1907e+02  3.5561e+01  1.5759e-06
    1T -9.4e-06       22-      59  2.1790e+02  3.4930e+01  1.0865e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       73-      38  2.3657e+02  1.0124e+02  4.7715e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       31-      61  3.4367e+02  3.5795e+01  1.6524e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       57-      16  2.7337e+02  4.0426e+01  4.2479e-06
    1T -7.1e-06       57-      62  1.7466e+02  3.5919e+01  3.5164e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       55-      65  3.1294e+02  5.2900e+01  4.4537e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       49-      63  3.4371e+02  3.4666e+01  4.1754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       39-      60  4.4933e+02  4.0323e+01  2.3950e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       56-      64  1.1680e+03  5.5048e+01  6.1571e-03
    1T  9.9e-06       43-      51  1.7333e+03  4.4982e+01  2.3730e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-07       42-      62  4.0562e+02  3.1834e+01  6.1935e-08
    1T  6.7e-06       45-      60  2.0422e+02  3.3572e+01  1.1258e-04
    1T  1.0e-05       14-      59  3.3073e+02  3.7290e+01  4.2480e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       50-      57  3.1738e+02  3.1764e+01  3.4256e-03
    1T  2.0e-06       33-      59  2.3407e+02  3.8832e+01  2.3085e-03
    1T  7.6e-07       57-      48  4.2131e+02  4.7450e+01  9.1019e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       70-      60  2.1297e+02  3.3471e+01  4.0465e-06
    1T -6.0e-06       50-      65  4.9154e+02  2.9327e+01  6.0218e-03
    1T  4.6e-06       51-      61  4.2250e+02  3.7992e+01  3.2148e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       13-      65  4.3975e+02  3.5482e+01  3.4172e-03
    1T  2.8e-07       65-      56  2.0171e+02  3.6624e+01  4.2455e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       28-      42  2.9281e+02  4.0489e+01  1.6597e-06
    1T  1.5e-06       70-      53  3.1130e+02  4.3951e+01  3.1526e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06        1-      65  5.1499e+02  3.4367e+01  3.6162e-06
    1T  3.3e-06       15-      69  2.0826e+02  4.2573e+01  3.6167e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06        2-      65  2.8622e+02  4.5145e+01  2.5946e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       15-      57  7.7538e+02  4.0928e+01  7.1091e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       42-      56  2.0244e+02  4.0580e+01  4.4456e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06        4-      60  2.0630e+02  4.1797e+01  2.3441e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       63-      61  2.0529e+02  3.7059e+01  2.6145e-03
    1T  1.9e-06       41-      63  2.2078e+02  4.2740e+01  1.9353e-06
    1T  1.2e-06        4-      64  1.8622e+02  4.1198e+01  3.9540e-07
    1T -5.4e-06       49-      51  1.8994e+02  3.5423e+01  1.4950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       18-      68  1.9155e+02  3.8946e+01  6.1731e-07
    1T -5.2e-08       38-      52  2.0715e+02  3.9170e+01  4.4256e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       20-      55  2.5156e+02  3.9037e+01  3.2309e-06
    1T  3.5e-06       23-      60  6.5157e+02  3.9631e+01  2.6500e-07
    1T  1.7e-06       36-      56  2.1233e+02  4.3668e+01  1.5697e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.3e-06       17-      45  2.1146e+02  3.4700e+01  9.7730e-04

indexes =

  Columns 1 through 13

   110   159   119   171    23   160   118   161   121     4     8    50     4

  Columns 14 through 26

   129    80    57    78    34    45   144   137    79   180    79    70   136

  Columns 27 through 30

   115   140   140   161


Accuracy =

   97.7244


Accuracy =

   97.8550


Accuracy =

   97.8632


Accuracy =

   97.8693


Accuracy =

   97.8285


Accuracy =

   97.8387


Accuracy =

   97.7326


Accuracy =

   97.7489


Accuracy =

   97.7673


Accuracy =

   97.7958


Accuracy =9.779583e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.6701
  100.0000
  100.0000
   99.2051
   99.3804
  100.0000
   99.8456
   95.4741
  100.0000
   99.5947
   98.4488
  100.0000
  100.0000
   98.7603
   92.1253
   98.4765


AverageAccuracy =

   98.8113

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06        8-      59  2.0084e+02  2.9411e+01  6.1811e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       60-      64  1.0681e+03  3.6793e+01  4.0750e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       65-      65  7.0087e+02  4.6358e+01  8.2437e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       55-      67  1.5464e+03  3.4224e+01  4.7956e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       27-      63  5.1098e+02  3.5420e+01  1.9538e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       18-      59  7.4474e+02  3.1832e+01  9.2788e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       24-      62  2.7817e+02  2.9267e+01  5.7276e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       31-      59  2.4510e+02  2.9626e+01  3.5063e-03
    1T  5.9e-06       74-      56  9.5714e+02  4.6532e+01  1.1801e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06        8-      69  5.0189e+02  2.9147e+01  6.7315e-03
    1T -3.4e-06       22-      60  2.0044e+02  3.8622e+01  3.0107e-03
    1T  3.5e-06       71-      66  4.8382e+02  3.5400e+01  1.1112e-06
    1T  2.7e-06       28-      61  5.2288e+02  3.5329e+01  4.9696e-06
    1T -1.1e-07        1-      60  2.5611e+02  3.2632e+01  3.4965e-03
    1T  6.0e-06       18-      64  8.2481e+02  3.3088e+01  3.5861e-06
    1T -6.7e-06       15-      62  4.0996e+02  2.6561e+01  4.1061e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       57-      68  4.7628e+02  3.2907e+01  6.3091e-04
    1T  8.2e-06        2-      68  4.2532e+02  3.3267e+01  5.0224e-06
    1T -5.9e-07        3-      52  2.4779e+02  3.3238e+01  7.8003e-03
    1T  6.7e-06       41-      59  2.8070e+02  3.8300e+01  8.1514e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       59-      56  3.0817e+02  5.3688e+01  2.1864e-06
    1T -3.1e-06       29-      69  4.1172e+02  3.1777e+01  5.1914e-03
    1T  8.9e-06       54-      57  3.9808e+02  5.1419e+01  8.9749e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.7e-06       35-      56  2.7412e+02  4.0846e+01  3.2489e-03
    1T  4.6e-06       59-      49  2.0000e+02  3.7667e+01  3.5195e-03
    1T  2.9e-06       48-      56  9.6071e+02  3.9744e+01  1.3870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       73-      50  2.0748e+02  4.8829e+01  2.5424e-06
    1T  5.5e-06       12-      60  4.6606e+02  4.1951e+01  1.7725e-03
    1T  7.7e-06       30-      53  2.4279e+02  4.0899e+01  1.1395e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       10-      66  1.9063e+02  3.9574e+01  2.2629e-03
    1T  9.3e-06       44-      54  3.7979e+02  3.8193e+01  5.2054e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       34-      64  1.8272e+02  3.8653e+01  1.5182e-03
    1T -4.3e-06       52-      60  1.8447e+02  3.6203e+01  2.8586e-03
    1T  7.4e-06       47-      51  3.7539e+02  4.7277e+01  3.3108e-03
    1T  9.0e-06        1-      61  1.9085e+02  3.7444e+01  1.8585e-05
    1T  4.4e-06       64-      64  2.4008e+02  4.5443e+01  3.6084e-05
    1T  4.1e-06       64-      55  2.2568e+02  3.6822e+01  3.8329e-03
    1T -9.3e-06       40-      55  2.1780e+02  4.1160e+01  2.9225e-03
    1T  4.3e-06       63-      51  2.7300e+02  3.4687e+01  4.7847e-03
    1T  7.6e-06       34-      51  2.6273e+02  4.6314e+01  3.6860e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       27-      51  3.0695e+02  3.1907e+01  4.9404e-03

indexes =

  Columns 1 through 13

    18    42    91   196   150   141   131    42   185    21   140   158   193

  Columns 14 through 26

   133   106   106   194    20   155   138    16    58    60    13   181     7

  Columns 27 through 30

    70   180   110     1


Accuracy =

   97.7522


Accuracy =

   97.8809


Accuracy =

   97.7890


Accuracy =

   97.8502


Accuracy =

   97.8441


Accuracy =

   97.7890


Accuracy =

   97.8788


Accuracy =

   97.8012


Accuracy =

   97.7298


Accuracy =

   97.8972


Accuracy =9.789719e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.4499
  100.0000
   99.4983
   99.1263
   98.1841
   99.8606
   99.9691
   95.7084
  100.0000
   99.7642
   98.3402
   99.8853
   99.7582
   99.8968
   92.6433
  100.0000


AverageAccuracy =

   98.8803

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       40-      37  2.2784e+02  1.0021e+02  1.0034e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       64-      64  4.9477e+02  4.5589e+01  7.4841e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       13-      66  4.3021e+02  3.5890e+01  2.4699e-07
    1T  3.5e-06        1-      55  3.8664e+02  7.3397e+01  1.7827e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06        8-      57  1.9007e+02  3.1807e+01  1.4131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       19-      55  3.0324e+02  3.4237e+01  5.7397e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       14-      65  5.0104e+02  3.9427e+01  3.4030e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-07       65-      61  3.4158e+02  5.0241e+01  1.6669e-07
    1T  4.6e-06       12-      63  4.3641e+02  3.7106e+01  2.7678e-03
    1T  3.2e-06       51-      64  2.9553e+02  3.8307e+01  4.5573e-06
    1T -3.0e-06       74-      65  3.0672e+02  7.0606e+01  3.1588e-03
    1T  2.3e-06       75-      52  2.4947e+02  4.5197e+01  1.4044e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       54-      39  2.6685e+02  4.9028e+01  6.7172e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       19-      64  8.6200e+02  4.3110e+01  6.7786e-03
    1T  2.3e-06       67-      58  4.0573e+02  5.8084e+01  1.2834e-06
    1T -4.5e-06       42-      63  3.7804e+02  3.9899e+01  2.1452e-03
    1T  2.1e-06        5-      58  3.4959e+02  7.5501e+01  6.3968e-07
    1T -7.7e-06       35-      54  4.3529e+02  4.1162e+01  1.0522e-02
    1T  7.5e-07        3-      54  3.7250e+02  7.6382e+01  8.5471e-07
    1T -4.2e-06       19-      55  8.0644e+02  5.4691e+01  1.4821e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        4-      59  1.0719e+03  4.2108e+01  5.8655e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       62-      54  2.2417e+02  4.6559e+01  4.1523e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       18-      57  2.4192e+02  4.8248e+01  6.5320e-07
    1T  3.5e-06       34-      53  8.4237e+02  4.6376e+01  1.3650e-05
    1T -9.0e-06       51-      64  2.0651e+02  4.6871e+01  2.6505e-03
    1T  3.3e-06       75-      66  1.8961e+02  4.7187e+01  1.1294e-06
    1T  1.2e-06        7-      65  1.7967e+02  4.9222e+01  4.3162e-03
    1T  7.4e-06       45-      62  4.9707e+02  4.8939e+01  2.3484e-03
    1T -6.5e-06       44-      67  4.7718e+02  5.2022e+01  5.7249e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       65-      64  2.8319e+02  4.5242e+01  2.0538e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-07       16-      64  1.9835e+02  5.4748e+01  5.6779e-07

indexes =

  Columns 1 through 13

     9    36   100   179   157   184   198   139    50    31   135     7    70

  Columns 14 through 26

    60   169    34   185    34    82   117    89    47    71   126    86    48

  Columns 27 through 30

   150    31   132   110


Accuracy =

   98.1892


Accuracy =

   98.1239


Accuracy =

   98.1035


Accuracy =

   98.1545


Accuracy =

   98.0851


Accuracy =

   98.1607


Accuracy =

   98.1505


Accuracy =

   98.1362


Accuracy =

   98.1545


Accuracy =

   98.0994


Accuracy =9.809942e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.8900
  100.0000
  100.0000
   98.6486
   99.9587
  100.0000
   99.7841
   96.3649
   99.9288
   99.9325
   99.6891
  100.0000
  100.0000
   99.5863
   92.0997
  100.0000


AverageAccuracy =

   99.1177

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines;
{Undefined function or variable 'indian_pines'.
} 
image_gt=indian_pines_gt;
size(image)
[Warning: MATLAB has disabled some advanced graphics rendering features by
switching to software OpenGL. For more information, click <a
href="matlab:opengl('problems')">here</a>.] 

ans =

     1     1


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end
{Undefined function or variable 'image'.
} 


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);
{Error using reshape
To RESHAPE the number of elements must not change.
} 

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1

{Undefined function or variable 'flatImage'.
} 

 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
{Error using randi
First input must be a positive scalar integer value IMAX, or two integer values
[IMIN IMAX] with IMIN less than or equal to IMAX.
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
{Operation terminated by user during
parallel.internal.cluster.FileStorage/getEntityNamesFromLocation (line 748)


In parallel.internal.cluster.FileStorage/getEntityLocations (line 448)
            [locations, IDs] = getEntityNamesFromLocation(obj, storageLocation,
            type);

In parallel.internal.cluster.FileStorage/findProxies (line 415)
            [entityLocations, IDs] = getEntityLocations(obj, parentLocation);

In parallel.internal.cluster.CJSSupport/getChildren (line 372)
            [proxs, ctors] = obj.Storage.findProxies( parentSId );

In
parallel.internal.cluster.CJSSupport>@(x,y)obj.getChildren(x,y{:},emptyTaskList,variantToForce)
(line 526)
            tl = arrayfun( @(x, y) obj.getChildren( ...

In parallel.internal.cluster.CJSSupport/getTasks (line 526)
            tl = arrayfun( @(x, y) obj.getChildren( ...

In parallel.internal.cluster.CJSJobMixin/getTasks (line 30)
                tl = obj.Support.getTasks( obj, obj.hGetSupportID() );

In parallel.Job/get.Tasks (line 222)
                tl = obj.getTasks();

In parallel.internal.cluster.CJSJobMethods.getJobStateFromTasks (line 148)
                stateFromTasks = iDeriveJobStateFromTasks( job.Tasks );

In parallel.internal.cluster.CJSJobMixin/hGetStateFromTasks (line 48)
            s = CJSJobMethods.getJobStateFromTasks( job );

In parallel.cluster.CJSCluster/hGetJobState (line 272)
            stateFromTasks = job.hGetStateFromTasks();

In parallel.internal.cluster.CJSJobMixin/getStateEnum (line 150)
                s{ii} = cluster.hGetJobState( thisJob, thisJob.hGetProperty(
                'StateEnum' ) );

In parallel.Job/get.StateEnum (line 238)
            se = obj.getStateEnum();

In parallel.Job/get.State (line 230)
            s = obj.StateEnum.Name;

In parallel.internal.customattr.CustomGetSet>iVectorisedGetHelper (line 117)
            val = {obj.(name)}';

In
parallel.internal.customattr.CustomGetSet>@(a,b,c)iVectorisedGetHelper(obj,a,b,c)
(line 91)
            helperFunc = @(a,b,c) iVectorisedGetHelper(obj,a,b,c);

In parallel.internal.customattr.CustomGetSet/doVectorisedGet (line 92)
            [values, handled] = cellfun( helperFunc, propsToAccess, handled,
            existingValues, ...

In parallel.internal.customattr.CustomGetSet/hVectorisedGet (line 65)
            [values, handled] = obj.doVectorisedGet( propsToAccess, handled,
            values );

In parallel.internal.customattr.GetSetImpl>iAccessProperties (line 322)
        v = hVectorisedGet( obj, name, handled, existingValue );

In parallel.internal.customattr.GetSetImpl>iGetAllPropertiesVec (line 264)
    vals_access  = iAccessProperties( objOrObjs, propsToAccess, ...

In parallel.internal.customattr.GetSetImpl.getImpl (line 133)
                    vcell = iGetAllPropertiesVec( objOrObjs, propsToGet,
                    propsToAccess, ...

In parallel.internal.customattr.CustomGetSet/get (line 30)
                vcell = GetSetImpl.getImpl( varargin{:} );

In parallel.internal.pool.InteractiveClient/pRemoveOldJobs (line 474)
            state = jobs.get({'State'});

In parallel.internal.pool.InteractiveClient/start (line 315)
                    obj.pRemoveOldJobs(sched);

In parallel.Pool>iStartClient (line 791)
spmdInitialized = client.start(poolType , numWorkers, cluster, ...

In parallel.Pool.hBuildPool (line 585)
                iStartClient(client, 'pool', cluster, guiMode, supportRestart,
                argsList);

In parallel.internal.pool.doParpool (line 18)
    pool = parallel.Pool.hBuildPool(constructorArgs{:});

In parpool (line 98)
    pool = parallel.internal.pool.doParpool(varargin{:});

In create_centered_features_bands (line 4)
parpool(36)
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       39-      54  5.8890e+02  3.8834e+01  7.2756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-07       25-      59  3.6549e+02  3.9955e+01  6.3727e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       18-      50  3.3941e+02  3.3130e+01  3.3918e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       25-      49  2.1381e+02  5.5805e+01  1.5415e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-07       70-      62  2.4906e+02  5.3612e+01  3.3080e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       24-      54  4.4795e+02  3.8541e+01  1.9993e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-07       65-      57  1.7300e+03  4.1712e+01  5.9497e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       50-      53  2.9571e+02  5.9304e+01  7.0568e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-07       26-      62  3.7768e+02  3.5833e+01  4.5425e-03
    1T -9.4e-06       67-      68  5.5657e+02  3.4598e+01  8.8599e-07
    1T -6.0e-06       66-      59  3.0078e+02  3.2403e+01  4.2154e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       29-      61  2.8705e+03  5.7408e+01  6.5399e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       64-      54  4.1296e+02  3.7774e+01  5.5722e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       41-      72  5.1045e+02  3.3905e+01  4.4335e-07
    1T -3.9e-06       17-      56  1.9730e+02  3.6638e+01  2.2681e-07
    1T  3.2e-06       67-      42  1.9806e+02  4.3534e+01  1.3927e-03
    1T -4.6e-06       23-      50  1.4047e+02  3.8465e+01  4.1667e-07
    1T -6.9e-07       46-      69  3.7129e+02  3.6374e+01  4.6717e-03
    1T  6.2e-06       63-      56  2.1933e+02  4.1227e+01  5.3876e-07
    1T  2.4e-06       18-      57  1.7956e+02  3.6172e+01  2.4984e-06
    1T -2.8e-06       67-      41  3.3456e+02  4.7713e+01  4.7401e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       35-      49  2.0802e+02  3.8458e+01  5.2268e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       65-      53  2.4352e+02  6.3494e+01  1.5089e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       63-      53  1.5871e+02  4.2491e+01  2.2048e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       58-      60  1.9967e+02  3.6983e+01  3.7953e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       20-      58  1.6867e+02  4.3687e+01  1.0010e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       24-      60  1.6898e+02  4.1635e+01  3.1144e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       17-      57  1.8818e+02  4.1099e+01  4.1947e-07
    1T -5.2e-06       70-      62  1.7794e+02  3.9676e+01  2.9840e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       74-      49  1.7049e+02  4.1388e+01  6.6531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       23-      60  1.8870e+02  4.8306e+01  1.0084e-03
    1T  1.9e-06       35-      64  1.6565e+02  3.9962e+01  3.1700e-03
    1T  7.8e-06       71-      64  5.7618e+02  4.3308e+01  4.8597e-03
    1T -6.8e-06       17-      53  1.5321e+02  3.8984e+01  1.4443e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       36-      55  1.4821e+02  4.2526e+01  3.2019e-03
    1T -2.2e-06       65-      56  2.3197e+02  4.5272e+01  5.0592e-03
    1T  8.8e-06       13-      66  1.5823e+02  4.1666e+01  3.2087e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       33-      59  2.1296e+02  4.5702e+01  1.8084e-03
    1T  1.2e-06       17-      50  3.8830e+02  4.5013e+01  6.3573e-07
    1T -2.7e-06       68-      54  2.0762e+02  4.2230e+01  5.3076e-03
    1T -6.2e-06       15-      62  1.5978e+02  4.2320e+01  2.6464e-03
    1T  9.9e-06       30-      61  1.9249e+02  3.7806e+01  6.3746e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       31-      46  3.7565e+03  1.3730e+02  1.4710e-05
    1T -7.7e-07       48-      67  1.5163e+02  4.1782e+01  1.7320e-03
    1T  2.9e-06       62-      58  2.2944e+02  4.6814e+01  2.8074e-03
    1T  4.7e-06       16-      59  1.7835e+02  3.9655e+01  3.1619e-03
    1T  9.8e-06       16-      57  1.8258e+02  4.4663e+01  2.2692e-06

indexes =

  Columns 1 through 13

   163   136   153    49    95    58    20    23   104    60    38   112   161

  Columns 14 through 26

    66    80   140    34   108   183   100    28    62    18   175    67    39

  Columns 27 through 30

   103    89   182   129


Accuracy =

   98.3550


Accuracy =

   98.3754


Accuracy =

   98.3733


Accuracy =

   98.3631


Accuracy =

   98.4101


Accuracy =

   98.4162


Accuracy =

   98.3733


Accuracy =

   98.3550


Accuracy =

   98.3509


Accuracy =

   98.3182


Accuracy =9.831823e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.5047
  100.0000
   99.9440
   98.4140
   99.3814
   99.9721
   99.9383
   96.2153
  100.0000
   99.5278
   99.7936
  100.0000
   98.5594
  100.0000
   94.5002
  100.0000


AverageAccuracy =

   99.1094

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines;
{Undefined function or variable 'indian_pines'.
} 
image_gt=indian_pines_gt;
size(image)
[Warning: MATLAB has disabled some advanced graphics rendering features by
switching to software OpenGL. For more information, click <a
href="matlab:opengl('problems')">here</a>.] 

ans =

     1     1


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end
{Undefined function or variable 'image'.
} 


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);
{Error using reshape
To RESHAPE the number of elements must not change.
} 

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1

{Undefined function or variable 'flatImage'.
} 

 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
{Error using randi
First input must be a positive scalar integer value IMAX, or two integer values
[IMIN IMAX] with IMIN less than or equal to IMAX.
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true

{Error using BPdual (line 122)
Incorrect dimensions for matrix multiplication. Check that the number of
columns in the first matrix matches the number of rows in the second matrix. To
perform elementwise multiplication, use '.*'.

Error in as_nnls (line 66)
    BPdual(A,b,-inf,c,lam,active,state,y,S,R,opts);

Error in create_centered_features_bands (line 5)
parfor i=1:rows
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       25-      62  1.3309e+02  4.0637e+01  1.8164e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       55-      59  2.5983e+02  3.6942e+01  6.3870e-03
    1T  8.7e-06       54-      56  6.1750e+02  3.4039e+01  4.6889e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       40-      65  4.7449e+02  3.1217e+01  1.0272e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-07       28-      42  2.3203e+02  4.6104e+01  2.9993e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-06       10-      62  3.6247e+02  4.2326e+01  7.9422e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       52-      62  3.3247e+02  3.9262e+01  4.5204e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06       49-      19  2.2405e+02  5.2701e+01  5.4577e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       48-      56  2.1607e+02  4.0740e+01  3.3903e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       56-      62  5.1850e+02  3.1163e+01  8.1176e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06        9-      58  1.5443e+02  3.6907e+01  5.0977e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07       19-      55  2.7083e+02  4.1164e+01  4.8902e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       36-      58  1.9899e+02  4.0249e+01  2.0399e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06        7-      68  7.3566e+02  4.9654e+01  2.8791e-03
    1T  8.1e-06       49-      56  3.3576e+02  4.2167e+01  4.6788e-03
    1T  8.2e-06       74-      61  2.2454e+02  5.1639e+01  4.7539e-03
    1T  4.8e-06        9-      64  6.7379e+02  3.5898e+01  6.9374e-07
    1T  6.8e-07       52-      64  3.0548e+02  3.9623e+01  8.8352e-03
    1T -3.0e-06       43-      64  2.1820e+02  4.2894e+01  1.5883e-03
    1T  3.8e-06       67-      60  5.4863e+02  4.1302e+01  4.0965e-03
    1T -4.0e-06       44-      61  2.3185e+02  4.1691e+01  3.3259e-03
    1T  4.3e-06        7-      55  2.0969e+02  4.0152e+01  1.0963e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       61-      46  2.7475e+02  5.0071e+01  3.0805e-06
    1T  9.3e-06       19-      59  2.3272e+02  3.8238e+01  5.9688e-03
    1T -7.9e-06       32-      45  2.0702e+02  4.6496e+01  4.2806e-04
    1T  3.5e-06       42-      64  6.4437e+02  3.7147e+01  9.7830e-07
    1T  4.7e-06       15-      59  2.2654e+02  4.1237e+01  3.0952e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       31-      49  1.1050e+03  7.3330e+01  2.7498e-05
    1T -6.4e-06       11-      52  7.1619e+02  5.1374e+01  5.5360e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       53-      50  1.9294e+02  4.1129e+01  2.2317e-05
    1T  5.5e-06       11-      57  1.7538e+02  4.3573e+01  1.9203e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       41-      45  2.6927e+02  4.2957e+01  2.6341e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        7-      58  2.0020e+02  4.2963e+01  1.2927e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-07       45-      58  1.5732e+02  4.0303e+01  2.8866e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       19-      49  2.4033e+02  4.2593e+01  5.4695e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       50-      61  1.8049e+02  3.8356e+01  3.5426e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-07       18-      63  1.7404e+02  3.9973e+01  3.5286e-08
    1T  9.9e-06       63-      54  2.3215e+02  4.2387e+01  4.7055e-03
    1T  8.9e-06       16-      60  1.6817e+02  4.0533e+01  2.7987e-06
    1T  3.0e-06       50-      61  1.6175e+02  3.9258e+01  5.4375e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06        3-      61  2.0318e+02  4.5814e+01  2.9905e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       20-      58  2.2058e+02  4.3612e+01  1.9959e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       66-      63  2.1668e+02  4.1067e+01  3.8528e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       66-      50  4.5786e+02  4.2586e+01  3.2795e-03
    1T  1.4e-06       20-      43  2.0091e+02  3.9944e+01  4.4276e-03
    1T  9.2e-06       56-      53  2.9678e+02  4.3980e+01  3.6760e-06
    1T  7.5e-06       13-      59  2.1480e+02  4.1843e+01  4.1244e-06
    1T  8.9e-06       41-      59  2.1854e+02  4.0897e+01  7.5845e-06
    1T  4.7e-07       61-      55  8.1190e+02  3.1928e+01  4.9801e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06       65-      55  2.4496e+02  3.8597e+01  1.9584e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-07        8-      64  1.5900e+02  3.6482e+01  5.8014e-07
    1T  4.0e-07        3-      53  2.1986e+02  4.8614e+01  1.8697e-07
    1T  7.2e-06       31-      58  2.1171e+02  4.0243e+01  4.4783e-03
    1T  3.5e-06       67-      46  1.9781e+02  4.2217e+01  1.6368e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       56-      50  2.5387e+02  4.2478e+01  3.4132e-03

indexes =

  Columns 1 through 13

    35   102    63    12    51   190     6    71    33   109    12    67   101

  Columns 14 through 26

   110    71    94    66     5   115    79   170    80   105    66   192    13

  Columns 27 through 30

   133   164   151   136


Accuracy =

   97.8948


Accuracy =

   97.9459


Accuracy =

   97.9908


Accuracy =

   98.0480


Accuracy =

   98.0970


Accuracy =

   97.9377


Accuracy =

   97.9867


Accuracy =

   98.0276


Accuracy =

   98.0112


Accuracy =

   98.0174


Accuracy =9.801736e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.8353
   99.9703
   99.8883
   98.2567
   99.0074
   99.9721
   99.6913
   97.3328
  100.0000
   99.3588
   98.4552
  100.0000
   99.7579
   99.3827
   91.1179
   99.3869


AverageAccuracy =

   98.8383

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

    11     3    21    41   145   147   192   151    40   159    97    83   179

  Columns 14 through 26

    18    77   144    36    15   133   133   169    88   147    12    61    78

  Columns 27 through 30

    23    88    40   157

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   68.8376


Accuracy =

   69.3552


Accuracy =

   69.4630


Accuracy =

   69.2366


Accuracy =

   69.8404


Accuracy =

   70.0992


Accuracy =

   69.3768


Accuracy =

   69.7110


Accuracy =

   69.2366


Accuracy =

   70.1747


Accuracy =7.017468e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   33.3333
   71.1077
   48.0744
   50.4630
   75.0572
   83.1818
    7.6923
   86.1432
    5.5556
   65.2273
   73.7292
   52.0599
   77.4194
   81.7863
   65.6160
   64.2857


AverageAccuracy =

   58.7958

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   160   146   158   194   107    56   182    50    57    76   161     4    83

  Columns 14 through 26

   165    47    24    47   183    31    66    14    27    14    51   190   165

  Columns 27 through 30

    69    79    80    45

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.6248


Accuracy =

   69.1503


Accuracy =

   69.2150


Accuracy =

   70.1316


Accuracy =

   69.6895


Accuracy =

   69.3552


Accuracy =

   69.8943


Accuracy =

   68.9239


Accuracy =

   68.9778


Accuracy =

   68.8700


Accuracy =6.886996e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   11.6279
   70.2243
   48.1333
   57.0093
   70.2517
   81.9970
    7.6923
   79.1667
   50.0000
   63.2420
   72.9730
   46.3687
   65.7754
   82.4760
   69.0544
   66.6667


AverageAccuracy =

   58.9162

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   151   101   180   188    88   134    15   169   106    34    71    71    71

  Columns 14 through 26

    82    99    29    48   162     8    35    99    83     7   174   130   174

  Columns 27 through 30

    46   109    38   198

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.0086


Accuracy =

   69.1164


Accuracy =

   68.7931


Accuracy =

   69.9030


Accuracy =

   68.9116


Accuracy =

   69.8599


Accuracy =

   68.8901


Accuracy =

   68.7392


Accuracy =

   68.9871


Accuracy =

   69.2026


Accuracy =6.920259e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   38.0952
   68.6579
   30.9840
   59.2593
   66.5148
   82.8528
   26.9231
   87.9908
    5.5556
   65.4545
   77.6079
   41.0781
   69.3548
   86.1014
   68.2857
   67.8571


AverageAccuracy =

   58.9108

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

    69    72   165   132     9    46    27   127   140    78    15   154   149

  Columns 14 through 26

   151   200   116    83    26   144    95    98    25    87    29   126    33

  Columns 27 through 30

     8    82    11    41

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   70.6555


Accuracy =

   71.2699


Accuracy =

   70.3536


Accuracy =

   71.0112


Accuracy =

   70.2458


Accuracy =

   70.9250


Accuracy =

   70.6339


Accuracy =

   70.5045


Accuracy =

   70.6878


Accuracy =

   70.3105


Accuracy =7.031048e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   21.4286
   65.9179
   54.2781
   55.0926
   73.2877
   80.7519
   23.0769
   82.6389
   38.8889
   62.2146
   75.7535
   49.4424
   68.2796
   86.0892
   68.5714
   75.0000


AverageAccuracy =

   61.2945

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

     8   131    49   173    41   149    85    93    44     8   101   110    12

  Columns 14 through 26

   195    71    29    23    86    61    94    33   162    10    57   193   196

  Columns 27 through 30

   147    59    28    93

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.8296


Accuracy =

   71.1128


Accuracy =

   69.7542


Accuracy =

   70.3041


Accuracy =

   68.9670


Accuracy =

   70.3041


Accuracy =

   69.6571


Accuracy =

   70.2933


Accuracy =

   69.4738


Accuracy =

   70.4227


Accuracy =7.042269e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   40.4762
   67.1053
   45.4667
   69.1589
   62.9291
   82.6484
   26.9231
   85.6813
   44.4444
   71.9498
   72.6700
   45.5390
   69.7297
   91.0279
   62.5000
   83.3333


AverageAccuracy =

   63.8489

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   112    80   162     8    73    11    23    58    56     2   181    51    44

  Columns 14 through 26

   129    77    73   123    89   109   158    29   144   114   123    56    53

  Columns 27 through 30

   134    90   111   173

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   70.4183


Accuracy =

   70.4614


Accuracy =

   70.4398


Accuracy =

   71.4101


Accuracy =

   71.3346


Accuracy =

   71.0759


Accuracy =

   70.1272


Accuracy =

   70.8279


Accuracy =

   70.2781


Accuracy =

   71.0759


Accuracy =7.107589e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   23.8095
   67.8045
   47.8610
   56.0748
   71.5596
   85.8006
   61.5385
   86.6051
   66.6667
   59.1166
   77.6529
   54.1045
   66.6667
   85.1658
   67.6218
   86.9048


AverageAccuracy =

   66.5596

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

     4   130   145   134    12   196    50    20   102   108    84   141   177

  Columns 14 through 26

    91    80   179    39   194    44    22   150   167   132     1    90    86

  Columns 27 through 30

   138   129    90    59

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.7166


Accuracy =

   69.3825


Accuracy =

   69.9321


Accuracy =

   69.0699


Accuracy =

   69.2855


Accuracy =

   69.1023


Accuracy =

   69.8028


Accuracy =

   69.9321


Accuracy =

   70.0075


Accuracy =

   70.1261


Accuracy =7.012609e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   19.0476
   69.5820
   52.1277
   57.6744
   69.9541
   77.6596
   23.0769
   84.8276
   61.1111
   63.5950
   73.3933
   44.3203
   72.1925
   87.4236
   73.8506
   70.2381


AverageAccuracy =

   62.5046

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   141    89    55   148   135   198    14    14   170    30   139   196    59

  Columns 14 through 26

    71   194   171    22   153   120   163   138   139   117    27    14   105

  Columns 27 through 30

   128    78    85   128

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.3277


Accuracy =

   69.1230


Accuracy =

   70.8145


Accuracy =

   69.7156


Accuracy =

   69.3816


Accuracy =

   69.5647


Accuracy =

   69.8233


Accuracy =

   69.8664


Accuracy =

   69.6940


Accuracy =

   69.1554


Accuracy =6.915535e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   38.0952
   68.4900
   46.3479
   58.6047
   60.1831
   84.4646
   57.6923
   79.2148
   55.5556
   62.9124
   73.5108
   52.2388
   72.5806
   84.2657
   64.4886
   71.4286


AverageAccuracy =

   64.3796

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

   175   152   101   155   155    25   186   193    76   148   169   100    94

  Columns 14 through 26

    37   123    71   178   142   102    92    85   180   121   126   114   167

  Columns 27 through 30

    34   114   150   150

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.5156


Accuracy =

   69.4726


Accuracy =

   69.9892


Accuracy =

   69.8816


Accuracy =

   70.0538


Accuracy =

   69.2142


Accuracy =

   69.1712


Accuracy =

   70.3229


Accuracy =

   69.6340


Accuracy =

   68.9451


Accuracy =6.894510e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   26.1905
   64.2471
   37.5830
   55.3488
   69.8630
   84.4646
   76.9231
   87.9350
    5.5556
   58.9103
   77.2890
   49.2537
   62.1622
   84.5684
   68.6782
   77.3810


AverageAccuracy =

   61.6471

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


indexes =

  Columns 1 through 13

    91    28    84   173    22   106   149   177   157    50   110    45     3

  Columns 14 through 26

   134    26    57   179   110    71   142   197    75   145    82     5    87

  Columns 27 through 30

    66    87    43    14

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   69.5441


Accuracy =

   69.8890


Accuracy =

   69.5441


Accuracy =

   70.2662


Accuracy =

   69.3501


Accuracy =

   69.2747


Accuracy =

   70.1153


Accuracy =

   69.1023


Accuracy =

   69.4795


Accuracy =

   69.7489


Accuracy =6.974890e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

    7.1429
   67.0015
   43.3912
   53.0233
   68.1922
   83.5098
   61.5385
   88.4793
   27.7778
   61.7747
   76.9335
   43.0970
   75.2688
   85.0394
   71.6332
   70.9302


AverageAccuracy =

   61.5458

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       52-      73  2.6339e+03  5.4652e+01  3.8866e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       75-      67  1.8374e+03  4.7512e+01  2.0962e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-06       75-      67  1.7695e+03  4.7932e+01  6.5279e-05
    1T  5.9e-06       52-      72  3.1019e+03  5.2278e+01  5.4840e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       21-      69  2.1085e+03  4.9390e+01  1.2538e-05

indexes =

  Columns 1 through 13

   169   131   181    63     6   153    23    92    57    30    96   168    58

  Columns 14 through 26

   102   122    19    45    87    53   137   158    80    18    52   154   116

  Columns 27 through 30

    12    82    61   108

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0552


Accuracy =

   96.2169


Accuracy =

   95.6995


Accuracy =

   96.1414


Accuracy =

   96.2169


Accuracy =

   96.1845


Accuracy =

   95.8720


Accuracy =

   95.9797


Accuracy =

   96.1845


Accuracy =

   96.2061


Accuracy =9.620608e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   98.2198
   93.0851
   89.2523
   98.8532
   94.8407
   66.6667
  100.0000
   73.6842
   96.4813
   96.8018
   97.2222
   96.7568
   99.4760
   83.6676
   85.7143


AverageAccuracy =

   91.4737

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

    12    27    29   133   108   184    27    78   107   192   176   177   180

  Columns 14 through 26

    90   125    31   198   106     7    13   139   197   145   197    62   164

  Columns 27 through 30

   179   109   115   193


Accuracy =

   94.8132


Accuracy =

   94.7478


Accuracy =

   94.8234


Accuracy =

   94.8111


Accuracy =

   94.8846


Accuracy =

   94.7478


Accuracy =

   94.8050


Accuracy =

   94.8132


Accuracy =

   94.8662


Accuracy =

   94.9377


Accuracy =9.493772e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.1736
   99.3179
   99.6654
   97.7760
   98.3072
   99.9721
   99.9383
   91.0928
  100.0000
   97.3702
   97.8238
  100.0000
   99.0326
   98.3556
   79.9483
   99.1458


AverageAccuracy =

   97.3075

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

    61   139    79    26   159    92   184   151   127   179    20    47     5

  Columns 14 through 26

   129   164    69   129   139    39    99    52   122   122   120   103    90

  Columns 27 through 30

    89   123    61   103


Accuracy =

   94.9443


Accuracy =

   94.8341


Accuracy =

   94.8769


Accuracy =

   94.7912


Accuracy =

   94.8647


Accuracy =

   94.7463


Accuracy =

   94.7422


Accuracy =

   94.8688


Accuracy =

   94.7973


Accuracy =

   94.8504


Accuracy =9.485039e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   98.7377
   99.9406
   99.7762
   97.6266
   98.2723
   99.9721
   99.7528
   90.2834
   99.9287
   95.4132
   99.1744
  100.0000
   99.3983
   99.1727
   81.0502
   99.0232


AverageAccuracy =

   97.3451

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

   146    44   189    26   160    44   122    94   190    69   117   126    20

  Columns 14 through 26

     1   156    87    26   191   112   159    14   124   185   123    62   171

  Columns 27 through 30

    64    31    33   147


Accuracy =

   94.7803


Accuracy =

   94.6273


Accuracy =

   94.7967


Accuracy =

   94.7926


Accuracy =

   94.7946


Accuracy =

   94.7640


Accuracy =

   94.8293


Accuracy =

   94.8395


Accuracy =

   94.8069


Accuracy =

   94.9150


Accuracy =9.491501e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.6701
   99.4364
   99.7205
   97.2288
   99.4637
  100.0000
   99.8766
   91.7263
  100.0000
   96.8297
   97.5181
   99.9427
   99.8800
   99.1761
   78.2999
   99.3313


AverageAccuracy =

   97.3813

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

   196     1   173     9   195   187   109   179    98   113    84   195    61

  Columns 14 through 26

    77    80   112    24    20    21   157   144   194    48     7    85    83

  Columns 27 through 30

    98   157    90    57


Accuracy =

   94.8231


Accuracy =

   94.9374


Accuracy =

   94.8803


Accuracy =

   94.8782


Accuracy =

   94.8578


Accuracy =

   94.8905


Accuracy =

   94.9946


Accuracy =

   94.8946


Accuracy =

   94.9966


Accuracy =

   94.9231


Accuracy =9.492314e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.3403
   99.9111
   99.8326
   97.8605
   98.2716
   99.9161
   99.8765
   91.0259
   99.9465
   96.6307
   98.7590
  100.0000
   98.7966
   99.1744
   79.6747
   99.5107


AverageAccuracy =

   97.4080

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

     7    89   171   172    13   104    54    89    47    77    67    27   107

  Columns 14 through 26

    65   184   181     5    97   114   128    50     9    90   156   117    56

  Columns 27 through 30

    41   192   105   194


Accuracy =

   95.0374


Accuracy =

   95.0435


Accuracy =

   95.0312


Accuracy =

   95.0476


Accuracy =

   95.0537


Accuracy =

   95.0639


Accuracy =

   95.0578


Accuracy =

   95.0680


Accuracy =

   95.1027


Accuracy =

   95.0802


Accuracy =9.508023e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   98.7885
   99.7922
   99.6083
   96.8329
   99.2155
   99.9441
   99.9074
   90.5238
   99.9466
   96.9983
   99.4861
  100.0000
   98.5577
   98.2438
   81.5833
   99.6337


AverageAccuracy =

   97.4414

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

     5   124   176   111   192   109    67    99   126   115   106   137    58

  Columns 14 through 26

   161    49    80    67   186   163    82    64    57    58    28    97    72

  Columns 27 through 30

   109    39   110     1


Accuracy =

   94.7337


Accuracy =

   94.7256


Accuracy =

   94.6786


Accuracy =

   94.6419


Accuracy =

   94.6357


Accuracy =

   94.6582


Accuracy =

   94.7419


Accuracy =

   94.6847


Accuracy =

   94.6500


Accuracy =

   94.6664


Accuracy =9.466637e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.0094
   99.8813
   99.8881
   97.8656
   98.8454
   99.9721
   99.9074
   91.6274
   99.9288
   97.1352
   96.6839
  100.0000
   99.3969
   96.4066
   77.2520
   98.7195


AverageAccuracy =

   97.0325

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04

indexes =

  Columns 1 through 13

    36    54    68    95    38   159   121    87   101   146    25    52   134

  Columns 14 through 26

    51   197    12   179    83   192   104    65    36   125    77   183    11

  Columns 27 through 30

    50   141   136   191


Accuracy =

   94.7171


Accuracy =

   94.8335


Accuracy =

   94.7273


Accuracy =

   94.8233


Accuracy =

   94.8886


Accuracy =

   94.6354


Accuracy =

   94.6762


Accuracy =

   94.7926


Accuracy =

   94.8069


Accuracy =

   94.7742


Accuracy =9.477424e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.2857
   99.1395
   99.7762
   97.8571
   98.1007
   99.9442
   99.8767
   90.8458
  100.0000
   96.4213
   99.4819
   99.8853
   98.9170
   98.9648
   79.5047
   98.7775


AverageAccuracy =

   97.2986

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04

indexes =

  Columns 1 through 13

   186   111   149   131   186    98    91    56    89     6   200    45   115

  Columns 14 through 26

    50    85    74   149   142    21    80   188    81    69    23    54   115

  Columns 27 through 30

   131   186   158    97


Accuracy =

   94.9253


Accuracy =

   94.8702


Accuracy =

   94.9253


Accuracy =

   94.9232


Accuracy =

   94.8845


Accuracy =

   94.8988


Accuracy =

   94.9028


Accuracy =

   94.9151


Accuracy =

   94.9090


Accuracy =

   94.7987


Accuracy =9.479873e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.2287
   99.5554
   99.6650
   97.4623
   99.1326
   99.9441
   99.9074
   91.2140
   99.7863
   96.5680
   99.2731
  100.0000
   99.0350
   98.4504
   78.6484
   99.4482


AverageAccuracy =

   97.3324

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04

indexes =

  Columns 1 through 13

   150    26     7    55     3   136    34    87   125    61   161    41    58

  Columns 14 through 26

   156   134    81    77    85   152    80    69   180   156    94    68   167

  Columns 27 through 30

    77    91   169    38


Accuracy =

   94.5914


Accuracy =

   94.5731


Accuracy =

   94.7160


Accuracy =

   94.7425


Accuracy =

   94.7282


Accuracy =

   94.7119


Accuracy =

   94.6915


Accuracy =

   94.7017


Accuracy =

   94.5914


Accuracy =

   94.6139


Accuracy =9.461391e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.1767
   99.1400
   99.6089
   97.7002
   98.7190
   99.9721
   99.8765
   91.0821
   99.8753
   96.5308
   99.2746
  100.0000
   98.6715
   99.0683
   77.8622
   98.7790


AverageAccuracy =

   97.2086

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       60-      23  1.8636e+03  3.1355e+01  3.4912e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       75-      24  1.8849e+03  2.3663e+01  3.5568e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      22  1.8580e+03  2.0976e+01  2.9337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       75-      24  1.8889e+03  2.3837e+01  8.6701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       19-      22  1.7943e+03  2.0779e+01  3.6374e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       16-      21  2.4539e+03  2.8851e+01  1.3270e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       19-      22  1.7389e+03  2.1045e+01  3.1295e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       57-      23  1.8467e+03  2.4099e+01  6.8835e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       20-      23  2.6246e+03  2.7512e+01  1.8531e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       47-      23  1.5581e+03  1.9463e+01  6.3485e-04
    1T  4.6e-06       72-      22  1.8190e+03  2.2935e+01  1.2186e-04
    1T -3.8e-06       75-      24  1.9202e+03  2.5125e+01  3.4769e-05
    1T -1.4e-06       17-      22  1.8092e+03  2.3341e+01  2.3154e-05
    1T -3.2e-07       19-      23  2.3649e+03  2.3415e+01  1.0618e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        4-      25  2.6521e+03  2.7339e+01  4.1684e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       11-      21  8.0103e+02  9.3697e+00  1.4291e-03
    1T  9.0e-07       60-      24  2.1523e+03  3.5862e+01  1.2568e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       16-      22  2.1974e+03  2.6267e+01  1.6989e-04
    1T  1.9e-07       22-      21  2.5073e+03  2.8861e+01  2.5980e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       19-      22  2.5165e+03  2.9207e+01  2.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       75-      24  2.0305e+03  2.5911e+01  1.0415e-05
    1T -6.2e-06       19-      22  2.5185e+03  2.9008e+01  2.0261e-04
    1T -1.5e-06       71-      24  3.4892e+03  2.7228e+01  1.6982e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       22-      23  2.4814e+03  2.8777e+01  1.1301e-04
    1T  4.5e-06       20-      24  4.3215e+03  3.3134e+01  6.1781e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       22-      22  2.4088e+03  2.8065e+01  8.2783e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       24-      23  2.6646e+03  3.1687e+01  4.6304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       22-      21  2.6772e+03  3.0302e+01  4.0250e-05
    1T  8.1e-06       37-      20  2.7337e+03  3.1722e+01  1.5468e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       24-      19  2.7230e+03  3.1764e+01  8.1483e-05
    1T  2.1e-06       37-      22  2.7075e+03  3.1394e+01  1.3521e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      21  2.6933e+03  3.1427e+01  4.3265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       37-      20  2.6942e+03  3.0948e+01  1.0524e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       16-      19  2.8889e+03  3.1519e+01  1.9240e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       22-      21  2.6330e+03  3.0455e+01  9.2379e-05
    1T -3.0e-06       37-      20  2.9249e+03  3.2339e+01  5.7023e-05
    1T -5.5e-06        4-      24  2.3287e+03  2.8894e+01  5.2792e-05
    1T  8.9e-06       37-      22  2.6366e+03  3.0768e+01  6.1165e-04
    1T -3.7e-06       24-      20  2.7267e+03  3.1435e+01  5.6955e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       20-      22  2.8327e+03  3.0124e+01  2.1024e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       37-      20  2.7115e+03  3.1579e+01  2.7743e-05
    1T  7.2e-06       37-      21  2.8723e+03  3.2697e+01  5.3564e-04
    1T  5.1e-06       24-      23  2.6562e+03  3.1093e+01  5.1216e-04
    1T  2.6e-06       37-      22  2.7244e+03  3.1958e+01  1.8981e-04
    1T -8.5e-06       16-      19  3.1892e+03  3.3894e+01  3.0099e-04

indexes =

  Columns 1 through 13

    65   174   128    30   111   196   198    96   159   174    76    81    91

  Columns 14 through 26

    36   182    47    20    32    36   106    15   192   120   192     7   158

  Columns 27 through 30

   187    45   197   102


Accuracy =

   94.7738


Accuracy =

   94.9145


Accuracy =

   94.7942


Accuracy =

   94.9186


Accuracy =

   94.8615


Accuracy =

   94.8737


Accuracy =

   94.7758


Accuracy =

   94.8798


Accuracy =

   94.8880


Accuracy =

   94.8513


Accuracy =9.485129e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   99.7802
  100.0000
   99.7765
   98.1028
   98.3498
   99.8049
   98.5498
   90.9866
   99.9822
   97.2335
   99.4840
   99.8275
   99.5157
   99.4851
   79.3538
   98.9628


AverageAccuracy =

   97.4497

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Pavia');

load('Pavia_gt');
image=pavia;
image_gt=pavia_gt;
size(image)

ans =

        1096         715         102


train_on_image=1;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
{Matrix index is out of range for deletion.
} 
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       32-      52  9.2440e+01  5.4884e+01  1.5427e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       65-      54  1.1541e+02  1.0950e+01  2.1373e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       47-      53  9.6569e+01  3.7913e+01  4.5976e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       35-      50  9.6418e+01  5.3113e+01  2.1560e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       51-      65  4.3070e+02  9.1500e+01  1.5141e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-07       60-      56  9.4735e+01  3.3940e+01  1.7245e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       68-      55  9.0825e+01  3.4856e+01  1.0592e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-07       75-      60  1.0880e+02  9.9299e+01  1.9008e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       47-      48  2.8631e+02  1.4235e+01  7.3761e-04
    1T  4.0e-06       42-      50  9.7950e+01  1.3991e+02  1.1548e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       57-      37  1.0742e+02  1.2630e+02  6.5652e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       62-      55  9.3541e+01  1.0871e+01  5.1061e-07
    1T  9.7e-06       28-      52  1.9174e+02  1.2037e+01  5.3612e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       64-      54  1.0052e+02  7.0131e+01  2.6992e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       31-      56  5.8805e+02  2.5858e+01  2.9766e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       19-      54  9.2189e+01  1.2217e+01  8.0549e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       30-      62  2.5396e+02  1.2997e+02  1.9455e-03
    1T  7.1e-06        6-      52  1.0798e+02  7.8676e+01  2.5698e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       28-      56  9.2172e+01  8.3972e+00  8.8429e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       46-      42  8.7805e+01  7.5373e+01  4.5617e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       71-      44  1.1312e+02  4.4219e+01  1.5648e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       14-      57  9.7973e+01  2.8780e+01  5.0081e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-07       56-      49  9.4264e+01  1.1472e+02  2.7759e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       28-      59  9.6052e+01  9.1715e+01  1.3548e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       42-      47  1.0916e+02  6.9484e+00  6.3131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       70-      53  8.2550e+01  8.2861e+00  4.0300e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       70-      67  5.3641e+02  6.2155e+01  2.8025e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       50-      55  1.0297e+02  1.0842e+01  5.9001e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06        5-      54  9.0224e+01  7.7119e+01  5.4213e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-08       72-      47  9.7289e+01  1.5228e+02  6.3024e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       54-      51  9.8439e+01  8.4534e+00  5.9690e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       27-      55  8.4215e+01  4.4959e+01  3.4073e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-07       11-      58  9.8616e+01  2.3091e+01  2.8808e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        8-      48  9.0183e+01  9.7337e+00  9.1282e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       14-      50  9.4487e+01  1.0295e+02  8.8682e-07
    1T  6.9e-06       51-      55  9.9052e+01  8.5683e+00  3.2475e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       55-      55  9.9852e+01  7.8193e+01  3.7604e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       49-      60  9.6195e+01  2.8062e+01  9.0524e-06
    1T  3.5e-06       45-      52  9.5453e+01  9.2912e+00  7.5487e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       59-      48  9.8486e+01  1.0384e+01  2.7909e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       38-      61  1.1331e+02  1.2194e+01  1.1908e-06
    1T  8.7e-06       66-      55  1.0065e+02  1.0702e+01  3.1908e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       73-      51  1.0099e+02  1.1039e+01  5.9905e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       17-      56  1.2087e+02  1.0328e+01  3.5304e-06
    1T -1.3e-06        3-      49  9.4589e+01  1.0046e+01  6.6545e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       19-      62  9.9734e+01  4.4308e+01  1.9115e-06
    2T  8.6e-06       46-      61  9.9734e+01  4.4309e+01  1.8928e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       60-      49  9.4148e+01  8.7130e+00  8.6996e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       36-      56  1.5509e+02  2.5670e+01  7.9802e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06        1-      54  1.2435e+02  1.0179e+01  4.4580e-04
    1T  7.4e-06        1-      57  9.9548e+01  1.1879e+01  3.7136e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       17-      57  9.7291e+01  1.9938e+01  3.6638e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06       55-      55  1.0565e+02  1.0378e+01  4.0647e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       68-      57  3.6699e+02  7.3396e+01  4.5000e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       12-      50  2.8503e+02  2.5336e+01  6.6995e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06        7-      53  9.7437e+01  1.0129e+01  1.9837e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       12-      47  9.5806e+01  7.5995e+00  3.9428e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       52-      57  8.9624e+01  1.8846e+01  1.3473e-06
    1T -4.4e-06        3-      53  9.2445e+01  8.8779e+00  2.9402e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       38-      59  9.6716e+01  6.2745e+01  4.1113e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       29-      41  1.3034e+03  2.8077e+01  1.4569e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       55-      59  2.3727e+02  2.9026e+01  1.2306e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       11-      55  9.7191e+01  1.0842e+01  5.2886e-06
    1T  5.5e-08        1-      57  1.0503e+02  9.4357e+00  9.3404e-09
    1T -4.3e-06       61-      60  9.5746e+01  1.3726e+02  1.2902e-04
    1T  6.9e-06       75-      57  9.7529e+01  3.8795e+01  1.6335e-06
    1T  1.2e-06       66-      51  9.7558e+01  8.6954e+00  3.0951e-04
    1T  9.5e-06       51-      58  9.9468e+01  1.4026e+01  5.9811e-05
    1T -9.0e-06       68-      71  6.2786e+02  2.1370e+02  2.9770e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       38-      62  1.0274e+02  9.4304e+01  5.4003e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       15-      58  9.7499e+01  8.1726e+01  3.0231e-04
    1T  6.6e-06       18-      60  9.9504e+01  9.9945e+01  5.6554e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       48-      67  7.7781e+02  1.1185e+02  2.8612e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       72-      49  1.0646e+02  8.4979e+00  1.4257e-06
    1T  2.2e-06       41-      25  7.0269e+02  2.2102e+02  3.2274e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       24-      52  1.0698e+02  3.5868e+01  1.2929e-06
    1T  4.1e-06       29-      52  9.6951e+01  1.8236e+02  2.5109e-06
    1T  7.7e-06       45-      55  9.7968e+01  4.3550e+01  4.7535e-06
    1T  6.7e-06       17-      55  1.0008e+02  1.3833e+01  4.0414e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       31-      30  1.1976e+02  5.8955e+00  1.0475e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06        6-      65  2.4784e+02  1.9246e+02  3.0035e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06        4-      66  7.4258e+02  2.5352e+02  1.8737e-03
    1T  5.7e-06       60-      56  7.0041e+02  2.0776e+01  2.6995e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       16-      63  1.5819e+02  1.2836e+02  2.3188e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-07       70-      67  2.9274e+02  3.7733e+01  4.4744e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       55-      61  8.0753e+02  3.1226e+01  4.5445e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-07       46-      58  1.2404e+03  2.9190e+01  2.6060e-07
    1T  1.0e-06       18-      55  9.6240e+02  2.7289e+01  4.0918e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-07       56-      54  8.2102e+02  2.8021e+01  3.8111e-03
    1T -1.6e-06       54-      54  1.7395e+03  2.5284e+01  4.6345e-03
    1T -6.9e-06       66-      67  1.5509e+03  4.1986e+02  5.1300e-07
    1T  5.3e-06       46-      64  1.0329e+03  2.8048e+01  2.6555e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06        1-      63  4.5960e+02  2.4540e+01  1.0773e-04
    1T  3.5e-06       51-      59  7.8579e+02  2.0069e+01  1.5776e-06
    1T -9.3e-06       37-      64  5.3769e+02  3.3504e+01  3.0204e-03
    1T  2.3e-06       31-      63  1.0433e+03  3.7459e+01  2.2744e-03
    1T  7.0e-06        9-      67  3.3441e+02  1.9719e+02  9.0248e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       56-      61  7.7936e+02  1.3762e+02  2.5215e-03
    1T  9.2e-06       24-      65  4.2877e+02  2.2063e+02  3.6146e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       15-      57  7.1337e+02  2.2524e+02  3.2765e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-07       19-      55  8.9788e+02  2.9670e+01  2.6906e-07
    1T  5.6e-06       58-      65  5.5610e+02  8.2726e+01  2.5798e-07

indexes =

  Columns 1 through 13

   153   129    13   158    99    98   181   145   195    63   187   173    99

  Columns 14 through 26

   149   153   168    98   155    21   121   105   107   130   139   152     7

  Columns 27 through 30

    44   106   119   107


Accuracy =

   99.7226


Accuracy =

   99.7375


Accuracy =

   99.7561


Accuracy =

   99.7203


Accuracy =

   99.7241


Accuracy =

   99.7300


Accuracy =

   99.7241


Accuracy =

   99.7189


Accuracy =

   99.7233


Accuracy =

   99.7330


Accuracy =9.973303e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

  100.0000
   99.2882
   98.8547
   99.3424
   99.3958
   99.3551
   99.3022
   99.8814
   96.9486


AverageAccuracy =

   99.1520

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Pavia');

load('Pavia_gt');
image=pavia;
image_gt=pavia_gt;
size(image)

ans =

        1096         715         102


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       18-      54  5.9312e+02  2.7781e+01  5.3833e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       68-      54  2.5312e+02  2.8788e+01  6.4122e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06        6-      50  1.0283e+02  2.1673e+01  2.7527e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       64-      54  1.3186e+02  3.5439e+01  1.3907e-07
    1T  5.3e-06       24-      54  9.5757e+01  1.7095e+01  1.6314e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       68-      52  8.7708e+01  1.5607e+01  4.6685e-07
    1T  6.5e-06       16-      58  3.1267e+02  4.5492e+01  7.7892e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       13-      56  1.0380e+02  2.7712e+01  3.3180e-05
    1T -2.2e-06        1-      55  1.0638e+02  2.6290e+01  1.2321e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       71-      49  9.6455e+01  1.7656e+01  6.3491e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       57-      45  1.2356e+02  1.3195e+01  4.7217e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       38-      50  1.0357e+02  2.2178e+01  1.3522e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       54-      61  4.0859e+02  6.2274e+01  1.4778e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       10-      59  9.3115e+01  2.9526e+01  9.8845e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       20-      36  1.0108e+02  1.3416e+01  6.3737e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       46-      51  8.9058e+01  2.7694e+01  1.9383e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       70-      58  9.9717e+01  2.1025e+01  3.8608e-05
    1T  2.4e-06       74-      52  1.1409e+03  6.3503e+01  4.4095e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       24-      36  9.3077e+01  1.2033e+01  6.3381e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      53  1.0376e+03  5.0425e+01  7.9889e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-07       60-      52  1.0123e+02  1.7476e+01  9.9776e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       58-      49  9.3143e+01  1.6644e+01  1.6522e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       53-      44  9.2875e+01  1.4259e+01  6.0592e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       21-      56  1.0259e+02  3.0176e+01  5.2646e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       20-      43  9.4958e+01  1.7477e+01  8.8576e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-07       30-      47  1.0226e+02  1.4116e+01  1.2232e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-07       17-      51  8.8367e+01  1.5429e+01  4.8445e-06
    1T -2.5e-06       64-      37  9.9938e+01  2.9314e+01  9.0070e-04
    1T  4.9e-06       37-      57  9.3364e+01  2.0480e+01  1.2159e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06        8-      55  1.0031e+02  2.5267e+01  2.0154e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       38-      53  1.0126e+03  5.4562e+01  5.3268e-06
    1T -3.0e-06       47-      47  9.5290e+01  1.5936e+01  2.7446e-04
    1T  2.4e-06       57-      41  1.1280e+03  6.7579e+01  1.6343e-03
    1T -3.2e-06       16-      47  9.9280e+01  1.3827e+01  1.2775e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       12-      43  9.4457e+01  1.3598e+01  3.9163e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       17-      39  1.0002e+02  1.5058e+01  3.4983e-06
    1T  4.0e-07       32-      50  9.0444e+01  1.7787e+01  9.5000e-08
    1T  6.4e-06       50-      54  9.7657e+01  2.3799e+01  2.7606e-06
    1T  2.6e-06       17-      48  9.4221e+01  1.5773e+01  1.0496e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       21-      58  1.0341e+02  2.7414e+01  1.0523e-06
    1T -9.6e-06       34-      52  1.0162e+02  1.7220e+01  3.1823e-04
    1T  5.5e-06       58-      44  1.0607e+02  1.9625e+01  7.9718e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06       20-      67  1.1429e+03  7.5996e+01  3.2281e-03
    1T  6.1e-06       17-      53  1.3107e+03  6.4844e+01  1.8691e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       12-      48  1.0160e+02  1.7465e+01  3.3554e-07
    1T  8.0e-06       32-      56  1.2421e+03  6.5378e+01  3.4863e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       54-      55  9.9265e+01  3.0515e+01  3.1794e-06
    1T  3.3e-06       46-      57  9.3440e+02  6.3856e+01  6.5309e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       58-      47  9.7017e+01  1.7303e+01  2.0128e-04
    1T  2.9e-06        8-      47  2.6476e+02  6.4221e+01  3.5492e-03
    1T  7.2e-06       59-      58  1.0391e+03  5.2167e+01  2.1760e-03
    1T  9.0e-06       38-      60  1.9970e+02  4.5036e+01  8.5828e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-07        5-      65  9.2934e+02  6.7471e+01  1.8002e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       51-      54  7.4731e+02  5.8090e+01  1.3087e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06        7-      55  1.3790e+03  5.6630e+01  4.5129e-07
    1T  6.0e-06       73-      54  1.1307e+03  6.5866e+01  2.9435e-06
    1T  8.3e-06        8-      63  3.4292e+02  6.3049e+01  5.6261e-06
    1T -4.4e-06       13-      60  1.0701e+03  4.2680e+01  1.2239e-03
    1T -9.3e-06       63-      51  7.3833e+02  4.6329e+01  2.2629e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       69-      56  4.4980e+02  7.7961e+01  3.3729e-03
    1T  7.8e-06       69-      54  1.9103e+02  4.3599e+01  6.5959e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       14-      60  6.2883e+02  4.1460e+01  1.6925e-04
    1T  9.3e-06        1-      61  9.2822e+02  4.1992e+01  1.7832e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-07       45-      59  1.5839e+03  1.0335e+02  1.2236e-07
    1T  6.0e-06       21-      63  1.0489e+03  6.3773e+01  5.2779e-07

indexes =

  Columns 1 through 13

    86     5   115   105    51    17     6    83   102    93    69   156    30

  Columns 14 through 26

   125    13    68   155   143   140    49   170    45    62    36    24    41

  Columns 27 through 30

    91   174    10   163


Accuracy =

   99.6740


Accuracy =

   99.6725


Accuracy =

   99.6502


Accuracy =

   99.6360


Accuracy =

   99.6479


Accuracy =

   99.6323


Accuracy =

   99.6755


Accuracy =

   99.6479


Accuracy =

   99.6748


Accuracy =

   99.6576


Accuracy =9.965762e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

  100.0000
   99.3161
   95.5181
   99.5058
   99.6981
   99.7728
   98.7709
   99.8529
   96.1330


AverageAccuracy =

   98.7297

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

   172    10   143   179    89    36   196    69     4   102    19   115   192

  Columns 14 through 26

    16   137    78   130   175   137    97   177    89   110   157   131    66

  Columns 27 through 30

   175    84    63   114


Accuracy =

   96.8145


Accuracy =

   96.8016


Accuracy =

   96.8765


Accuracy =

   96.8740


Accuracy =

   96.7758


Accuracy =

   96.8559


Accuracy =

   96.5278


Accuracy =

   96.8274


Accuracy =

   96.7499


Accuracy =

   96.6233


Accuracy =9.662335e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   96.9338
   99.2890
   88.2570
   92.6688
   99.9177
   98.5736
   94.8505
   89.6604
   87.7480


AverageAccuracy =

   94.2110

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

   139    37   161    35    56    82    71    11   176    97    84    67   151

  Columns 14 through 26

    95   173    50    96   104    18   109    63    27    19     5    94   169

  Columns 27 through 30

    61     4   165   143


Accuracy =

   96.5826


Accuracy =

   96.9933


Accuracy =

   97.0760


Accuracy =

   96.6627


Accuracy =

   96.8048


Accuracy =

   96.8900


Accuracy =

   96.8487


Accuracy =

   96.9365


Accuracy =

   96.8151


Accuracy =

   96.9908


Accuracy =9.699075e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   96.7022
   99.3838
   85.6616
   94.6970
  100.0000
   98.7030
   96.8386
   91.4466
   92.7739


AverageAccuracy =

   95.1341

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

indexes =

  Columns 1 through 13

    95   175    21    52   137    12    76    91    62    31   138   183    10

  Columns 14 through 26

    15   148   144    40   159     1   183   122     4   163   125   100   122

  Columns 27 through 30

    29   174   182   116


Accuracy =

   97.0129


Accuracy =

   96.7960


Accuracy =

   96.9716


Accuracy =

   96.9458


Accuracy =

   96.9948


Accuracy =

   97.0852


Accuracy =

   97.0645


Accuracy =

   96.9354


Accuracy =

   97.1239


Accuracy =

   96.9871


Accuracy =9.698707e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.5691
   99.3957
   88.3500
   95.8588
   98.8487
   98.4642
   93.1120
   89.8082
   91.1422


AverageAccuracy =

   94.7277

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

     8   111    94    26    77    27    57    80    56   150    67    84   116

  Columns 14 through 26

     5    28    15   101   158     5   158   110   110   102    45    37   156

  Columns 27 through 30

   172   188    79   189


Accuracy =

   96.9305


Accuracy =

   96.7962


Accuracy =

   96.8530


Accuracy =

   96.9745


Accuracy =

   96.7394


Accuracy =

   96.7652


Accuracy =

   96.7109


Accuracy =

   96.8246


Accuracy =

   97.0520


Accuracy =

   96.8350


Accuracy =9.683495e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.5671
   99.2528
   84.8580
   92.6099
   99.5078
   98.6611
   94.4954
   92.1298
   92.4419


AverageAccuracy =

   94.6138

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

   188    91   157     2    26   143   177   124    42   188    65    69   102

  Columns 14 through 26

   109   115    42   191   191   180    87   160   107   175   107    49    68

  Columns 27 through 30

    74    98    39   142


Accuracy =

   96.9038


Accuracy =

   96.7514


Accuracy =

   96.8599


Accuracy =

   96.9814


Accuracy =

   96.9995


Accuracy =

   96.7669


Accuracy =

   96.9142


Accuracy =

   96.9271


Accuracy =

   97.0124


Accuracy =

   96.9064


Accuracy =9.690642e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   95.8285
   99.6265
   88.0927
   93.5182
   99.1783
   99.1648
   93.9268
   92.0096
   89.4063


AverageAccuracy =

   94.5280

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

    48    31   173    13    13    78   195   101   107   108   190     1    72

  Columns 14 through 26

    31   183    56    26    29   189   170    23   160    43    65    48   156

  Columns 27 through 30

   177   108   124    78


Accuracy =

   96.9948


Accuracy =

   97.0800


Accuracy =

   97.0594


Accuracy =

   96.6847


Accuracy =

   96.9224


Accuracy =

   97.0206


Accuracy =

   96.8630


Accuracy =

   97.2041


Accuracy =

   96.8991


Accuracy =

   96.9922


Accuracy =9.699217e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   96.3851
   99.6501
   86.8282
   93.0836
   98.9327
   99.0771
   92.7741
   93.3894
   90.1984


AverageAccuracy =

   94.4799

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

    22   143    19    27    99   181   196   134    85   118    96   180   132

  Columns 14 through 26

    59   160   116   193   146    10   139    27   134   134   101   147    10

  Columns 27 through 30

   146   129   120   137


Accuracy =

   96.9025


Accuracy =

   96.9878


Accuracy =

   96.7269


Accuracy =

   96.8509


Accuracy =

   96.8483


Accuracy =

   96.8199


Accuracy =

   96.7165


Accuracy =

   96.7759


Accuracy =

   96.7940


Accuracy =

   96.8638


Accuracy =9.686378e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.2671
   99.6148
   88.6902
   92.3882
   98.9327
   98.2653
   94.0784
   91.2038
   87.9953


AverageAccuracy =

   94.2706

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

   105    25   168    41   155    28    68    46   197   194    80   178   150

  Columns 14 through 26

    95   108   122    41   199   195    68   187   160   191    92    65   154

  Columns 27 through 30

    29    76   142    35


Accuracy =

   97.0072


Accuracy =

   96.9659


Accuracy =

   96.9452


Accuracy =

   96.8728


Accuracy =

   96.9581


Accuracy =

   96.8005


Accuracy =

   96.8780


Accuracy =

   96.8702


Accuracy =

   96.8832


Accuracy =

   97.0770


Accuracy =9.707699e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   97.6845
   99.3595
   86.4979
   94.5868
   98.9318
   99.1868
   92.2693
   92.9129
   88.4884


AverageAccuracy =

   94.4353

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

    71    38    26    95   162    32    58   155     7   149   161    79    53

  Columns 14 through 26

   102    91    17   166   169   133   177   178   144    12   191    11   117

  Columns 27 through 30

    28   128   141   108


Accuracy =

   96.6565


Accuracy =

   96.7289


Accuracy =

   96.7366


Accuracy =

   96.5376


Accuracy =

   96.7314


Accuracy =

   96.7779


Accuracy =

   96.7004


Accuracy =

   96.8374


Accuracy =

   96.7444


Accuracy =

   96.5557


Accuracy =9.655573e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   95.7124
   99.3182
   85.3697
   93.4509
   99.4243
   99.5825
   93.4167
   91.0784
   88.5781


AverageAccuracy =

   93.9924

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       73-      40  6.9860e+02  8.0932e+01  4.6074e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       38-      30  1.8960e+02  5.9531e+01  3.7074e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        6-      42  1.6842e+03  7.9088e+01  7.0770e-06
    1T  2.3e-06        1-      34  1.2674e+03  6.7398e+01  2.7999e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       34-      46  9.0524e+02  1.2742e+02  4.0756e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       57-      44  3.9754e+02  7.6034e+01  2.1291e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       62-      39  5.6882e+02  7.4490e+01  2.6325e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       72-      49  9.5108e+02  1.1908e+02  5.7234e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       38-      34  2.7451e+02  7.4156e+01  1.2584e-07
    1T  2.5e-07       37-      31  4.4438e+02  5.5058e+01  1.7275e-08
    1T  8.3e-06       20-      48  1.1510e+03  1.1632e+02  1.9943e-03
    1T  4.6e-06       72-      48  9.3224e+02  1.2167e+02  3.4952e-06
    1T -8.0e-06       60-      42  1.9075e+03  9.5638e+01  2.9488e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        8-      46  1.9363e+02  1.0630e+02  3.6922e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       44-      37  6.4499e+02  7.2127e+01  1.2056e-06

indexes =

  Columns 1 through 13

    22   119   172    74    87    16    43    22    38    51   134   107   133

  Columns 14 through 26

    12    36   142   112   156    37   165    33    30    76    88    59    87

  Columns 27 through 30

   100   185   145   171


Accuracy =

   96.8601


Accuracy =

   96.9454


Accuracy =

   96.8446


Accuracy =

   97.0953


Accuracy =

   96.8240


Accuracy =

   96.9196


Accuracy =

   96.5836


Accuracy =

   96.6973


Accuracy =

   96.8421


Accuracy =

   96.8240


Accuracy =9.682396e+01

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9


class_accuracy =

   96.1622
   99.3424
   86.0306
   93.8695
   99.5078
   99.4062
   95.2540
   91.8692
   89.2145


AverageAccuracy =

   94.5174

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       66-      67  1.8778e+03  5.0467e+01  3.0968e-04
    1T  8.4e-06       20-      70  1.9760e+03  5.1170e+01  3.5883e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       60-      64  1.1839e+03  3.9753e+01  2.8485e-05

indexes =

  Columns 1 through 13

   194    55   110   200   162   114    21    59   100   106   196   173    78

  Columns 14 through 26

   192    72   178     7   122    89   132   120   183    22   127   127   164

  Columns 27 through 30

   154   175   154    60

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.5447


Accuracy =

   96.2325


Accuracy =

   96.2540


Accuracy =

   95.9096


Accuracy =

   96.1464


Accuracy =

   96.3940


Accuracy =

   95.7266


Accuracy =

   96.2002


Accuracy =

   96.4909


Accuracy =

   96.2756


Accuracy =9.627557e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   96.1449
   95.4847
   87.3832
   91.7241
   98.9378
   76.9231
   96.5278
  100.0000
   92.0455
   99.0143
   92.3364
   99.4595
   97.4717
   99.1453
   97.6190


AverageAccuracy =

   94.5672

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       50-      53  1.1541e+03  4.4050e+01  2.1583e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       50-      53  1.1541e+03  4.4050e+01  2.1583e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       50-      53  1.1541e+03  4.4050e+01  2.1583e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       50-      53  1.1541e+03  4.4050e+01  2.1583e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       33-      64  1.4743e+03  3.6697e+01  2.3163e-04

indexes =

  Columns 1 through 13

    67    84     8    97   188    38   195   189    74    89   115    59   199

  Columns 14 through 26

    73   157   115     3   136    29   191    14    45   183   165   178   161

  Columns 27 through 30

    63   152    88   108

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0039


Accuracy =

   95.5084


Accuracy =

   96.0039


Accuracy =

   96.2085


Accuracy =

   96.1870


Accuracy =

   95.9393


Accuracy =

   95.8746


Accuracy =

   96.4132


Accuracy =

   95.9177


Accuracy =

   95.9500


Accuracy =9.595002e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   96.1420
   95.8556
   93.9535
   95.8621
   97.8884
  100.0000
  100.0000
  100.0000
   95.4649
   96.1331
   89.0335
   91.9786
   98.4252
   93.9828
   90.5882


AverageAccuracy =

   95.5103

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       74-      69  1.8474e+03  3.9458e+01  1.4870e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      61  1.4610e+03  4.3339e+01  1.0543e-02

indexes =

  Columns 1 through 13

    59   171    43    23    90    59    69   115    86    50   179   154    94

  Columns 14 through 26

    90   155    89   119   101    23   173   186    71    39   109    71     3

  Columns 27 through 30

   123   111    60   190

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4962


Accuracy =

   95.5069


Accuracy =

   95.3992


Accuracy =

   95.3238


Accuracy =

   95.5393


Accuracy =

   95.3346


Accuracy =

   95.1514


Accuracy =

   95.4531


Accuracy =

   95.1945


Accuracy =

   95.0975


Accuracy =9.509751e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   83.3333
   91.5635
   90.4255
   86.5116
   96.7890
   98.3333
   76.9231
   99.3088
   94.4444
   92.0455
   98.5162
   90.0185
   94.0541
   98.6877
   95.4155
   95.2381


AverageAccuracy =

   92.6005

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       57-      69  2.5342e+03  4.9140e+01  4.1558e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       67-      66  1.5591e+03  3.9495e+01  1.9625e-05
    1T  8.9e-06       16-      68  1.8932e+03  4.4130e+01  8.6484e-05
    1T -8.9e-06       17-      68  2.9448e+03  5.1459e+01  2.3863e-05

indexes =

  Columns 1 through 13

    96   182    49    94   126    50   184    26   146   107    79   172    41

  Columns 14 through 26

   116   166   100   151   111   161   148   119   193   128   192    72   172

  Columns 27 through 30

    43    68   198   131

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4825


Accuracy =

   95.3423


Accuracy =

   95.7844


Accuracy =

   95.4286


Accuracy =

   95.2453


Accuracy =

   95.6658


Accuracy =

   95.2992


Accuracy =

   95.6334


Accuracy =

   95.3423


Accuracy =

   95.2345


Accuracy =9.523450e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   60.4651
   93.6582
   96.5287
   87.8505
   88.5845
   97.7238
   96.1538
  100.0000
   88.8889
   91.4773
   98.7821
   87.7095
   84.0426
   98.0803
   99.7143
   97.6190


AverageAccuracy =

   91.7049

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06        3-      74  3.0367e+03  5.7070e+01  9.6937e-06
    1T -1.6e-06       31-      57  1.0503e+03  3.9130e+01  9.3501e-06

indexes =

  Columns 1 through 13

   196    86    81   146   169    16   133   118   111   186    29   118   175

  Columns 14 through 26

   150   168   176   133   120   116   160    26    25   142   155    37    37

  Columns 27 through 30

    66    99    14   189

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.1986


Accuracy =

   96.2847


Accuracy =

   96.2309


Accuracy =

   96.4786


Accuracy =

   96.4893


Accuracy =

   96.1447


Accuracy =

   96.3924


Accuracy =

   96.2955


Accuracy =

   96.7586


Accuracy =

   96.3278


Accuracy =9.632781e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   92.8571
   93.5957
   91.9786
   87.9070
   92.9224
   98.3333
  100.0000
  100.0000
  100.0000
   92.4036
   99.0553
   97.7612
   98.3957
   99.0393
   98.0057
   92.8571


AverageAccuracy =

   95.9445

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-07        4-      48  2.0221e+03  3.8145e+01  1.3606e-06
    1T  8.0e-06       32-      66  1.5439e+03  3.9773e+01  3.6478e-05

indexes =

  Columns 1 through 13

    49    74    51    21    74   125    79    68   188    29   110    34   131

  Columns 14 through 26

   130    77   114   122    40   121   155    33   173    55   162   100   106

  Columns 27 through 30

   138   176    62   114

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.8850


Accuracy =

   96.1650


Accuracy =

   95.9388


Accuracy =

   96.2081


Accuracy =

   96.3158


Accuracy =

   95.9927


Accuracy =

   96.3374


Accuracy =

   96.1543


Accuracy =

   96.2189


Accuracy =

   96.3158


Accuracy =9.631585e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   65.1163
   93.9628
   95.6175
   92.0930
   95.8810
   98.0243
  100.0000
  100.0000
   94.4444
   95.6867
   97.1210
   95.7090
   99.4595
   98.8666
   98.0114
   75.0000


AverageAccuracy =

   93.4371

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       65-      68  1.9154e+03  4.7532e+01  2.3807e-05
    1T -6.6e-06       58-      71  2.3912e+03  4.4417e+01  1.8940e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       61-      65  1.3094e+03  4.5670e+01  3.2405e-05
    1T -3.2e-06       30-      70  1.1797e+03  5.0487e+01  9.1948e-06

indexes =

  Columns 1 through 13

    14   151   195   199   181    48    89    28   185   194    71   180    88

  Columns 14 through 26

    91    44   187    19    26    86   159   144   144   101    60    84   170

  Columns 27 through 30

    18   131    79    82

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.6943


Accuracy =

   96.2421


Accuracy =

   96.3390


Accuracy =

   96.5005


Accuracy =

   96.3282


Accuracy =

   96.5005


Accuracy =

   96.0805


Accuracy =

   96.5005


Accuracy =

   96.4682


Accuracy =

   95.8437


Accuracy =9.584365e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   64.2857
   96.9064
   89.4526
   89.3023
   96.5753
   98.7842
   70.3704
  100.0000
   94.4444
   97.2727
   96.8104
   93.4701
   89.7297
   98.7784
   95.7386
   77.9070


AverageAccuracy =

   90.6143

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=1500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.

{Operation terminated by user during
parallel.internal.cluster.FileSerializer>iSaveMat (line 276)


In parallel.internal.cluster.FileSerializer/saveFieldsToFile (line 222)
                    saveFunction(thisLocation, structToSave, saveFlags);

In parallel.internal.cluster.FileSerializer/putFields (line 157)
            obj.saveFieldsToFile(entity, names, values, '-append');

In parallel.internal.cluster.CJSSupport/setProperties (line 328)
            obj.Serializer.putFields( iSerializerStruct( variant, sId ),
            mappedNames, values );

In parallel.internal.cluster.CJSSupport/setJobProperties (line 499)
            obj.setProperties( jobvariant, jobsid, propName, val );

In parallel.internal.cluster.CJSJobMixin/hSetPropertyNoCheck (line 54)
            obj.Support.setJobProperties( obj.SupportID, obj.Variant, propName,
            val );

In parallel.Job/hSetProperty (line 628)
            hSetPropertyNoCheck( obj, propName, val );

In parallel.Job/attachRequiredFiles (line 933)
            job.AttachedFilePaths = filePathMap;

In parallel.Job/preSubmit (line 584)
            job.attachRequiredFiles();

In parallel.Job/submit (line 347)
            job.preSubmit();

In parallel.internal.pool.InteractiveClient/start (line 339)
                    submit(obj.ParallelJob);

In parallel.Pool>iStartClient (line 791)
spmdInitialized = client.start(poolType , numWorkers, cluster, ...

In parallel.Pool.hBuildPool (line 585)
                iStartClient(client, 'pool', cluster, guiMode, supportRestart,
                argsList);

In parallel.internal.pool.doParpool (line 18)
    pool = parallel.Pool.hBuildPool(constructorArgs{:});

In parpool (line 98)
    pool = parallel.internal.pool.doParpool(varargin{:});

In create_centered_features_bands (line 4)
parpool(36)
} 
clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06        3-      73  4.0764e+03  5.7046e+01  7.5393e-06
    1T  7.8e-06       70-      73  2.4912e+03  6.1583e+01  1.1208e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06        4-      64  2.0825e+03  5.0805e+01  3.0887e-06
    1T  2.9e-06       60-      52  1.1719e+03  5.0321e+01  7.9709e-06

indexes =

  Columns 1 through 13

   171    51    12    96   192    91    28    47   178   183   169    49    44

  Columns 14 through 26

   192    30    92   124   189   158    59   143    60   116   176    66    62

  Columns 27 through 30

   199   142    22   122

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.4741


Accuracy =

   95.6891


Accuracy =

   95.2913


Accuracy =

   95.8074


Accuracy =

   95.3451


Accuracy =

   95.3021


Accuracy =

   95.5063


Accuracy =

   95.5923


Accuracy =

   95.5171


Accuracy =

   95.5601


Accuracy =9.556009e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   97.6190
   95.8398
   89.4040
   90.2778
   94.2922
   98.3384
  100.0000
  100.0000
   33.3333
   93.8776
   97.7978
   96.8401
   91.3514
   99.3043
   88.2857
   71.4286


AverageAccuracy =

   89.8744

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       26-      63  3.0039e+03  5.9033e+01  2.8171e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       22-      69  2.2430e+03  7.0275e+01  3.1679e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       57-      58  1.8263e+03  5.5415e+01  2.9173e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        4-      61  1.8834e+03  5.5073e+01  7.0594e-06

indexes =

  Columns 1 through 13

    18    24   101    17   118   132    99    95   121   185   200    72   129

  Columns 14 through 26

   199   149    65   145    29   181   125   151     7    64     6     4    87

  Columns 27 through 30

   177    88    63   119

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3035


Accuracy =

   96.9070


Accuracy =

   96.7022


Accuracy =

   96.4328


Accuracy =

   96.7022


Accuracy =

   97.0255


Accuracy =

   96.7346


Accuracy =

   97.0902


Accuracy =

   96.8208


Accuracy =

   96.6699


Accuracy =9.666990e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   80.9524
   97.4478
   96.9374
   88.8889
   90.8884
   99.5434
   88.4615
  100.0000
   63.1579
   95.4494
   96.8047
   94.6296
  100.0000
   99.0393
   98.2808
   86.9048


AverageAccuracy =

   92.3366

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       75-      58  1.4180e+03  4.6293e+01  3.3811e-03
    1T  3.9e-06       19-      72  2.5211e+03  6.5583e+01  6.5334e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       10-      64  1.6189e+03  4.1656e+01  5.2904e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       75-      64  1.7773e+03  4.2595e+01  1.6080e-05

indexes =

  Columns 1 through 13

    98   142    58   177   111    42   196    55    68    17    36   119    96

  Columns 14 through 26

    41   169   124   169    27   158    64   125   137   177    45   185    36

  Columns 27 through 30

   134    37   111     2

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3115


Accuracy =

   96.4517


Accuracy =

   96.5380


Accuracy =

   96.4625


Accuracy =

   96.6566


Accuracy =

   96.6566


Accuracy =

   96.6997


Accuracy =

   96.6242


Accuracy =

   96.4193


Accuracy =

   96.1821


Accuracy =9.618205e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   95.2381
   95.5916
   92.3797
   97.1963
   98.1818
   97.1299
   84.6154
  100.0000
  100.0000
   90.4437
   99.2339
   96.0821
   81.2834
   98.6877
   99.1404
   69.4118


AverageAccuracy =

   93.4135

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       20-      68  1.0722e+03  6.8328e+01  1.5645e-05
    1T  2.4e-06       74-      70  1.9732e+03  6.0253e+01  1.9890e-06
    1T  2.9e-06       14-      61  2.0505e+03  4.4083e+01  3.8800e-05

indexes =

  Columns 1 through 13

    42   154    56   151     2   114    73   186    18    90   190    43   133

  Columns 14 through 26

   129   172    91    21   118   134    49   132   186   176    61   192   185

  Columns 27 through 30

    79   168    48   140

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.0691


Accuracy =

   95.4899


Accuracy =

   95.2849


Accuracy =

   94.8748


Accuracy =

   95.6085


Accuracy =

   95.2633


Accuracy =

   95.4143


Accuracy =

   95.5654


Accuracy =

   95.3496


Accuracy =

   95.1770


Accuracy =9.517695e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   73.8095
   96.3650
   96.8000
   90.7407
   93.1193
   98.3333
   96.1538
   99.7685
   88.8889
   90.7850
   95.3562
   88.6194
   92.4324
   99.3001
   91.1429
   97.6190


AverageAccuracy =

   93.0771

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       74-      60  2.0587e+03  4.6647e+01  1.8535e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       22-      73  2.5341e+03  6.9698e+01  9.7038e-06
    1T -3.7e-06       46-      71  4.1135e+03  6.4262e+01  3.4747e-04

indexes =

  Columns 1 through 13

   186    67   127   193    63   163    50    10    54   129   101    19   144

  Columns 14 through 26

   153   116   140    40    91    83    26     6    81   109    73   151   127

  Columns 27 through 30

   159    45    73   178

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.0590


Accuracy =

   96.0052


Accuracy =

   96.1667


Accuracy =

   96.3605


Accuracy =

   95.5745


Accuracy =

   96.6082


Accuracy =

   96.1128


Accuracy =

   95.9083


Accuracy =

   96.3067


Accuracy =

   96.0590


Accuracy =9.605901e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   64.2857
   96.9744
   89.7606
   87.0370
   89.7025
   96.8182
   61.5385
  100.0000
   94.4444
   94.3246
   99.1468
   96.8343
   98.9305
   99.6507
   94.5869
   77.3810


AverageAccuracy =

   90.0885

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
[Warning: The cluster failed to cancel the job execution. The error was: Unable
to read file
'/home/research/g.dehghanpoor/.matlab/local_cluster_jobs/R2018a/Job47.in.mat'.
No such file or directory.] 
[> In parallel.internal.cluster.CJSJobMethods.cancelOneJob (line 53)
  In parallel.job.CJSConcurrentJob/cancelOneJob (line 57)
  In parallel.Job/cancel (line 1348)
  In parallel.Cluster/hDeleteOneJob (line 911)
  In parallel.internal.pool.InteractiveClient>iDeleteJobs (line 873)
  In parallel.internal.pool.InteractiveClient/pRemoveOldJobs (line 481)
  In parallel.internal.pool.InteractiveClient/start (line 315)
  In parallel.Pool>iStartClient (line 791)
  In parallel.Pool.hBuildPool (line 585)
  In parallel.internal.pool.doParpool (line 18)
  In parpool (line 98)
  In create_centered_features_bands (line 4)] 
[Warning: The Cluster reported an error while destroying a job. The error was:
Unable to read file
'/home/research/g.dehghanpoor/.matlab/local_cluster_jobs/R2018a/Job47.in.mat'.
No such file or directory..] 
[> In parallel.internal.cluster.CJSJobMethods.destroyOneJob (line 79)
  In parallel.job.CJSConcurrentJob/destroyOneJob (line 52)
  In parallel.Job/delete (line 1279)
  In parallel.Cluster/hDeleteOneJob (line 926)
  In parallel.internal.pool.InteractiveClient>iDeleteJobs (line 873)
  In parallel.internal.pool.InteractiveClient/pRemoveOldJobs (line 481)
  In parallel.internal.pool.InteractiveClient/start (line 315)
  In parallel.Pool>iStartClient (line 791)
  In parallel.Pool.hBuildPool (line 585)
  In parallel.internal.pool.doParpool (line 18)
  In parpool (line 98)
  In create_centered_features_bands (line 4)] 
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       26-      74  2.2054e+03  7.5074e+01  7.6984e-06
    1T  3.3e-06       74-      71  3.1241e+03  6.3794e+01  1.5419e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06        5-      40  1.3413e+03  4.0657e+01  1.2504e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       32-      64  2.1005e+03  5.9355e+01  1.8152e-05
    1T  7.9e-06       18-      63  1.4312e+03  7.0516e+01  2.1022e-05

indexes =

  Columns 1 through 13

   174    98    67   196    66   108    26    13   125   129    70   119   154

  Columns 14 through 26

     7   109    39    38    55   157   150    64   138    25    83   118    71

  Columns 27 through 30

    59   143   139   143

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.8093


Accuracy =

   96.9602


Accuracy =

   96.8417


Accuracy =

   97.1435


Accuracy =

   97.0141


Accuracy =

   97.2081


Accuracy =

   97.1111


Accuracy =

   96.5291


Accuracy =

   97.1650


Accuracy =

   96.7770


Accuracy =9.677698e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   88.0952
   96.3622
   93.0574
   93.9815
   94.0774
   97.2686
  100.0000
   99.5370
   55.5556
   95.2109
   97.4382
   98.7013
   98.3784
   99.4755
   98.8571
   89.2857


AverageAccuracy =

   93.4551

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1



for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2500;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;


SVM_train;
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
class_accuracy
AverageAccuracy=mean(class_accuracy)


end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [2499x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       37-      72  3.1076e+03  5.8804e+01  6.5945e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       75-      65  2.1565e+03  5.4294e+01  5.6439e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       42-      61  1.6099e+03  4.9655e+01  1.3800e-05
    1T  3.8e-06       16-      63  1.9835e+03  5.1487e+01  7.2593e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06        2-      61  1.4050e+03  5.1755e+01  1.7903e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       66-      59  1.4830e+03  5.6014e+01  4.4142e-06
    1T -4.2e-06       50-      62  1.3360e+03  4.6597e+01  1.4564e-05

indexes =

  Columns 1 through 13

   171    63   168   197   182   178    41    54    18   199    85   165   125

  Columns 14 through 26

   130   154   182    90   133    38    51    12    70   118   126    74    88

  Columns 27 through 30

   108    75   186   182

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.2144


Accuracy =

   96.4625


Accuracy =

   95.8909


Accuracy =

   96.3978


Accuracy =

   95.8801


Accuracy =

   96.5487


Accuracy =

   95.9987


Accuracy =

   96.1173


Accuracy =

   96.1821


Accuracy =

   96.3223


Accuracy =9.632226e+01

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16


class_accuracy =

   60.4651
   97.5969
   94.4000
   94.4186
   93.1350
   97.4203
   76.9231
   99.5370
   94.4444
   95.5782
   97.2485
   99.2551
   88.1720
   99.4764
   90.5714
   78.5714


AverageAccuracy =

   91.0759

clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        7-      66  1.0830e+03  5.3381e+01  1.2727e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        7-      66  1.0830e+03  5.3381e+01  1.2727e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        7-      66  1.0830e+03  5.3381e+01  1.2727e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        7-      66  1.0830e+03  5.3381e+01  1.2727e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        7-      66  1.0830e+03  5.3381e+01  1.2727e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        7-      66  1.0830e+03  5.3381e+01  1.2727e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       18-      73  1.1529e+03  5.8285e+01  8.8542e-06
    1T  9.1e-06       59-      50  1.2439e+03  4.2136e+01  5.3607e-03
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
{Error using parpool (line 113)
Found an interactive session. You cannot have multiple interactive sessions
open simultaneously. To terminate the existing session, use
'delete(gcp('nocreate'))'.

Error in create_centered_features_bands (line 4)
parpool(36)
} 
SVM_train;

indexes =

  Columns 1 through 13

   107   200    10   167   113   133   187   167   112   182   116    63   151

  Columns 14 through 26

    67    33    77   192   188    83    30    91   197   132   161    42    36

  Columns 27 through 30

    97    13    55    75

{Index in position 3 exceeds array bounds (must not exceed 75).

Error in SVM_train (line 20)
flatFeatures=reshape(imageFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.6e-06       29-      69  1.8479e+03  4.8996e+01  5.0115e-06
    1T  3.4e-06       74-      68  1.3344e+03  4.7995e+01  7.1906e-06
    1T  9.7e-06       27-      61  1.2460e+03  4.5569e+01  2.8312e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       57-      64  1.2835e+03  4.3843e+01  6.9889e-04
    1T  6.7e-06       57-      63  1.0680e+03  4.5188e+01  1.0915e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       33-      74  2.3187e+03  5.6776e+01  1.6266e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06        1-      60  1.4489e+03  4.2180e+01  1.1121e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.400221s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true

Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    48    18   193   124    10    60    40    16   170   116   164    65    73

  Columns 14 through 26

    90    21    40   126   180   100   182   147    41   160    68   110    94

  Columns 27 through 30

   138   187   137    25

{Index in position 3 exceeds array bounds (must not exceed 75).

Error in SVM_train (line 20)
flatFeatures=reshape(imageFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       49-      71  2.0247e+03  4.6895e+01  8.5371e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       70-      45  8.6669e+02  4.0798e+01  1.1151e-04
    1T  4.0e-06       44-      67  1.6370e+03  4.4857e+01  8.2413e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       30-      62  8.3619e+02  4.0164e+01  3.1816e-05
    1T -3.7e-06       55-      60  1.1449e+03  4.7931e+01  7.1887e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       23-      71  2.8815e+03  4.6827e+01  1.8703e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       12-      72  1.7136e+03  6.9026e+01  8.5515e-06
    1T -9.0e-06        9-      55  1.2327e+03  4.2913e+01  2.3418e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       67-      74  3.7844e+03  6.1993e+01  3.1365e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       12-      65  2.0620e+03  4.6626e+01  4.4360e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.386449s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T -4.2e-07       61-      63  2.2990e+03  4.3420e+01  3.2584e-03
    1T  2.1e-06       20-      72  4.7805e+03  4.6480e+01  5.8452e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        6-      71  2.5446e+03  3.8040e+01  2.3719e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    45    28   146    58   191     6   133   136   189    11   183    88    34

  Columns 14 through 26

    19    39   183    75   128   179    41   193    29     9    35    71   178

  Columns 27 through 30

    64   121    97    63

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.2842


Accuracy =

   97.0579


Accuracy =

   97.1333


Accuracy =

   97.3057


Accuracy =

   97.2626


Accuracy =

   97.3381


Accuracy =

   97.1010


Accuracy =

   97.1872


Accuracy =

   97.1764


Accuracy =

   97.2626


Accuracy =9.726264e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   95.2381
   95.1201
   95.6059
   88.0184
   97.0320
   98.9362
   92.3077
   99.5392
   83.3333
   96.2457
   99.1899
   95.7486
   96.2162
   99.3886
   97.7011
   91.6667

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   95.0805




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-07       27-      67  1.2667e+03  4.6473e+01  1.3708e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06        8-      72  1.3890e+03  5.0719e+01  5.9311e-05
    1T  4.7e-06       71-      72  1.4041e+03  5.7955e+01  2.6969e-06
    1T  6.3e-06       66-      66  1.1718e+03  4.7481e+01  1.2105e-04
    1T -9.8e-06       27-      60  9.0986e+02  4.1908e+01  3.1065e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.

{Error using parpool (line 113)
Parallel pool failed to start with the following error. For more detailed
information, validate the profile 'local' in the Cluster Profile Manager.

Error in create_centered_features_bands (line 4)
parpool(36)

Caused by:
    Error using parallel.internal.pool.InteractiveClient>iThrowWithCause (line
    676)
    Failed to start pool.
        Error using save
        Unable to write file
        /home/research/g.dehghanpoor/.matlab/local_cluster_jobs/R2018a/Job47.in.mat:
        No such file or directory.
} 
SVM_train;

indexes =

  Columns 1 through 13

   161   195   108   191    77   155   117   111     8    77    49    87   125

  Columns 14 through 26

   129    89     2    83    55   169     5    44    37   144   180   144   121

  Columns 27 through 30

    94   113   119   118

{Index in position 3 exceeds array bounds (must not exceed 75).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       19-      63  8.8096e+02  4.9495e+01  4.2407e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       74-      59  1.1596e+03  5.5940e+01  2.4563e-05
    1T  6.8e-06       25-      63  1.1757e+03  4.4027e+01  1.2534e-05
    1T -2.1e-06       32-      72  2.3404e+03  6.4973e+01  2.0486e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       28-      65  1.3149e+03  5.7358e+01  1.2286e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.

{Error using parpool (line 113)
Parallel pool failed to start with the following error. For more detailed
information, validate the profile 'local' in the Cluster Profile Manager.

Error in create_centered_features_bands (line 4)
parpool(36)

Caused by:
    Error using parallel.internal.pool.InteractiveClient>iThrowWithCause (line
    676)
    Failed to start pool.
        Error using parallel.Cluster/createConcurrentJob (line 1023)
        Unable to write to MAT-file
        /home/research/g.dehghanpoor/.matlab/local_cluster_jobs/R2018a/Job47.in.mat.
                The file may be corrupt.
} 
SVM_train;

indexes =

  Columns 1 through 13

     2   107   146    49    53   113    53    65    60    75     6    44   100

  Columns 14 through 26

    56    70    36   103   165    90    97    94    54   185   128    67   120

  Columns 27 through 30

   126    77   175    84

{Index in position 3 exceeds array bounds (must not exceed 75).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       19-      63  8.8096e+02  4.9495e+01  4.2407e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       28-      65  1.3149e+03  5.7358e+01  1.2286e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       32-      72  2.3404e+03  6.4973e+01  2.0486e-06
    1T  6.8e-06       25-      63  1.1757e+03  4.4027e+01  1.2534e-05
    1T  8.7e-06       74-      59  1.1596e+03  5.5940e+01  2.4563e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-07       28-      69  1.6720e+03  4.5990e+01  7.0627e-07
    1T  3.5e-06       29-      43  1.3759e+03  4.2292e+01  8.7446e-05
    1T -5.1e-06       37-      69  3.2359e+03  5.1054e+01  7.1984e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       12-      68  1.5545e+03  5.4381e+01  6.6630e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       62-      64  2.1206e+03  4.5593e+01  1.7390e-05
    1T  2.0e-06       44-      65  1.4620e+03  4.7790e+01  7.7137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       19-      67  1.4904e+03  4.4968e+01  2.1707e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06       29-      66  1.3825e+03  4.3295e+01  8.9572e-03
    1T  6.8e-06       45-      60  1.3865e+03  4.3077e+01  1.3147e-04
    1T -3.1e-06       12-      63  1.7371e+03  4.7449e+01  4.2700e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       30-      71  2.7347e+03  5.0823e+01  1.0789e-04
    1T  6.4e-07        4-      63  2.1110e+03  4.1064e+01  2.0657e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       12-      64  1.4825e+03  3.9226e+01  1.6931e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.382255s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-07       56-      74  6.5510e+03  6.3377e+01  4.3263e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       33-      66  2.8655e+03  4.4632e+01  3.3597e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   163    21   100   186   183    24    17     6   189    55   200    14   152

  Columns 14 through 26

   142     9   120    78    75   179    30    12    97    16    61    55    11

  Columns 27 through 30

   182    45    31    51

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.0896


Accuracy =

   96.9063


Accuracy =

   97.1111


Accuracy =

   96.6584


Accuracy =

   96.9279


Accuracy =

   96.6261


Accuracy =

   96.7662


Accuracy =

   96.9494


Accuracy =

   97.2405


Accuracy =

   96.9387


Accuracy =9.693867e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   59.5238
   96.8242
   97.1963
   88.3721
   95.2164
   98.9442
   88.4615
   96.7593
   83.3333
   95.3250
   98.4263
   94.0631
   97.3118
   99.0359
   99.7151
   91.6667

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   92.5109




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       41-      73  3.2054e+03  6.1191e+01  8.9805e-06
    1T -6.2e-06       24-      60  1.4710e+03  5.1659e+01  9.3396e-06
    1T  1.3e-06       13-      67  6.4504e+02  7.4735e+01  1.6205e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       54-      70  2.2255e+03  4.3603e+01  1.1327e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-07       57-      65  1.3842e+03  4.1812e+01  1.6707e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06        7-      67  1.2586e+03  4.3751e+01  6.8393e-04
    1T  9.2e-06       56-      65  1.1081e+03  4.7982e+01  1.1273e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       62-      74  2.0223e+03  5.3420e+01  6.1688e-06
    1T -8.2e-06       66-      64  2.3927e+03  4.6658e+01  1.4518e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.365063s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       63-      63  2.1282e+03  4.5518e+01  6.3815e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       75-      70  2.6002e+03  4.1752e+01  1.8452e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   171    98    82   183   155    19   194     8   104   128    78    56    81

  Columns 14 through 26

   145   170   133   172    74    65    72    68   119   124    32   162   153

  Columns 27 through 30

   101    46   111   130

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3981


Accuracy =

   96.4089


Accuracy =

   96.6246


Accuracy =

   96.0531


Accuracy =

   96.6030


Accuracy =

   96.4628


Accuracy =

   96.8619


Accuracy =

   96.7648


Accuracy =

   96.9481


Accuracy =

   96.6893


Accuracy =9.668931e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   85.7143
   98.2184
   91.4894
  100.0000
   99.3103
   98.1791
   96.1538
   96.5438
   94.4444
   91.2500
   98.9179
   94.4444
   95.6757
   99.5629
   91.1429
   91.6667

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   95.1696




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       53-      74  2.2579e+03  6.3250e+01  6.5727e-06
    1T -5.5e-06       31-      38  1.0934e+03  4.4116e+01  2.0298e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        8-      58  1.2125e+03  4.4460e+01  4.3393e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       19-      65  1.6035e+03  5.4696e+01  2.4848e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06        7-      63  2.0062e+03  5.0616e+01  9.7765e-05
    1T -4.4e-06       55-      60  1.2797e+03  4.4626e+01  1.2344e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      71  2.5525e+03  5.8873e+01  3.6870e-06
    1T  5.9e-07       29-      65  2.2089e+03  4.3234e+01  7.6401e-06
    1T  5.0e-06        9-      72  3.4582e+03  5.3801e+01  9.5518e-06
    1T  7.1e-06       59-      74  2.4098e+03  6.0370e+01  5.9026e-06
    1T  8.9e-06       64-      65  2.9618e+03  5.4385e+01  2.7564e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T -8.4e-06       30-      55  1.5144e+03  4.0014e+01  2.2569e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
    1T  6.9e-06       22-      62  2.7221e+03  3.9325e+01  2.9624e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.390468s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06        5-      68  3.1826e+03  5.1139e+01  1.9458e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-07       36-      63  2.1163e+03  4.1477e+01  1.4068e-06
    1T  5.6e-06        7-      69  2.1587e+03  5.0699e+01  9.3978e-06
    1T  9.3e-06        7-      72  2.6533e+03  5.4970e+01  1.1740e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   120    74   183   118   173   114    63   109    14   127   143    31   160

  Columns 14 through 26

   169   186    65   120    71   191   102   120    40    18    81    74   157

  Columns 27 through 30

    18    72   197   167

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.7999


Accuracy =

   96.5521


Accuracy =

   96.7353


Accuracy =

   96.6814


Accuracy =

   96.9077


Accuracy =

   96.3151


Accuracy =

   96.9615


Accuracy =

   96.8646


Accuracy =

   97.0585


Accuracy =

   97.0477


Accuracy =9.704773e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   92.8571
   96.9040
   96.0317
   85.1163
   95.8716
   98.3308
   96.1538
   99.0741
   72.2222
   95.0969
   99.1003
   97.2171
   82.2581
   99.5633
   98.5714
   89.4118

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   93.3613




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       29-      60  9.2669e+02  4.1922e+01  7.2116e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       29-      60  9.2669e+02  4.1922e+01  7.2116e-03
    1T  3.6e-06       29-      60  9.2669e+02  4.1922e+01  7.2116e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-07       45-      67  1.3450e+03  5.1209e+01  1.4747e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       63-      37  9.7046e+02  4.1634e+01  2.0858e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       26-      58  9.7901e+02  5.2007e+01  1.0581e-05
    1T  5.7e-06       11-      73  8.5736e+02  6.1364e+01  3.2371e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       40-      53  6.8115e+02  4.9259e+01  5.7550e-06
    1T -9.5e-06       62-      68  1.9330e+03  5.7999e+01  1.7093e-05
    1T  1.8e-06       16-      55  1.0477e+03  4.6402e+01  5.7226e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       32-      67  1.4542e+03  5.1165e+01  2.7428e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       38-      72  2.0329e+03  5.3769e+01  1.6144e-05
    1T  4.0e-06       32-      59  1.2887e+03  4.5270e+01  2.6657e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       20-      72  2.8024e+03  5.1088e+01  8.2108e-06
    1T -1.5e-06        5-      71  3.1451e+03  6.3020e+01  5.1471e-03
    1T -2.8e-06       46-      68  2.2444e+03  4.2779e+01  4.3087e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       26-      68  2.5110e+03  4.8097e+01  2.5506e-06
    1T  2.3e-06        2-      73  1.5357e+03  5.7269e+01  1.5889e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.363173s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       14-      70  2.5297e+03  4.0705e+01  1.6827e-05
    1T  2.0e-06       38-      74  4.0225e+03  5.1668e+01  2.4679e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       19-      69  3.3975e+03  4.3187e+01  1.1220e-05
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -2.2e-06       63-      73  2.7210e+03  4.8352e+01  4.7100e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       68-      62  1.9112e+03  3.9809e+01  5.9223e-05
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
    1T -3.4e-06       50-      71  2.7495e+03  3.9107e+01  5.7135e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   200    66   137    51    30    69   146   185    79    91   154    93    62

  Columns 14 through 26

    67    80   173    36   124   170   177    11   184   133    23   173    22

  Columns 27 through 30

    35    71   178    99

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.4674


Accuracy =

   97.8877


Accuracy =

   97.4243


Accuracy =

   97.5536


Accuracy =

   97.4027


Accuracy =

   97.7799


Accuracy =

   97.8661


Accuracy =

   97.3812


Accuracy =

   97.6937


Accuracy =

   97.9093


Accuracy =9.790926e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   76.7442
   98.7626
   98.6720
   93.0233
   97.2477
   98.7879
   69.2308
  100.0000
   94.4444
   95.7955
   98.7393
   98.3240
   97.8495
   99.7375
   92.8775
   90.5882

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   93.8015




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
{Operation terminated by user during struct_nonneg (line 35)


In sdf_core/derivexpand (line 525)
                    sub{j} = seq{k}(ftr{k-1},task);

In sdf_core/JHJx (line 669)
        x = derivexpand(x);

In nls_gndl/JHJx (line 243)
    y = dF.JHJx(z,x);

In mpcg (line 78)
    else Ad = A(d); end

In nls_gndl (line 376)
                mpcg(@JHJx,-grad,options.CGTol,options.CGMaxIter,dF.PC, ...

In sdf_core (line 335)
[z,output] = options.Algorithm(@objfun,dF,model.variables,options);

In sdf_nls (line 145)
    [sol, output] = sdf_core(model,options{:});

In FactorizeTensor (line 18)
sol = sdf_nls(model);
} 
SVM_train;

indexes =

  Columns 1 through 13

    70    60   191   200   136   155   195    63   132    10    12    63   115

  Columns 14 through 26

   105    44    63   124    87     1   124    83   152    71     6    72    39

  Columns 27 through 30

   169   107    28    66

{Index in position 3 exceeds array bounds (must not exceed 1).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       19-      61  2.6656e+02  4.0519e+01  2.9593e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06        6-      61  5.2072e+02  4.7333e+01  1.7994e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       39-      62  1.1759e+02  3.6262e+01  1.5677e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       27-      59  2.9540e+02  4.0341e+01  2.6742e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       71-      59  1.7754e+02  3.4624e+01  1.0660e-03
    1T  1.9e-06       50-      59  1.0939e+02  3.6356e+01  9.6225e-04
    1T -3.5e-06        6-      64  1.1911e+02  3.3092e+01  9.3765e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       46-      58  1.1936e+02  2.7329e+01  1.3361e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       22-      63  6.8254e+02  4.5618e+01  6.8531e-04
    1T  2.3e-06       12-      60  2.8416e+02  3.4219e+01  4.0482e-07
    1T  2.8e-06       75-      57  2.8096e+02  3.6910e+01  9.2224e-07
    1T -9.3e-06       41-      65  4.1012e+02  4.4259e+01  2.1457e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       10-      63  1.9415e+02  4.1021e+01  2.8720e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       17-      55  2.5363e+02  2.9567e+01  1.5297e-06
    1T  4.1e-06       47-      59  1.3248e+02  3.7278e+01  2.1145e-03
    1T  3.5e-07        6-      59  2.7989e+02  4.4072e+01  3.5749e-03
    1T  9.4e-06       47-      57  7.0543e+02  4.8602e+01  1.5954e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       40-      65  2.1738e+02  3.7949e+01  6.5058e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       46-      57  1.1421e+02  5.7610e+01  2.0983e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       44-      58  2.3304e+02  3.5913e+01  1.6050e-03
    1T  4.3e-07       22-      60  2.0368e+02  3.3582e+01  2.4505e-03
    1T  1.8e-06       29-      64  3.4341e+02  4.1812e+01  1.2680e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       65-      54  3.1793e+02  5.7675e+01  5.8343e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       18-      59  2.4926e+02  4.6547e+01  6.8165e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       25-      62  1.6926e+02  2.7180e+01  1.3110e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       65-      57  7.8679e+02  2.5057e+01  4.3495e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       33-      58  1.0369e+03  2.4414e+01  4.2010e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06        8-      67  3.1687e+02  2.3757e+01  5.7523e-04
    1T -1.4e-06       73-      65  1.6741e+02  2.5854e+01  1.6141e-03
    1T  9.3e-06       54-      63  4.6912e+02  2.8580e+01  1.7896e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-07       49-      66  5.7162e+02  3.7552e+01  6.6144e-07
    1T  9.7e-06       50-      59  2.9657e+02  2.2418e+01  2.5840e-03
    1T  2.5e-06       27-      64  2.2851e+02  2.5476e+01  2.0921e-04
    1T  4.5e-07       57-      66  1.3650e+03  3.9580e+01  3.4498e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       73-      64  2.0326e+03  4.3993e+01  9.9325e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       18-      42  9.8313e+02  3.5766e+01  2.0255e-06
    1T -3.9e-06       26-      64  2.1528e+03  3.7931e+01  2.9181e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       28-      62  3.2875e+02  2.2683e+01  2.4845e-03
    1T -4.3e-06       62-      52  7.2445e+02  3.7468e+01  1.8174e-03
    1T  5.2e-06       10-      62  1.9831e+02  3.1814e+01  1.3079e-06
    1T  1.5e-06       19-      62  6.9875e+02  3.1161e+01  2.8070e-07
    1T  9.3e-06       54-      61  1.7984e+02  2.6964e+01  3.5549e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       71-      66  2.5990e+02  2.5305e+01  3.8920e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       36-      68  4.6256e+02  2.7564e+01  1.5346e-06
    1T -2.1e-06        5-      61  6.3075e+02  3.0727e+01  6.1876e-03
    1T  3.9e-06       26-      68  2.2639e+02  2.9441e+01  3.0872e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       12-      60  1.1140e+03  2.8380e+01  1.1599e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06        8-      66  1.8071e+02  2.9658e+01  1.5318e-03
    1T -4.8e-07       12-      62  1.7786e+02  3.5655e+01  1.3367e-03
    1T  2.6e-06        1-      68  4.9515e+02  2.8384e+01  3.3489e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       59-      63  1.7515e+02  2.8541e+01  3.7946e-03
    1T  4.0e-06       39-      69  2.0522e+02  2.5740e+01  8.6054e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       54-      64  1.2608e+03  1.7460e+01  4.2421e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       16-      62  1.3782e+03  1.9767e+01  2.9872e-03
    1T  9.1e-06       56-      68  1.5410e+03  1.8651e+01  2.3330e-03
    1T  6.4e-07        9-      65  2.4660e+02  1.8541e+01  2.6189e-04
    1T  3.2e-06       50-      67  3.4855e+02  2.0020e+01  3.2366e-06
    1T -7.5e-06        5-      65  2.3756e+02  1.7915e+01  2.1306e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       31-      64  9.1633e+02  1.9247e+01  4.5087e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       21-      67  4.0971e+02  2.1543e+01  1.5940e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       16-      68  3.0107e+02  2.2916e+01  2.4364e-03
    1T  1.5e-06        2-      70  3.7455e+02  2.1879e+01  3.3179e-03
    1T -8.3e-06       29-      65  2.5552e+02  2.2355e+01  2.6427e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       14-      64  3.6859e+02  2.8067e+01  2.4126e-03
    1T  5.8e-06        9-      65  2.1085e+02  2.8477e+01  3.0580e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       42-      60  4.8987e+02  2.4081e+01  2.7987e-03
    1T  6.4e-06        9-      61  8.0745e+02  1.8720e+01  2.0617e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       10-      69  6.6354e+02  2.1019e+01  2.1879e-05
    1T -5.3e-07       12-      64  6.2640e+02  2.4128e+01  1.2603e-03
    1T  4.3e-06       10-      65  6.4048e+02  2.4966e+01  9.9924e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       16-      53  2.3003e+03  2.7891e+01  1.9752e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       73-      62  1.1870e+03  2.3883e+01  3.1522e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       21-      64  6.1736e+02  2.2792e+01  1.3359e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       72-      64  3.8318e+02  2.1933e+01  3.6124e-03
    1T  8.1e-06       51-      66  3.6932e+02  2.2021e+01  5.2530e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   198    67   136    76   152   141   180   178   137    76   133    75   164

  Columns 14 through 26

   142    38    16    13   164   126   115   180    15    63     8    40   152

  Columns 27 through 30

    18    90    93   100


Accuracy =

   98.6733


Accuracy =

   98.6578


Accuracy =

   98.7120


Accuracy =

   98.5985


Accuracy =

   98.6681


Accuracy =

   98.5830


Accuracy =

   98.5623


Accuracy =

   98.5778


Accuracy =

   98.5830


Accuracy =

   98.6114


Accuracy =9.861136e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   98.7348
   99.9763
   94.3803
   96.1081
   98.6885
   99.6924
   96.5862
   96.2196
   94.6574

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   97.2271




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       32-      62  1.1881e+03  7.9853e+01  7.0203e-07
    1T  9.2e-06       32-      62  1.1881e+03  7.9853e+01  7.0203e-07
    1T  9.2e-06       32-      62  1.1881e+03  7.9853e+01  7.0203e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       31-      62  1.5414e+02  3.2041e+01  1.7020e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06        1-      58  2.2633e+02  3.2150e+01  9.0786e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       30-      70  5.3936e+02  4.8656e+01  1.4088e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       32-      56  2.1617e+02  3.1064e+01  4.1170e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06        6-      63  2.9635e+02  2.6891e+01  1.4805e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-07       69-      67  8.4410e+02  4.4490e+01  2.9244e-03
    1T -7.8e-06       39-      58  1.7977e+02  2.6595e+01  3.2445e-04
    1T  1.5e-06       36-      62  1.2522e+02  3.2370e+01  4.7205e-07
    1T  7.1e-06       66-      63  2.9541e+02  3.3466e+01  5.6245e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       58-      63  2.5240e+02  3.3948e+01  9.8396e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       38-      60  4.2737e+02  2.6732e+01  1.8640e-03
    1T  7.2e-06        9-      63  2.9681e+02  4.5899e+01  1.0758e-05
    1T  7.2e-06       13-      55  9.1949e+02  3.1328e+01  1.8532e-06
    1T  2.7e-06       70-      65  3.8047e+02  4.0288e+01  1.4272e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        4-      62  1.5159e+02  3.1728e+01  3.6687e-07
    1T  1.2e-06       44-      64  3.4791e+02  4.0408e+01  4.3551e-03
    1T -9.3e-06       46-      55  2.2359e+02  2.6197e+01  1.8447e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.6e-06        6-      60  2.3473e+02  3.5495e+01  9.3599e-04
    1T  7.8e-06       72-      59  1.0079e+02  2.7434e+01  1.1333e-03
    1T  3.8e-06       37-      49  3.4056e+02  2.7365e+01  4.3377e-03
    1T  2.0e-06       31-      62  1.2937e+02  3.8778e+01  2.4328e-03
    1T -1.0e-05       45-      66  3.1979e+02  2.9011e+01  2.6277e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       72-      63  1.6084e+02  3.5667e+01  1.3029e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       17-      61  2.2746e+02  3.9544e+01  1.4515e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-07       27-      61  4.6311e+02  4.2652e+01  9.8731e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       59-      57  1.9779e+02  3.4268e+01  1.3883e-04
    1T -2.0e-07       58-      60  1.3735e+02  4.2173e+01  2.4747e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       54-      56  1.6232e+02  3.4306e+01  3.5475e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       54-      56  1.6232e+02  3.4306e+01  3.5475e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       54-      56  1.6232e+02  3.4306e+01  3.5475e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       60-      60  1.7679e+02  3.4941e+01  4.0078e-03
    1T  5.2e-06       16-      60  1.3284e+02  3.9898e+01  4.0683e-03
    1T  8.4e-06       31-      59  3.1564e+02  2.9769e+01  2.6390e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       30-      57  1.6360e+02  3.6401e+01  9.5810e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       46-      55  3.0653e+02  2.4944e+01  9.2012e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06        6-      57  1.8194e+02  2.4792e+01  2.2090e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       75-      47  2.7236e+02  2.3678e+01  3.9844e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       52-      67  1.9032e+02  2.9507e+01  2.6839e-03
    1T  1.9e-06       25-      68  4.9233e+02  6.2623e+01  3.4558e-07
    1T  7.3e-06       55-      59  9.1183e+02  2.7679e+01  8.3769e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-07       12-      65  1.0157e+03  3.2326e+01  1.9911e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       42-      66  1.1479e+03  3.4101e+01  2.4159e-03
    1T  3.0e-06        1-      60  4.4767e+02  2.5024e+01  1.6747e-07
    1T  1.6e-06       38-      64  5.1349e+02  2.9578e+01  1.7625e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       74-      59  4.8622e+02  3.3772e+01  1.6445e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       49-      61  3.7572e+02  3.0548e+01  2.1861e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       63-      59  4.3616e+02  3.3175e+01  5.6747e-03
    1T  1.3e-06       39-      67  2.1884e+02  2.8446e+01  1.9068e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06        6-      63  1.8624e+02  3.2147e+01  2.8396e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       36-      64  8.7226e+02  3.2322e+01  1.4588e-03
    1T  7.2e-06       59-      64  2.1798e+02  3.3539e+01  2.2479e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06        4-      60  7.8842e+02  3.7000e+01  1.1892e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       14-      66  3.5041e+02  3.5748e+01  1.8586e-03
    1T  8.4e-06       55-      48  1.9955e+02  3.2501e+01  3.2263e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       15-      57  3.1114e+02  3.5427e+01  2.0039e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       23-      64  2.5416e+02  3.5218e+01  2.4101e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       52-      63  3.2102e+02  3.1240e+01  2.1539e-03
    1T  9.6e-06       38-      66  2.2810e+02  3.3132e+01  2.4024e-06
    1T  2.8e-07       28-      64  6.5356e+02  3.5518e+01  1.5518e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       67-      63  3.2237e+02  2.2281e+01  2.7567e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       13-      66  1.5368e+03  2.9120e+01  1.4290e-06
    1T -8.1e-06        2-      67  8.7736e+02  2.4275e+01  2.1341e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       48-      64  1.5577e+03  2.7843e+01  1.6194e-06
    1T  1.5e-06        9-      65  8.4696e+02  2.0532e+01  1.4870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       55-      64  4.4263e+02  2.0323e+01  3.3027e-03
    1T -3.8e-06       27-      63  1.4340e+03  2.8599e+01  9.5070e-04
    1T  5.8e-08       68-      60  1.2586e+03  3.0107e+01  5.8183e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-07       46-      60  2.3341e+03  2.2472e+01  3.4370e-04
    1T  1.8e-06       30-      61  2.9397e+03  4.3232e+01  1.0801e-04
    1T  3.8e-06       36-      67  1.5347e+03  2.9582e+01  5.0365e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       15-      59  9.7472e+02  2.1910e+01  2.7839e-03
    1T  8.0e-06       25-      67  5.4967e+02  1.9962e+01  5.7726e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       25-      63  6.6937e+02  2.8165e+01  2.7913e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       53-      65  1.3814e+03  2.9806e+01  2.1071e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       66-      69  3.1543e+02  2.3184e+01  2.5209e-03
    1T  4.6e-06       24-      65  1.8332e+03  2.2390e+01  1.5550e-03
    1T -6.8e-07       66-      66  4.4284e+02  2.3314e+01  4.1161e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       68-      62  4.8856e+02  2.3227e+01  1.9196e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    78    85     4   186   165    42   145     8   175    39   167    75   174

  Columns 14 through 26

    60    87    32    97   127   129   169   194   154   142   152    96    64

  Columns 27 through 30

   115    10    53   163


Accuracy =

   98.3731


Accuracy =

   98.3964


Accuracy =

   98.3654


Accuracy =

   98.2621


Accuracy =

   98.3292


Accuracy =

   98.2079


Accuracy =

   98.3241


Accuracy =

   98.3138


Accuracy =

   98.3086


Accuracy =

   98.2466


Accuracy =9.824661e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   98.6507
   99.9822
   89.7059
   96.4995
   98.9362
   99.4288
   90.7731
   96.4254
   96.1404

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.2824




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       37-      66  5.6526e+02  4.7059e+01  5.1055e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-07       58-      59  5.0236e+02  3.7302e+01  2.4545e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       64-      66  1.2064e+02  5.3601e+01  3.4784e-07
    1T -3.6e-06       51-      61  1.0830e+02  3.8428e+01  2.6190e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06        1-      61  1.8931e+02  3.7325e+01  3.0967e-04
    1T  6.7e-06       21-      59  1.7438e+02  3.7012e+01  2.8666e-06
    1T  9.6e-06       73-      62  6.6410e+02  4.6225e+01  7.1418e-03
    1T  4.1e-06       67-      66  1.3283e+02  4.3487e+01  2.1031e-03
    1T  2.9e-06       48-      60  3.9599e+02  3.9258e+01  4.4135e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       43-      35  5.8777e+02  4.6971e+01  4.0792e-07
    1T  2.5e-06        3-      59  1.8722e+02  3.6714e+01  1.3739e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.5e-06       15-      60  2.9032e+02  3.9954e+01  2.4887e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       53-      65  8.5820e+02  4.3513e+01  1.6363e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       17-      69  4.7402e+02  5.5392e+01  1.0820e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       17-      63  1.1401e+02  4.8777e+01  2.6707e-03
    1T -5.5e-06        4-      66  1.2399e+02  4.1328e+01  1.6493e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06        9-      55  1.8397e+02  3.7911e+01  3.5889e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-07       61-      61  6.3239e+02  4.9220e+01  3.9048e-04
    1T  2.6e-06       27-      66  2.1100e+02  4.7100e+01  3.5136e-07
    1T  2.6e-06       27-      66  2.1100e+02  4.7100e+01  3.5136e-07
    1T  2.6e-06       27-      66  2.1100e+02  4.7100e+01  3.5136e-07
    1T  5.4e-06       66-      60  1.4986e+02  4.1937e+01  2.4474e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       62-      46  3.0019e+02  4.9516e+01  6.0663e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       27-      66  2.1100e+02  4.7100e+01  3.5136e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       27-      66  2.1100e+02  4.7100e+01  3.5136e-07
    1T  5.2e-06       25-      54  2.0775e+02  4.7467e+01  5.4510e-05
    1T  2.6e-06       27-      66  2.1100e+02  4.7100e+01  3.5136e-07
    1T  7.8e-06       69-      50  3.3420e+02  4.8334e+01  6.4753e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       65-      60  1.0384e+02  4.0559e+01  1.0721e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       38-      66  9.8833e+02  2.7703e+01  4.5648e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       24-      51  9.3671e+02  2.7597e+01  4.2026e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       52-      60  3.3114e+02  2.1976e+01  5.6836e-05
    1T  3.9e-06       39-      55  1.7422e+02  2.1985e+01  2.9686e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06        7-      57  2.9894e+02  2.3918e+01  3.3234e-04
    1T  7.8e-06       67-      68  4.9373e+02  3.6908e+01  1.5310e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       64-      48  1.6492e+03  4.9149e+01  3.6017e-03
    1T  5.4e-06       36-      52  1.4873e+03  4.0686e+01  1.5279e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       26-      56  6.7443e+02  2.8959e+01  1.1214e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       25-      58  4.1883e+02  2.2259e+01  1.6333e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       49-      51  5.2922e+02  2.2664e+01  3.7235e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-07       66-      64  3.5758e+02  3.6065e+01  3.4310e-08
    1T  3.8e-06       32-      62  5.5648e+02  2.4084e+01  4.0618e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       33-      62  2.0468e+02  2.9104e+01  6.2576e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       39-      52  2.7788e+02  2.4664e+01  5.8997e-03
    1T  3.5e-06       73-      65  9.0776e+02  3.8583e+01  1.7028e-06
    1T -5.6e-07       51-      63  4.5338e+02  2.8038e+01  3.5049e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       66-      65  4.6384e+02  2.8480e+01  3.9857e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       22-      69  2.7493e+02  3.0486e+01  1.6644e-03
    1T -8.8e-06       69-      57  4.0951e+02  2.8537e+01  6.0317e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06       46-      65  4.4360e+02  2.9203e+01  9.2902e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       30-      65  5.4138e+02  2.3327e+01  2.7593e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       17-      63  8.1525e+02  2.3675e+01  1.2865e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       12-      68  9.8686e+02  2.7782e+01  1.2062e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06        4-      66  3.7152e+02  2.6234e+01  2.5424e-03
    1T  8.7e-07       41-      69  1.0665e+03  3.1316e+01  1.4517e-07
    1T  8.2e-06       33-      68  4.8351e+02  3.2637e+01  3.7197e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       33-      69  6.4814e+02  3.1187e+01  9.5369e-07
    1T  3.3e-06        8-      65  4.6343e+02  2.5814e+01  5.7436e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       27-      62  3.1932e+02  3.0817e+01  5.8836e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-07       32-      65  3.9914e+02  2.5477e+01  1.4533e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       23-      53  1.6647e+03  4.4820e+01  4.0788e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       55-      63  5.0537e+02  2.9187e+01  2.5872e-07
    1T -3.9e-06       27-      61  1.8651e+03  2.9760e+01  3.1206e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       42-      66  5.2638e+02  3.8091e+01  3.9872e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       28-      67  4.2112e+02  2.9778e+01  3.6309e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   198   173     6   120   200   199   103    24   104   188   162   186   158

  Columns 14 through 26

   160   180     7    94     9    54   159   124    38   111   199   121   181

  Columns 27 through 30

   155   108   185   187


Accuracy =

   98.4652


Accuracy =

   98.5557


Accuracy =

   98.5376


Accuracy =

   98.4911


Accuracy =

   98.5893


Accuracy =

   98.3128


Accuracy =

   98.5247


Accuracy =

   98.4704


Accuracy =

   98.4575


Accuracy =

   98.4549


Accuracy =9.845490e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   99.1332
   99.9881
   92.3523
   96.7231
   98.2744
   99.8242
   95.9336
   94.1176
   96.0373

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.9315




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       63-      65  2.0546e+02  2.8258e+01  1.7376e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       41-      62  7.2738e+02  4.2459e+01  3.4326e-03
    1T  2.4e-06       68-      54  1.0819e+03  3.7409e+01  4.3724e-03
    1T  2.1e-06       37-      55  4.7174e+02  3.9557e+01  5.3428e-07
    1T  4.0e-07       43-      55  3.1930e+02  4.4676e+01  1.9669e-07
    1T -6.3e-06       66-      61  7.5115e+02  4.3866e+01  4.0664e-03
    1T  8.6e-06       33-      54  8.7619e+02  3.8561e+01  3.5106e-06
    1T  1.6e-07       73-      60  1.1195e+02  3.8241e+01  2.6256e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       45-      60  1.9551e+02  3.4898e+01  2.5466e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-08        8-      66  2.0926e+02  3.5169e+01  2.3090e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-07       71-      33  2.8984e+02  4.3201e+01  4.0829e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       33-      62  1.4263e+02  2.9069e+01  1.0472e-06
    1T -8.8e-06       61-      65  2.8701e+02  4.4795e+01  1.0415e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       44-      56  1.0512e+02  3.4521e+01  7.9636e-07
    1T -3.0e-06       47-      65  4.9261e+02  3.8339e+01  7.7382e-04
    1T  8.8e-06        3-      58  5.0995e+02  3.0507e+01  3.1060e-06
    1T  6.5e-06       42-      58  2.3616e+02  4.2427e+01  6.6199e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       39-      62  1.1200e+02  3.8327e+01  2.1023e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       24-      63  1.6502e+02  5.2053e+01  5.1403e-03
    1T  5.1e-06       14-      67  2.1346e+02  3.7372e+01  2.1934e-03
    1T  8.1e-06       32-      61  3.7656e+02  4.6844e+01  1.3900e-04
    1T  3.0e-06       57-      64  1.6804e+02  3.8005e+01  4.4256e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       72-      64  2.0219e+02  2.8533e+01  4.1935e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       41-      60  2.2186e+02  2.5519e+01  1.4050e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       56-      62  3.4866e+02  2.4536e+01  1.3468e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       38-      65  2.0023e+02  2.6438e+01  3.5669e-03
    1T -4.5e-06       25-      63  4.9914e+02  2.5703e+01  8.5831e-04
    1T  2.9e-06       56-      68  1.6876e+02  2.5536e+01  2.1292e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       45-      60  5.3103e+02  2.3834e+01  4.7227e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-07       44-      63  1.9104e+02  2.5014e+01  3.4678e-03
    1T  1.5e-06       65-      57  1.5762e+02  2.7343e+01  1.0864e-07
    1T -5.4e-06       28-      66  2.0082e+02  2.5116e+01  2.5326e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       58-      65  2.6139e+02  2.4801e+01  6.3404e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       51-      64  3.3152e+02  2.6434e+01  3.0291e-03
    1T  1.0e-05       52-      58  1.0728e+03  2.6111e+01  8.7414e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06        6-      60  4.7574e+02  2.6724e+01  1.4269e-06
    1T -3.5e-06       29-      65  4.8041e+02  2.6873e+01  3.5074e-03
    1T -2.8e-06       44-      60  1.5549e+02  3.3923e+01  5.6095e-04
    1T  2.0e-06       39-      66  3.3198e+02  2.6296e+01  8.5389e-07
    1T -3.1e-06        5-      61  3.9452e+02  2.2073e+01  3.5423e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       47-      65  2.5312e+02  3.0914e+01  4.8592e-07
    1T -7.3e-06       75-      55  4.0562e+02  2.3552e+01  5.2980e-03
    1T  9.8e-06       57-      61  3.8099e+02  2.7051e+01  9.7371e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       19-      51  2.1251e+02  2.7678e+01  4.2327e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       75-      56  2.7387e+02  3.4608e+01  2.9851e-03
    1T -3.3e-06       14-      57  2.0111e+02  3.2625e+01  2.2818e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       35-      61  2.2176e+02  2.6906e+01  4.1704e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       32-      61  3.1687e+02  2.3150e+01  1.5721e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       74-      65  7.2469e+02  2.4473e+01  2.7403e-07
    1T  3.7e-06       42-      69  1.7972e+03  2.4967e+01  2.5578e-03
    1T  9.4e-07       16-      58  1.1783e+03  2.0613e+01  2.5260e-03
    1T -9.1e-06       57-      67  1.3302e+03  2.5931e+01  2.6917e-03
    1T  3.6e-07       49-      60  1.1868e+03  2.3270e+01  1.1649e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       50-      66  9.9715e+02  5.2378e+01  1.2165e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       27-      66  4.2231e+02  2.3453e+01  2.2195e-03
    1T  1.7e-06       72-      63  4.3378e+02  2.6022e+01  4.1911e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       24-      67  8.0063e+02  2.8783e+01  5.9909e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.5e-06       45-      64  2.8950e+02  2.3563e+01  4.2230e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       32-      67  2.8076e+02  2.6782e+01  4.0826e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       19-      64  3.7031e+02  1.9664e+01  1.2461e-03
    1T  2.3e-06       73-      64  8.3461e+02  1.9397e+01  5.8519e-07
    1T  5.3e-06        2-      60  1.9445e+03  2.9401e+01  9.2066e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       75-      65  1.1863e+03  2.2867e+01  7.4917e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       12-      64  2.6701e+02  2.6060e+01  1.3621e-03
    1T  1.0e-06       49-      68  6.4938e+02  2.3798e+01  3.5469e-03
    1T  8.7e-06       40-      63  3.6822e+02  2.6573e+01  3.0748e-06
    1T  1.2e-06        6-      63  1.4646e+03  3.1755e+01  3.1823e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       43-      62  5.0809e+02  2.4740e+01  2.0358e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       11-      66  3.4851e+02  2.4318e+01  1.6311e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       23-      65  4.1430e+02  2.7037e+01  2.6810e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   174   142    89    70    89    12   156   166    57     7    64   119    29

  Columns 14 through 26

    93    69   121    32   100   115     9   132   101   144   122    73   162

  Columns 27 through 30

    39    84   151    39


Accuracy =

   98.2412


Accuracy =

   98.2102


Accuracy =

   98.1844


Accuracy =

   98.1043


Accuracy =

   98.1715


Accuracy =

   98.0837


Accuracy =

   98.1586


Accuracy =

   98.1508


Accuracy =

   98.2025


Accuracy =

   98.1689


Accuracy =9.816890e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   99.2171
   99.9526
   91.8421
   96.1386
   99.3437
   99.2754
   95.1159
   92.6060
   94.6387

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.4589




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06        4-      62  1.6728e+02  4.0769e+01  1.6580e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       28-      57  3.5602e+02  6.6225e+01  2.1806e-03
    1T -7.4e-06       40-      57  6.8528e+02  3.6631e+01  5.4533e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       16-      60  1.9362e+02  4.3266e+01  1.6004e-03
    1T -9.1e-06       32-      49  1.9944e+03  7.5845e+01  2.3313e-03
    1T -4.5e-06       15-      59  2.1083e+02  3.1859e+01  3.5624e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       53-      60  6.3890e+02  4.8980e+01  3.3761e-03
    1T -1.6e-06       30-      54  1.9417e+02  2.6144e+01  2.9151e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       35-      63  6.5367e+02  3.8751e+01  2.0487e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       45-      48  6.8875e+02  3.3254e+01  1.3053e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       14-      57  1.4591e+02  2.9862e+01  4.1812e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       38-      64  2.9841e+02  6.1122e+01  1.0708e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       25-      60  3.1358e+02  4.3028e+01  9.4759e-04
    1T  5.6e-06       15-      61  2.5769e+02  3.8759e+01  1.2287e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       15-      61  2.5769e+02  3.8759e+01  1.2287e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       15-      61  2.5769e+02  3.8759e+01  1.2287e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       15-      61  2.5769e+02  3.8759e+01  1.2287e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       15-      61  2.5769e+02  3.8759e+01  1.2287e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       15-      61  2.5769e+02  3.8759e+01  1.2287e-03
    1T  1.2e-07       47-      59  3.6264e+02  5.2211e+01  1.3696e-08
    1T  5.9e-06       20-      57  1.0064e+02  4.5193e+01  1.2918e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       10-      50  1.0676e+02  3.2872e+01  1.6168e-06
    1T  9.6e-06       73-      61  4.8317e+02  5.0683e+01  4.1350e-03
    1T -8.6e-06       34-      61  9.8598e+02  3.7058e+01  1.1447e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-08       73-      65  2.0067e+02  4.5746e+01  1.1692e-03
    1T -3.6e-06       72-      52  4.5244e+02  3.0432e+01  1.5479e-03
    1T  6.7e-06       51-      66  2.0771e+02  4.6638e+01  9.8686e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       40-      59  1.5584e+02  3.9140e+01  3.4624e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       13-      62  2.1882e+02  4.3518e+01  2.5675e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.0e-06       51-      61  1.2973e+02  4.3718e+01  5.6524e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       58-      59  2.0929e+02  3.6525e+01  1.3727e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       45-      60  2.7781e+02  3.6567e+01  4.7165e-04
    1T -6.5e-06       73-      60  1.8162e+02  4.8186e+01  3.2333e-03
    1T -2.4e-06        3-      52  3.3835e+02  2.8441e+01  2.1797e-03
    1T -4.4e-06       19-      63  1.2916e+02  3.6625e+01  4.5757e-04
    1T  3.9e-06       33-      59  1.6677e+02  4.4308e+01  3.0233e-03
    1T  8.5e-06       35-      57  1.7944e+02  3.0490e+01  3.2986e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       74-      59  5.4096e+02  4.7324e+01  1.4519e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       17-      63  1.8746e+02  4.2196e+01  4.5080e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       35-      67  1.8036e+02  3.3057e+01  9.0761e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       34-      63  8.2674e+02  3.6519e+01  8.0220e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       17-      68  2.3699e+02  3.0809e+01  1.2286e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       10-      63  2.2779e+02  2.6425e+01  1.2747e-06
    1T -1.2e-06       34-      65  1.6460e+02  2.7049e+01  1.8001e-03
    1T  4.9e-06       56-      64  3.3653e+02  2.6046e+01  1.5859e-03
    1T  9.1e-06       10-      62  5.7933e+02  2.8759e+01  1.9634e-06
    1T  4.3e-06       13-      65  3.1526e+02  2.8664e+01  1.5094e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       64-      57  2.7520e+02  2.7764e+01  7.5112e-07
    1T  1.5e-08        7-      68  7.6460e+02  2.8156e+01  3.5561e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-07       43-      48  2.9400e+02  3.0095e+01  2.2294e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       72-      60  2.8715e+02  2.6769e+01  2.2734e-03
    1T  7.7e-08       23-      62  5.5675e+02  3.9510e+01  1.8673e-08
    1T -9.9e-06       61-      55  4.0952e+02  2.8025e+01  3.3505e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       29-      62  2.0468e+02  2.9841e+01  3.5157e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-07        5-      60  1.1703e+03  3.0342e+01  9.1750e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       53-      57  4.4522e+02  2.5621e+01  4.2195e-03
    1T  5.2e-06       36-      62  1.8027e+02  3.1780e+01  3.3481e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       10-      64  1.2029e+03  2.7745e+01  1.6938e-06
    1T  6.5e-06       45-      60  1.3908e+03  5.5220e+01  1.3447e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       21-      65  9.0744e+02  3.1015e+01  1.1294e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       15-      62  5.1626e+02  3.7109e+01  5.7120e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       50-      50  3.5641e+02  2.6296e+01  5.6083e-07
    1T  1.7e-06       23-      64  5.6315e+02  3.6067e+01  3.9811e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06        7-      64  3.0114e+02  3.2673e+01  1.8623e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       25-      62  5.5118e+02  2.5424e+01  3.4298e-03
    1T  3.2e-06       20-      65  2.0914e+02  2.7120e+01  2.1484e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       34-      50  1.2667e+03  2.9234e+01  1.1993e-05
    1T  7.1e-06       34-      50  1.2667e+03  2.9234e+01  1.1993e-05
    1T  7.1e-06       34-      50  1.2667e+03  2.9234e+01  1.1993e-05
    1T  7.1e-06       34-      50  1.2667e+03  2.9234e+01  1.1993e-05
    1T  7.1e-06       34-      50  1.2667e+03  2.9234e+01  1.1993e-05
    1T  7.1e-06       34-      50  1.2667e+03  2.9234e+01  1.1993e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       13-      62  1.4953e+03  3.4467e+01  1.2152e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       75-      55  1.0630e+03  2.7569e+01  6.8901e-08
    1T  7.0e-06       59-      64  2.1782e+03  3.9429e+01  6.9105e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       75-      64  9.5801e+02  2.8045e+01  1.6914e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       74-      69  3.0087e+02  2.7224e+01  2.7145e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   193    96    90    84   135   196    86    18   114   185   113   197    18

  Columns 14 through 26

    11   198   127   101   190   108   134    66   117    61   169    43   132

  Columns 27 through 30

    81   125    11     3


Accuracy =

   98.4329


Accuracy =

   98.3528


Accuracy =

   98.4200


Accuracy =

   98.1618


Accuracy =

   98.4561


Accuracy =

   98.4045


Accuracy =

   98.3477


Accuracy =

   98.3296


Accuracy =

   98.4148


Accuracy =

   98.3477


Accuracy =9.834766e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   98.3361
   99.9882
   94.3158
   95.0216
   99.5062
   99.7149
   95.2618
   95.2024
   93.4808

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.7586




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       18-      60  4.4900e+02  3.8611e+01  3.8451e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       23-      59  2.0996e+02  3.9306e+01  1.9656e-06
    1T  4.0e-06       72-      57  2.8122e+02  3.5080e+01  1.7025e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       15-      61  1.2863e+02  3.2731e+01  1.1282e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        1-      56  4.7316e+02  3.5310e+01  6.1257e-03
    1T  6.1e-06       15-      31  2.0073e+02  4.2700e+01  9.3184e-07
    1T  6.1e-06       59-      65  1.1961e+02  3.2234e+01  1.1561e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       45-      59  2.3975e+02  3.7204e+01  1.8004e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       67-      63  5.7045e+02  5.5735e+01  3.3525e-03
    1T  1.5e-06       51-      54  1.4067e+03  8.4108e+01  2.6629e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       39-      63  2.5245e+02  3.4625e+01  2.8308e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06        1-      53  1.0040e+03  4.4226e+01  6.6993e-06
    1T  3.2e-06       70-      58  1.3817e+02  2.8666e+01  1.2918e-06
    1T  5.1e-07       21-      58  2.6502e+02  3.0612e+01  6.5254e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       69-      52  2.2889e+03  3.1314e+01  2.3463e-03
    1T  7.9e-06       24-      56  4.3113e+02  4.5048e+01  4.4318e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       22-      49  1.7584e+02  2.5897e+01  2.0582e-06
    1T  6.4e-06       45-      62  2.7291e+02  4.4854e+01  2.1774e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       19-      64  1.6959e+02  3.8395e+01  2.3199e-04
    1T  4.8e-06       46-      57  7.6982e+02  3.8143e+01  1.3797e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06        1-      57  7.6212e+02  5.4455e+01  1.8683e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-07       74-      62  3.9829e+02  4.2948e+01  3.0777e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        7-      62  2.5382e+02  3.3673e+01  1.6774e-03
    1T -9.6e-06       12-      63  1.7702e+02  3.6036e+01  2.4658e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       74-      59  1.9484e+02  4.0936e+01  1.6437e-03
    1T  8.7e-06       50-      64  2.4839e+02  2.9973e+01  2.8927e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       24-      61  2.4697e+02  3.3930e+01  3.8363e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       10-      51  1.3829e+02  3.2948e+01  2.6570e-07
    1T  5.4e-06       10-      51  1.3829e+02  3.2948e+01  2.6570e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       10-      51  1.3829e+02  3.2948e+01  2.6570e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       10-      51  1.3829e+02  3.2948e+01  2.6570e-07
    1T  5.4e-06       10-      51  1.3829e+02  3.2948e+01  2.6570e-07
    1T  5.4e-06       10-      51  1.3829e+02  3.2948e+01  2.6570e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       36-      64  2.9151e+02  3.5122e+01  4.1113e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       68-      62  5.4689e+02  2.6303e+01  2.6496e-03
    1T  9.9e-06       39-      64  2.1897e+02  2.4905e+01  3.4816e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       54-      67  5.4559e+02  2.4945e+01  1.0785e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       48-      65  2.5564e+02  2.5510e+01  2.3479e-07
    1T  7.7e-06       67-      61  3.9816e+02  2.1556e+01  3.1848e-03
    1T  9.0e-06       18-      64  3.8927e+02  2.3609e+01  2.1299e-06
    1T  8.7e-06       47-      66  8.2411e+02  2.9942e+01  6.0256e-07
    1T -2.8e-06       10-      64  3.1198e+02  2.5945e+01  2.4411e-03
    1T  9.7e-06       25-      51  3.0244e+02  5.7155e+01  1.7763e-06
    1T -5.0e-07       34-      61  1.6914e+02  2.3851e+01  5.1339e-04
    1T  3.0e-06       48-      51  8.6119e+02  5.6040e+01  6.6449e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       61-      56  5.2725e+02  4.6978e+01  2.7698e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-07       62-      65  6.7133e+02  2.5465e+01  9.1957e-08
    1T -7.0e-06        5-      59  1.7486e+02  2.6207e+01  2.6848e-03
    1T  7.1e-06       17-      67  3.1769e+02  2.4888e+01  4.3881e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       32-      64  4.5635e+02  2.7544e+01  7.9556e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       63-      61  2.3685e+02  2.5801e+01  4.1935e-03
    1T -9.5e-06       19-      62  6.5001e+02  2.8748e+01  3.7301e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06        2-      69  5.0243e+02  3.3490e+01  1.2220e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       21-      62  1.8512e+02  2.8168e+01  4.9832e-04
    1T -9.7e-06       48-      60  1.7934e+02  2.7073e+01  2.7910e-03
    1T  2.6e-06       29-      66  5.1366e+02  2.6450e+01  4.3296e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.1e-06        2-      68  3.6789e+02  2.8796e+01  3.4814e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       75-      69  4.3586e+02  2.8478e+01  2.8612e-03
    1T  2.4e-06       50-      66  4.2840e+03  8.4530e+01  8.7811e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       23-      64  1.3100e+03  2.4064e+01  1.1284e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       11-      66  2.4998e+03  6.5485e+01  1.3468e-06
    1T -9.8e-08       63-      68  9.6074e+02  3.2061e+01  1.7679e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       54-      62  2.2905e+02  2.6762e+01  2.8934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-07       55-      66  3.2787e+02  2.6997e+01  4.2282e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-06       46-      68  3.0972e+02  2.6965e+01  2.3360e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       39-      66  2.1944e+02  2.8634e+01  9.2309e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       62-      66  1.4823e+03  1.9158e+01  5.4827e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06        7-      64  9.0614e+02  1.9837e+01  2.6961e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.7e-06       61-      72  1.3438e+03  2.2678e+01  3.0907e-03
    1T  2.7e-06       37-      64  3.5811e+02  1.9835e+01  3.4309e-03
    1T -7.8e-06       43-      71  1.7938e+03  1.9895e+01  2.3679e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       25-      67  1.2122e+03  2.0031e+01  1.4570e-03
    1T  6.8e-06       16-      62  1.4169e+03  2.1130e+01  1.8879e-06
    1T  3.3e-06        2-      71  5.2059e+02  2.6931e+01  1.9751e-03
    1T -1.9e-06       29-      67  1.7616e+03  1.8562e+01  1.8787e-03
    1T -6.2e-06       18-      67  4.2178e+02  2.6159e+01  2.5162e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       41-      72  5.4463e+02  2.1878e+01  2.4696e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-07       56-      71  3.2106e+02  2.5818e+01  1.2157e-03
    1T -5.8e-06       29-      69  1.8835e+03  2.3997e+01  2.4346e-07
    1T -3.5e-06       70-      66  7.1856e+02  2.9213e+01  7.9873e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-06       48-      67  2.7172e+02  2.4334e+01  2.3912e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

     2   145    23   198   102    51    25    96    45    40   144   129   151

  Columns 14 through 26

   181    87   140    99   109    41    81   109    40   144   153    80    31

  Columns 27 through 30

   154   179   126    38


Accuracy =

   98.2196


Accuracy =

   98.1989


Accuracy =

   98.2118


Accuracy =

   98.2584


Accuracy =

   98.1421


Accuracy =

   98.1834


Accuracy =

   98.1085


Accuracy =

   98.1033


Accuracy =

   98.0852


Accuracy =

   98.1834


Accuracy =9.818342e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   98.6304
   99.9467
   93.9968
   97.2252
   97.9491
   98.5485
   96.9345
   93.0330
   92.8904

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.5728




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       45-      51  3.1660e+02  2.8360e+01  1.5586e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       53-      61  1.1912e+02  2.5812e+01  6.1302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-07       28-      59  3.8000e+02  2.9087e+01  2.9644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       27-      59  6.7974e+02  2.8761e+01  7.4308e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       48-      55  3.2192e+02  3.1358e+01  4.3602e-07
    1T -7.1e-06       72-      59  1.8748e+02  3.1575e+01  1.4865e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       11-      60  6.7330e+02  2.8143e+01  1.9392e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       47-      54  5.1869e+02  2.3462e+01  2.9724e-03
    1T  7.2e-06       22-      44  3.1116e+02  4.3897e+01  3.6457e-06
    1T  9.4e-06       61-      46  1.8875e+02  6.0304e+01  3.5076e-05
    1T  4.5e-06       73-      62  3.4373e+02  3.5466e+01  1.9359e-06
    1T  4.1e-06       71-      57  1.0801e+02  2.6824e+01  3.5606e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       58-      64  1.5916e+03  6.2746e+01  2.0804e-04
    1T  3.5e-07        7-      55  1.1651e+02  3.4107e+01  3.7640e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       19-      45  4.1657e+02  5.9319e+01  4.2477e-06
    1T -8.5e-06       21-      66  1.7724e+02  3.3178e+01  3.7496e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       56-      62  3.3577e+02  2.9692e+01  1.4912e-06
    1T  7.8e-06       66-      54  4.0523e+02  4.6060e+01  6.5254e-06
    1T  7.6e-06       14-      64  1.8382e+02  3.1569e+01  3.4989e-03
    1T  6.2e-06       29-      53  1.0325e+02  2.8598e+01  2.8349e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       51-      63  2.2882e+02  2.6363e+01  1.7632e-03
    1T -6.4e-06       61-      63  2.1623e+02  3.4017e+01  6.7650e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       42-      61  1.1687e+02  3.1083e+01  3.6353e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-07       72-      59  1.9268e+02  3.5878e+01  1.3615e-07
    1T  5.6e-07       60-      61  2.7437e+02  2.9921e+01  1.5837e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       11-      63  4.4462e+02  2.4807e+01  3.0041e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       20-      67  3.9995e+02  2.9912e+01  9.5596e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       14-      66  1.7366e+02  3.0301e+01  2.3118e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-07       26-      63  3.6115e+02  2.0294e+01  3.4125e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.9e-08        2-      67  1.5883e+02  2.1624e+01  2.5365e-03
    1T -3.5e-06       38-      69  3.3368e+02  3.0942e+01  1.5604e-03
    1T -9.9e-07       64-      63  2.8845e+02  2.1472e+01  1.6196e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       45-      66  2.6296e+02  2.5120e+01  7.8900e-06
    1T -1.3e-07        2-      63  1.2183e+03  3.5877e+01  2.1307e-03
    1T  3.9e-06       58-      63  2.4241e+02  2.1486e+01  8.1910e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       22-      59  3.2863e+02  2.4103e+01  1.8304e-06
    1T  2.1e-06       25-      66  3.4895e+02  3.5679e+01  1.2716e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       67-      59  1.5221e+02  3.2494e+01  2.2611e-03
    1T  1.0e-05       53-      61  1.9559e+02  2.4453e+01  1.5068e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       60-      67  2.3499e+02  2.5931e+01  5.1158e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       61-      67  3.0470e+02  3.0579e+01  1.7569e-03
    1T  7.3e-06       11-      62  2.1806e+02  2.7049e+01  3.4457e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       36-      61  1.8425e+02  2.5370e+01  2.5504e-03
    1T  4.7e-06       27-      58  4.4624e+02  2.2477e+01  3.6966e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       71-      33  4.9866e+02  1.5209e+01  4.7773e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       23-      66  3.1115e+02  2.4103e+01  1.6690e-03
    1T  3.7e-06       34-      66  3.4079e+02  2.1194e+01  7.7178e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       27-      68  2.2256e+03  2.0437e+01  7.2503e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06       50-      69  6.3577e+02  1.8687e+01  2.2316e-03
    1T -1.2e-06       72-      67  3.4308e+02  2.1556e+01  3.7909e-03
    1T  7.7e-06       43-      67  9.8786e+02  1.8548e+01  2.0580e-03
    1T  6.0e-06       67-      68  4.1835e+02  1.7110e+01  2.0984e-03
    1T  9.8e-07       15-      59  2.9359e+02  2.0311e+01  8.7329e-04
    1T  5.1e-06        9-      69  1.0720e+03  1.8183e+01  3.9043e-03
    1T  2.4e-06       56-      68  8.2589e+02  2.5530e+01  5.7030e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06        9-      66  1.6498e+03  1.8208e+01  1.5214e-03
    1T  3.6e-06       12-      67  8.5049e+02  2.3967e+01  1.5851e-06
    1T  3.1e-07        4-      67  2.2587e+03  1.8456e+01  2.7919e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       29-      65  2.7259e+02  1.9611e+01  2.0626e-03
    1T  3.1e-06       49-      64  5.8964e+02  1.9318e+01  5.6120e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       65-      65  3.7753e+02  2.2184e+01  6.0841e-03
    1T  8.1e-06       11-      68  2.3258e+02  1.9325e+01  1.7570e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06       21-      61  3.3757e+02  2.0478e+01  3.3003e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06        7-      68  1.2607e+03  1.6629e+01  3.2897e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       15-      70  1.3855e+03  1.5099e+01  1.2597e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       37-      65  2.3931e+03  1.6072e+01  4.3547e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       22-      68  1.8005e+03  1.5422e+01  4.2783e-04
    1T -3.5e-06       54-      69  1.5360e+03  1.7644e+01  2.4933e-03
    1T -2.4e-06       25-      70  3.9583e+03  3.0942e+01  4.7322e-03
    1T -2.7e-07       33-      67  1.6883e+03  1.3729e+01  3.5818e-03
    1T -9.9e-06       39-      66  5.7326e+03  2.3900e+01  1.3403e-03
    1T -3.2e-06       15-      66  1.7322e+03  1.4087e+01  1.8254e-03
    1T  8.1e-06       40-      68  1.9038e+03  1.6885e+01  2.1689e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       12-      68  1.7636e+03  1.3792e+01  3.4392e-03
    1T -1.3e-06       42-      67  1.7946e+03  1.3011e+01  1.4503e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       65-      67  5.7283e+02  1.4428e+01  1.3761e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       32-      68  5.8358e+02  1.6792e+01  2.7177e-03
    1T  8.5e-07        2-      70  3.4949e+03  1.7825e+01  4.9514e-05
    1T -5.8e-06       42-      68  2.7450e+03  1.4858e+01  2.1347e-03
    1T  1.0e-05       46-      69  1.9125e+03  1.8452e+01  2.8594e-03
    1T -6.7e-06        6-      72  3.0062e+03  1.5537e+01  2.4749e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       31-      67  3.8713e+02  1.7504e+01  3.4119e-04
    1T -4.8e-06       53-      71  2.6137e+03  1.6513e+01  1.0500e-03
    1T -8.8e-06       65-      65  2.9813e+03  1.2915e+01  1.4013e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       20-      71  1.9946e+03  1.6423e+01  2.6040e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       14-      64  3.9538e+02  1.8281e+01  5.5479e-03
    1T  1.2e-06        2-      68  5.0677e+02  1.7470e+01  2.8027e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

     8    39    48   129   167    98   115   110   177   194    80   148    87

  Columns 14 through 26

   148   117    78   147     1   182   159    55   170   106     3    90    88

  Columns 27 through 30

   199   156    27    78


Accuracy =

   98.4682


Accuracy =

   98.5767


Accuracy =

   98.5095


Accuracy =

   98.5302


Accuracy =

   98.5508


Accuracy =

   98.4553


Accuracy =

   98.4062


Accuracy =

   98.4268


Accuracy =

   98.4475


Accuracy =

   98.4088


Accuracy =9.840876e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   99.3503
   99.9704
   94.5732
   97.0408
   98.9318
   99.7803
   94.5923
   93.0456
   92.1820

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.6074




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       17-      43  9.2422e+01  3.5434e+01  1.6162e-06
    1T -5.4e-06       16-      53  1.6108e+02  3.6467e+01  3.2353e-03
    1T  7.2e-08        1-      42  3.2133e+02  3.1336e+01  1.7668e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       54-      59  3.3410e+02  3.2150e+01  1.0067e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-07       11-      66  1.7990e+02  3.4357e+01  2.2278e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       33-      64  6.1557e+02  4.8706e+01  3.1743e-03
    1T  8.9e-06       24-      60  2.5421e+02  3.5582e+01  2.4220e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-07       28-      62  4.2673e+02  4.4502e+01  8.1707e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       41-      64  4.3279e+02  3.2902e+01  1.6327e-03
    1T  1.3e-06       70-      61  2.8971e+02  3.6102e+01  3.6269e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       52-      60  2.6754e+02  3.2647e+01  5.6161e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-06       30-      64  4.8144e+02  4.8288e+01  1.8272e-03
    1T -3.0e-06       55-      62  1.4279e+02  3.4952e+01  2.3079e-03
    1T  1.0e-05       54-      64  1.4327e+02  4.7490e+01  5.2305e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       26-      46  5.9540e+02  4.0685e+01  3.9199e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       25-      60  1.8175e+02  4.7407e+01  1.8016e-06
    1T  8.2e-07       75-      61  4.5541e+02  4.5571e+01  5.8101e-04
    1T -8.3e-06       75-      64  5.3879e+02  3.8497e+01  2.4754e-03
    1T  7.5e-06       27-      61  2.0525e+02  3.0400e+01  1.0206e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       32-      60  3.7341e+02  3.5408e+01  1.9114e-04
    1T  6.9e-06        3-      59  2.4381e+02  3.7329e+01  8.6213e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       36-      63  2.7094e+02  4.8040e+01  3.3102e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       62-      55  3.6430e+02  3.1504e+01  1.5824e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       59-      65  3.1777e+02  3.6459e+01  1.3264e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06        7-      61  1.4333e+02  3.4248e+01  2.6877e-03
    1T  4.2e-06       43-      64  2.2491e+02  3.8801e+01  1.4003e-06
    1T -6.8e-06       71-      65  2.8268e+02  3.4662e+01  3.5748e-03
    1T -8.6e-06        2-      60  4.5011e+02  3.7747e+01  2.7249e-03
    1T -1.5e-06        2-      58  2.1928e+02  3.1803e+01  3.7160e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       30-      60  1.1246e+03  1.9964e+01  3.9725e-03
    1T  2.7e-06       31-      61  2.7665e+02  2.5696e+01  7.2715e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       55-      68  3.0140e+02  2.7751e+01  1.2231e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       46-      63  2.7383e+02  2.5033e+01  3.0447e-03
    1T  1.2e-06       39-      66  5.5445e+02  2.7282e+01  2.5021e-07
    1T -3.9e-06       60-      66  2.4137e+02  2.2059e+01  2.6385e-03
    1T  4.2e-06        3-      66  5.7291e+02  3.0355e+01  4.7174e-06
    1T  7.6e-06        3-      63  3.7750e+02  2.4498e+01  1.2068e-03
    1T -1.3e-06       41-      65  1.6440e+02  2.8961e+01  1.0001e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06       11-      57  1.4487e+02  2.1858e+01  1.1631e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       61-      61  1.1141e+03  2.4935e+01  3.2874e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-07       11-      67  4.5108e+02  2.3649e+01  2.9682e-03
    1T  8.1e-06        5-      63  4.8707e+02  2.2797e+01  4.0800e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       55-      65  4.6544e+02  2.4228e+01  2.1083e-03
    1T  7.3e-06       55-      65  3.1910e+02  2.4648e+01  3.2514e-04
    1T  4.5e-06       34-      64  2.1292e+02  2.6391e+01  3.2511e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        1-      67  2.1853e+02  3.0526e+01  2.0375e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       24-      63  6.6173e+02  3.4949e+01  5.4842e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       71-      63  1.3294e+03  2.8141e+01  4.1408e-03
    1T  5.4e-06       70-      67  3.8026e+02  2.0969e+01  1.7693e-04
    1T  6.3e-06       54-      49  7.2657e+02  4.1144e+01  4.9589e-06
    1T  3.0e-06       59-      71  6.9731e+02  2.1596e+01  1.2693e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       49-      66  2.2849e+02  2.6078e+01  3.9634e-04
    1T  1.9e-06       44-      69  5.2408e+02  2.3873e+01  1.4721e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06        2-      67  9.7990e+02  2.2839e+01  3.6012e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06        2-      63  8.3443e+02  2.2342e+01  1.3400e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       47-      65  5.0541e+02  2.4055e+01  2.3390e-03
    1T  2.0e-06       45-      47  3.4082e+03  4.2833e+01  9.2132e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       34-      59  3.7553e+02  2.7046e+01  9.3311e-04
    1T -5.3e-07       16-      66  2.5660e+02  2.1120e+01  3.3030e-03
    1T -7.0e-06       72-      66  8.2574e+02  2.6410e+01  1.1494e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.6e-07       33-      69  2.5147e+02  2.4772e+01  2.9280e-03
    1T -1.1e-06       19-      68  2.9367e+02  2.5848e+01  3.8638e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-06       20-      61  2.9099e+02  2.8020e+01  2.2274e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       58-      71  3.0748e+02  2.8147e+01  9.3838e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-07       66-      57  2.0773e+03  2.9166e+01  1.5520e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       52-      63  1.8634e+03  3.1363e+01  2.3985e-03
    1T  2.1e-06       60-      60  1.2746e+03  2.7578e+01  1.7366e-03
    1T  9.6e-06       20-      63  7.3258e+02  2.5502e+01  2.9767e-03
    1T  6.5e-06       66-      64  2.6632e+02  3.4502e+01  3.1740e-03
    1T -2.3e-06       54-      48  2.2891e+03  3.9644e+01  2.6856e-03
    1T  8.8e-06       41-      54  1.1285e+03  2.6012e+01  5.6822e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       56-      67  1.2396e+03  3.7502e+01  2.3337e-04
    1T  4.1e-06       49-      66  3.6545e+02  2.6728e+01  2.2222e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       65-      65  5.6092e+02  3.3136e+01  4.2041e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       10-      55  5.2641e+02  2.9835e+01  6.3231e-04
    1T  7.7e-06       52-      66  3.0734e+02  3.0831e+01  3.0221e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   102   174    52   109    44   150    14   162    79   103    38    10   186

  Columns 14 through 26

    31   188    95    30    52    88    96    71   114    73   186   174    83

  Columns 27 through 30

    95   153   195   120


Accuracy =

   98.4712


Accuracy =

   98.4609


Accuracy =

   98.4816


Accuracy =

   98.5126


Accuracy =

   98.5745


Accuracy =

   98.5384


Accuracy =

   98.5332


Accuracy =

   98.6417


Accuracy =

   98.4093


Accuracy =

   98.4506


Accuracy =9.845057e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   99.1513
   99.9704
   91.1193
   97.3256
   97.7851
   99.9121
   97.6744
   94.8549
   91.8129

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.6229




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-07        3-      59  2.5021e+02  3.6738e+01  7.6683e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       72-      58  5.8762e+02  4.5989e+01  4.0816e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       52-      58  2.4252e+02  3.9145e+01  1.1015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       58-      53  2.0995e+02  3.2831e+01  2.5143e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       36-      51  4.8546e+02  3.3382e+01  1.1917e-03
    1T  4.0e-06       31-      53  1.5375e+02  3.2860e+01  5.3993e-07
    1T  3.0e-07       31-      60  1.2356e+02  3.5634e+01  2.2035e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-07       30-      62  3.8582e+02  3.7622e+01  1.5377e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       51-      51  7.2235e+02  3.3705e+01  1.5522e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       14-      55  1.5735e+02  3.5863e+01  1.3642e-07
    1T  7.0e-06       51-      64  6.0692e+02  4.7884e+01  1.4860e-03
    1T  4.0e-06       72-      60  2.3491e+02  3.9034e+01  5.6280e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       22-      60  5.4255e+02  4.1295e+01  8.9974e-07
    1T -9.7e-06       17-      59  3.2414e+02  3.7897e+01  2.6764e-03
    1T  7.4e-06       44-      67  1.3528e+02  3.7273e+01  8.0432e-04
    1T  6.6e-07       44-      57  1.9153e+02  3.1640e+01  1.0800e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-07       58-      59  1.0379e+03  5.7798e+01  3.1972e-03
    1T -7.4e-06       24-      59  3.6414e+02  3.5802e+01  1.2742e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       51-      60  3.9905e+02  2.4820e+01  6.6873e-04
    1T  2.4e-07       43-      58  1.1475e+03  2.8530e+01  4.1919e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       49-      62  1.7267e+02  2.3465e+01  6.1549e-06
    1T  3.4e-06       17-      48  2.7286e+03  5.7951e+01  3.3049e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       33-      62  7.9731e+02  2.4368e+01  2.1270e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       52-      64  2.1471e+02  3.3536e+01  5.8610e-06
    1T -5.2e-06       41-      60  5.3104e+02  4.5578e+01  9.7223e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-07       14-      61  8.2943e+02  2.9738e+01  5.0296e-07
    1T  9.8e-06       30-      66  3.4744e+02  2.4856e+01  9.1187e-04
    1T -2.3e-06       14-      66  1.5473e+02  2.8695e+01  1.4014e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       12-      56  1.0829e+03  3.8095e+01  4.1624e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       74-      62  4.2571e+02  2.6782e+01  3.1408e-04
    1T  3.9e-07        6-      55  7.2261e+02  2.1552e+01  2.1252e-06
    1T  9.0e-07       50-      64  4.1450e+02  3.9709e+01  3.0643e-07
    1T -6.2e-07       19-      58  1.6833e+02  3.2038e+01  2.7087e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       36-      66  4.9967e+02  3.0333e+01  3.4310e-03
    1T -2.3e-07       48-      62  2.3198e+02  2.5987e+01  2.6147e-03
    1T  6.2e-06       16-      68  2.6011e+02  2.5451e+01  1.6885e-06
    1T  9.8e-07       33-      64  2.0838e+02  2.7125e+01  1.8841e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       26-      58  4.5235e+02  3.0888e+01  1.5749e-06
    1T  1.2e-06        1-      59  3.6462e+02  2.6621e+01  4.3078e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       26-      65  4.2748e+02  3.0262e+01  8.6169e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06       30-      61  7.5795e+02  2.5427e+01  2.0506e-03
    1T  3.2e-06       52-      61  3.3449e+02  2.9684e+01  1.0321e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       65-      65  1.9476e+02  3.1062e+01  3.2667e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       74-      65  1.9517e+02  2.3572e+01  3.1944e-03
    1T -7.6e-06       35-      62  1.2936e+03  2.3943e+01  1.1361e-03
    1T  4.7e-06       30-      63  6.6848e+02  2.8696e+01  1.8472e-03
    1T -5.7e-06       45-      67  2.6940e+02  2.5439e+01  1.5992e-03
    1T  5.5e-06        6-      69  6.3148e+02  2.5419e+01  3.1875e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       24-      64  4.3417e+02  2.6417e+01  1.4389e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-07       66-      61  5.9913e+02  2.6416e+01  5.7179e-03
    1T  7.7e-06       49-      64  2.3663e+02  2.5512e+01  1.4124e-03
    1T  2.3e-06       67-      68  5.8217e+02  2.4879e+01  1.9919e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       23-      60  5.7462e+02  2.6096e+01  2.9964e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       57-      66  9.0794e+02  2.6468e+01  2.7584e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       59-      68  1.8668e+03  2.6099e+01  3.5348e-03
    1T -2.4e-06       50-      69  7.7140e+02  2.5306e+01  2.8727e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       35-      59  3.4401e+03  5.1376e+01  1.3472e-03
    1T -5.9e-08       25-      63  2.3868e+03  2.9911e+01  2.9722e-03
    1T -8.1e-06       39-      69  3.5332e+02  2.5631e+01  9.4781e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    89   112    85   110   181    11   139    96   150   153    61   181    90

  Columns 14 through 26

   146   122    94   132   109   187    13     1    79    72    64    93    59

  Columns 27 through 30

   154   199    10    37


Accuracy =

   98.2150


Accuracy =

   98.2279


Accuracy =

   98.3416


Accuracy =

   98.2821


Accuracy =

   98.3080


Accuracy =

   98.3131


Accuracy =

   98.3829


Accuracy =

   98.2124


Accuracy =

   98.3441


Accuracy =

   98.2615


Accuracy =9.826148e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   99.1832
   99.9941
   93.5297
   96.1857
   97.0516
   99.1436
   96.1889
   93.8720
   91.9393

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.3431




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       70-      31  1.0397e+02  2.3213e+01  8.4670e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       14-      61  1.0970e+02  3.7212e+01  1.4119e-06
    1T  8.2e-06        3-      59  9.1625e+01  3.2315e+01  3.1998e-06
    1T  3.9e-06       50-      63  1.4273e+02  3.6490e+01  1.4920e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       64-      62  5.0987e+02  3.4818e+01  1.7839e-03
    1T  3.9e-06       39-      62  6.0107e+02  3.5467e+01  3.3428e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       49-      61  2.6295e+02  4.0547e+01  2.6265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       32-      53  2.1357e+02  2.4085e+01  3.7241e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-07       49-      60  4.1117e+02  3.6540e+01  4.0412e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       29-      65  2.3385e+02  2.9372e+01  2.5110e-03
    1T -5.2e-06       38-      56  9.8576e+01  3.2192e+01  2.0167e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       69-      64  2.2646e+02  3.7113e+01  4.2217e-07
    1T -6.9e-06       60-      59  3.3847e+02  2.7789e+01  1.9406e-03
    1T  7.1e-06       67-      67  1.9635e+02  2.8831e+01  1.5129e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       60-      54  1.1578e+02  3.6866e+01  1.2030e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-07       20-      66  1.9784e+02  3.4359e+01  1.4862e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       57-      59  1.9125e+02  3.6298e+01  1.3052e-06
    1T -1.3e-06       15-      66  1.2840e+02  2.9630e+01  2.3136e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       21-      59  2.0160e+02  4.0432e+01  5.8981e-07
    1T  5.2e-06       46-      60  1.3044e+02  4.2096e+01  6.1975e-07
    1T  4.0e-06       28-      59  3.5570e+02  4.3105e+01  1.2614e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       72-      66  1.6731e+02  4.7026e+01  2.5740e-06
    1T -1.1e-06       75-      56  1.7632e+02  3.7261e+01  3.9773e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       65-      61  1.1219e+02  2.9913e+01  3.3534e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       14-      65  8.3589e+02  1.9808e+01  1.2316e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-07        8-      67  4.4941e+02  2.6681e+01  1.9181e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-07        8-      67  4.4941e+02  2.6681e+01  1.9181e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-07        8-      67  4.4941e+02  2.6681e+01  1.9181e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       30-      67  2.3360e+02  1.7286e+01  3.2835e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       14-      68  5.4093e+02  1.9403e+01  2.6424e-03
    1T  5.1e-07        8-      67  4.4941e+02  2.6681e+01  1.9181e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       67-      69  1.4115e+02  2.2814e+01  2.4203e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       52-      65  4.0032e+02  1.5954e+01  1.0898e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06        9-      67  2.4320e+03  2.0852e+01  2.4012e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       38-      65  2.6178e+02  2.1124e+01  5.9749e-04
    1T -8.1e-06       18-      61  6.4192e+02  2.0686e+01  2.7398e-03
    1T  2.7e-06       44-      64  1.4505e+02  2.2876e+01  2.4194e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06        8-      66  3.6655e+02  1.8935e+01  2.6745e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       73-      65  1.8806e+02  1.8464e+01  3.1960e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       12-      70  2.2320e+02  1.9076e+01  2.1263e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       73-      66  2.2332e+02  1.8747e+01  3.5184e-03
    1T  5.3e-06       19-      68  1.9121e+02  1.9412e+01  1.2087e-06
    1T  8.1e-06       69-      69  2.1854e+02  1.8912e+01  2.3120e-03
    1T  8.6e-06       21-      62  2.8537e+02  1.9821e+01  2.1901e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.0e-06       70-      65  3.4889e+02  2.3328e+01  1.1633e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06        7-      67  1.2187e+03  2.0494e+01  2.5711e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06        3-      72  6.4877e+02  2.5398e+01  8.7454e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       70-      48  2.0758e+03  2.2558e+01  8.6781e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-06       37-      68  5.4567e+02  2.4621e+01  3.0049e-03
    1T  5.1e-06        6-      70  3.6382e+02  2.4276e+01  2.5051e-03
    1T  8.8e-07       53-      59  2.0104e+03  2.4329e+01  4.2366e-03
    1T  6.5e-06        1-      60  8.9973e+02  2.3499e+01  7.3765e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       12-      66  1.4863e+03  2.1226e+01  2.5206e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-07       72-      65  3.7705e+02  2.2251e+01  2.7340e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       23-      62  2.5063e+02  2.5023e+01  2.2255e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06        6-      58  3.6460e+02  2.4276e+01  6.3100e-03
    1T  8.2e-06       44-      66  4.6512e+02  2.2287e+01  2.4163e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       56-      65  2.4929e+02  2.1660e+01  9.4372e-06
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-07        4-      64  3.5710e+02  2.6600e+01  1.3294e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03
    1T  9.0e-06        5-      65  1.0247e+03  2.1545e+01  5.5056e-03
    1T -7.2e-06       57-      67  7.1639e+02  2.2105e+01  1.0222e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [103x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       65-      67  4.1685e+02  2.6590e+01  2.5260e-03
    1T  3.8e-06       59-      65  4.5827e+02  2.3424e+01  2.8269e-03
    1T  3.5e-06       17-      65  3.0670e+02  2.2339e+01  1.3566e-06
    1T -5.3e-06        3-      66  4.9960e+02  2.5873e+01  2.2311e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-07       10-      63  6.2177e+02  2.5871e+01  1.5012e-04
    1T  5.0e-07       62-      61  2.2234e+03  5.7641e+01  4.7314e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06        2-      57  2.8859e+03  3.4311e+01  5.0385e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       63-      58  1.5745e+03  2.9290e+01  6.0866e-07
    1T  8.5e-06       41-      67  3.4143e+02  2.5845e+01  1.6462e-06
    1T -7.6e-06       69-      64  6.3133e+02  2.9563e+01  3.4819e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    24    84    33   149    33    96    42    15   100    28   107   142    90

  Columns 14 through 26

    27    95   106   168    55   185    57   168    50    31    27    70    25

  Columns 27 through 30

   189   103   155    92


Accuracy =

   98.3081


Accuracy =

   98.4321


Accuracy =

   98.2874


Accuracy =

   98.3391


Accuracy =

   98.3288


Accuracy =

   98.2332


Accuracy =

   98.3675


Accuracy =

   98.2358


Accuracy =

   98.1841


Accuracy =

   98.3159


Accuracy =9.831585e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

   98.9333
   99.9704
   92.7330
   96.1483
   97.6171
   99.7805
   96.2656
   95.0480
   89.6149

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   96.2346




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines;
{Undefined function or variable 'indian_pines'.
} 
image_gt=indian_pines_gt;
size(image)
[Warning: MATLAB has disabled some advanced graphics rendering features by
switching to software OpenGL. For more information, click <a
href="matlab:opengl('problems')">here</a>.] 

ans =

     1     1


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end
{Undefined function or variable 'image'.
} 


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);
{Error using reshape
To RESHAPE the number of elements must not change.
} 

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1

{Undefined function or variable 'flatImage'.
} 

 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
{Error using randi
First input must be a positive scalar integer value IMAX, or two integer values
[IMIN IMAX] with IMIN less than or equal to IMAX.
} 
SVM_train;

indexes =

  Columns 1 through 13

    23    46    58    99   179    55    52   113   145     9    47   129    69

  Columns 14 through 26

     2    55   144    52   134    61   168   150   192    73   163    74   146

  Columns 27 through 30

   177    13    92    22

{Error using reshape
To RESHAPE the number of elements must not change.

Error in SVM_train (line 12)
flatImage=reshape(image_gt,[rows*cols 1]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       59-      61  2.0607e+03  4.5629e+01  8.7918e-05
    1T  3.4e-06       52-      62  9.3855e+02  5.5558e+01  1.3253e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       32-      70  1.6282e+03  6.1676e+01  4.5945e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       11-      74  8.3315e+02  6.3897e+01  2.5260e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
    1T  9.8e-07       31-      61  1.6504e+03  4.6069e+01  6.2576e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
    1T  6.5e-06       20-      70  2.7842e+03  5.8537e+01  2.7337e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       11-      65  2.8168e+03  4.8425e+01  6.1293e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06        5-      66  1.6222e+03  4.2395e+01  2.4262e-04
    1T  9.7e-06       15-      69  3.1029e+03  5.4040e+01  1.1592e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-07       22-      66  1.8229e+03  4.4379e+01  9.6936e-06
    1T  5.8e-06       32-      69  1.4153e+03  6.2617e+01  8.3702e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.385749s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       41-      58  2.4791e+03  4.3701e+01  8.7196e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06        1-      62  2.2582e+03  4.7300e+01  3.9411e-05
    1T  4.8e-06       43-      65  2.0351e+03  3.9773e+01  2.3885e-05
    1T  7.9e-06       37-      68  2.8478e+03  4.2362e+01  8.6170e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   198   161   121    48   186   164   146    82   108     3   189     2   117

  Columns 14 through 26

    98   200   111   176    85    98   129    43   179    87    17    70   167

  Columns 27 through 30

    30   180    71    53

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3266


Accuracy =

   96.1650


Accuracy =

   96.2404


Accuracy =

   96.4236


Accuracy =

   96.1327


Accuracy =

   96.6067


Accuracy =

   96.3374


Accuracy =

   96.5313


Accuracy =

   96.0034


Accuracy =

   96.5097


Accuracy =9.650975e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   66.6667
   94.4359
   98.4000
   86.9159
   99.5423
   98.6405
   84.6154
   99.7685
   61.1111
   91.8275
   97.5259
   95.9335
   97.8378
   99.2126
   99.1429
   88.2353

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   91.2382




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       56-      73  2.1543e+03  4.8451e+01  6.9055e-06
    1T  9.3e-06       52-      64  9.8594e+02  4.6556e+01  1.1067e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       47-      74  1.9483e+03  7.3146e+01  9.1056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       22-      59  1.2068e+03  4.3370e+01  7.8868e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       56-      71  1.2448e+03  5.4286e+01  5.1735e-05
    1T  8.0e-06       75-      66  9.4789e+02  5.4875e+01  6.7732e-05
    1T  9.7e-06       15-      71  1.6854e+03  5.6201e+01  1.2005e-05
    1T  9.0e-07       62-      57  1.0749e+03  4.2167e+01  5.0783e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       15-      63  1.7334e+03  4.4971e+01  6.5515e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       75-      60  1.5518e+03  5.0038e+01  8.5282e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       20-      73  5.4713e+03  6.1097e+01  2.1024e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       67-      61  2.3530e+03  5.2127e+01  1.0722e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       51-      64  2.3451e+03  4.2782e+01  1.1592e-05
    1T  1.8e-06       42-      63  1.8646e+03  4.4864e+01  2.2575e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.39362s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       12-      65  1.7327e+03  4.5592e+01  1.0571e-05
    1T  3.3e-06       57-      68  3.0277e+03  4.5474e+01  9.0045e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06        7-      70  4.8653e+03  4.7116e+01  1.3671e-05
    1T -7.2e-06       41-      63  2.2391e+03  4.3165e+01  1.4707e-05
    1T  8.1e-06       41-      72  3.2601e+03  4.9649e+01  1.3187e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    42    52    12    28   167   107    35     2    57    70    88    10    11

  Columns 14 through 26

   125   159    73   149    92    35    26    72   121   124   118    62    21

  Columns 27 through 30

   167    92   149   162

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.4763


Accuracy =

   97.6704


Accuracy =

   97.5194


Accuracy =

   97.3145


Accuracy =

   97.5626


Accuracy =

   97.6381


Accuracy =

   97.7351


Accuracy =

   97.7028


Accuracy =

   97.3684


Accuracy =

   97.6596


Accuracy =9.765962e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   83.3333
   97.6798
   98.9348
   88.7850
  100.0000
   96.6767
   96.1538
  100.0000
   94.4444
   96.9353
   98.4234
   92.6966
   98.9189
   99.4751
   97.1429
   94.0476

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   95.8530




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       60-      68  1.5862e+03  5.6901e+01  1.6207e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       60-      68  1.5862e+03  5.6901e+01  1.6207e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       60-      68  1.5862e+03  5.6901e+01  1.6207e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       39-      68  1.3236e+03  5.8772e+01  1.2690e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       39-      68  1.3236e+03  5.8772e+01  1.2690e-05
    1T -4.8e-06       39-      68  1.3236e+03  5.8772e+01  1.2690e-05
    1T  3.2e-06       72-      66  1.1970e+03  5.2302e+01  1.0388e-04
    1T  6.5e-06        8-      61  9.5381e+02  4.2779e+01  3.6264e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       46-      59  7.4391e+02  4.1932e+01  1.0844e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       65-      62  2.8036e+03  5.4986e+01  1.9144e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06        8-      63  1.5383e+03  5.2435e+01  1.9797e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       15-      64  1.2431e+03  4.7759e+01  2.8260e-04
    1T -9.0e-06       29-      57  1.4088e+03  5.4704e+01  5.9863e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       46-      67  2.3949e+03  5.4181e+01  9.6433e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       18-      62  1.9169e+03  4.9469e+01  1.7501e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.367974s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       44-      65  1.7706e+03  4.2658e+01  1.4397e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       62-      73  3.8029e+03  5.0903e+01  1.2488e-05
    1T  9.1e-06       62-      73  1.8287e+03  5.7169e+01  1.1169e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       52-      67  2.0854e+03  4.2594e+01  5.1639e-04
    1T  3.9e-06       69-      70  3.0126e+03  4.8533e+01  2.2016e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    79   136   110     6    23   124   161   164    97   175    24    68    43

  Columns 14 through 26

   112   166   165    15   102    66   149    64   179    52   170     3    50

  Columns 27 through 30

    30    38   139    36

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.5588


Accuracy =

   96.5912


Accuracy =

   96.4078


Accuracy =

   96.5156


Accuracy =

   96.5372


Accuracy =

   96.5049


Accuracy =

   96.2675


Accuracy =

   96.7853


Accuracy =

   96.7745


Accuracy =

   96.9040


Accuracy =9.690399e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   92.8571
   96.6667
   95.0798
   94.3925
   93.5927
   96.5099
  100.0000
   99.5402
   66.6667
   94.5392
   99.2339
   96.4486
   89.2473
   99.3007
   96.2857
   90.4762

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   93.8023




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-07       44-      70  1.0296e+03  7.1235e+01  3.5419e-06
    1T  6.9e-06       30-      67  2.5909e+03  6.3682e+01  4.5372e-05
    1T -5.6e-06       26-      61  8.7445e+02  4.9998e+01  4.9553e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       66-      62  1.3705e+03  5.8411e+01  9.3941e-06
    1T  8.6e-07       59-      72  2.3260e+03  7.1303e+01  1.7509e-06
    1T  1.8e-06        9-      57  9.3760e+02  5.1244e+01  2.3620e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-07       73-      61  1.3518e+03  5.1764e+01  1.0639e-06
    1T  2.4e-06        7-      61  1.1942e+03  6.0572e+01  4.4091e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       73-      65  1.6997e+03  4.6854e+01  1.6403e-05
    1T  5.5e-06        1-      69  3.0500e+03  5.4842e+01  1.5820e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
    1T  7.2e-06       34-      67  1.4172e+03  4.7798e+01  3.6253e-05
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
    1T  2.6e-06       69-      70  1.6107e+03  4.6961e+01  3.9699e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       21-      65  2.1211e+03  4.8224e+01  1.9894e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.401922s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       25-      57  2.6565e+03  4.2986e+01  2.3458e-05
    1T -7.4e-06       60-      59  1.7290e+03  4.3559e+01  2.2116e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       23-      60  1.8597e+03  4.3892e+01  9.2295e-05
    1T -7.0e-06       16-      58  1.9818e+03  4.3415e+01  2.1290e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   148    35   126   180    66   137   189     1    18    78    24   180   136

  Columns 14 through 26

   134    21   144    31   146    95    66    97   149    77   123    90   187

  Columns 27 through 30

    55   182   187   168

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.7669


Accuracy =

   97.4135


Accuracy =

   97.1441


Accuracy =

   96.8208


Accuracy =

   96.9393


Accuracy =

   97.1333


Accuracy =

   97.4458


Accuracy =

   97.0363


Accuracy =

   97.3381


Accuracy =

   97.3057


Accuracy =9.730574e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   54.7619
   97.0565
   97.3369
   74.0741
   97.4886
   98.6322
   84.6154
   99.7680
  100.0000
   95.5932
   99.5052
   98.1378
   95.1872
  100.0000
   95.1567
   92.8571

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   92.5107




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       43-      65  1.9648e+03  5.3059e+01  2.7094e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       39-      42  1.0748e+03  4.3385e+01  1.5267e-05
    1T  8.8e-06       73-      57  7.8604e+02  4.9254e+01  3.3171e-04
    1T  1.6e-06       18-      67  1.1226e+03  5.3302e+01  4.4384e-06
    1T  8.8e-06       61-      69  9.5380e+02  5.6828e+01  8.8370e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       71-      70  1.8538e+03  4.5308e+01  2.2562e-06
    1T -6.1e-06       75-      59  1.1154e+03  4.9903e+01  1.1020e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       15-      68  1.9025e+03  4.6877e+01  4.0855e-04
    1T  9.0e-06       58-      69  2.3713e+03  4.7693e+01  6.7042e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.39699s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       58-      74  8.0964e+03  5.2532e+01  1.0540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06        6-      73  5.2342e+03  5.1764e+01  1.8434e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   139    34   156   148   139    45    84   150   193   198    16    75    15

  Columns 14 through 26

    45   122   127   131   192    14    48    83    22    82   153   137   143

  Columns 27 through 30

    18    77    52   143

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.2752


Accuracy =

   97.3506


Accuracy =

   97.5660


Accuracy =

   97.6629


Accuracy =

   97.1998


Accuracy =

   97.5660


Accuracy =

   97.4260


Accuracy =

   97.4690


Accuracy =

   97.6198


Accuracy =

   97.4260


Accuracy =9.742596e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   90.4762
   96.6023
   98.8064
   96.2791
   96.3303
   98.1818
   92.3077
   97.6905
   83.3333
   94.5392
   99.8203
   92.5651
   98.3957
   98.6865
   98.5673
   81.1765

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   94.6099




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       20-      46  1.2984e+02  6.6150e+01  3.1344e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       23-      44  1.5928e+03  8.6071e+01  1.2834e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06        6-      56  2.5691e+02  4.7287e+01  4.5852e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       49-      60  3.2472e+02  1.0590e+02  9.2810e-03
    1T -2.5e-06       17-      62  3.2638e+02  9.0879e+01  4.6023e-03
    1T  3.8e-06       28-      66  3.5914e+02  7.8886e+01  1.1344e-06
    1T -7.8e-06       32-      36  2.0334e+02  1.2860e+02  4.0455e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-07        3-      48  4.0196e+02  7.6764e+01  1.7311e-03
    1T  9.4e-08       52-      57  2.5257e+02  8.8594e+01  3.6500e-03
    1T  2.6e-06       11-      42  1.6945e+02  7.7755e+01  3.2172e-03
    1T  4.9e-07       35-      46  5.4069e+02  1.0620e+02  5.8222e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       21-      53  2.8929e+02  5.8630e+01  8.2666e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       64-      49  1.4160e+02  4.3612e+01  3.8834e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       44-      52  1.4282e+02  6.7595e+01  3.2619e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       59-      47  1.6791e+02  6.9406e+01  1.9189e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       68-      51  2.5778e+02  7.1626e+01  3.3732e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       70-      50  1.5701e+02  6.1044e+01  2.1812e-06
    1T  3.2e-06        3-      57  1.7155e+02  9.5847e+01  2.5903e-06
    1T  8.3e-06        1-      56  2.0931e+02  6.3879e+01  3.1486e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       56-      50  1.6726e+02  5.5185e+01  3.0010e-03
    1T -6.1e-06        5-      55  1.5498e+02  5.6449e+01  5.7799e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  1.6190e+02  6.4035e+01  4.9296e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06        8-      47  1.4212e+02  5.3803e+01  4.8857e-03
    1T  1.9e-06       24-      52  1.6343e+02  7.3349e+01  1.0852e-06
    1T  7.9e-06       56-      50  4.1009e+02  1.6422e+02  2.4679e-06
    1T  4.4e-06       49-      57  1.4935e+02  7.0247e+01  2.4145e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06        7-      48  2.1168e+02  7.6451e+01  4.6047e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       37-      59  1.6013e+02  6.1141e+01  1.5876e-03
    1T  7.0e-06       22-      49  1.6324e+02  1.0683e+02  1.5906e-06
    1T  2.6e-06       74-      52  2.1847e+02  8.6901e+01  4.3183e-03
    1T -3.9e-06       74-      45  1.5561e+02  7.7852e+01  3.0611e-03
    1T  1.8e-06       61-      50  2.0387e+02  7.3434e+01  9.2933e-08
    1T  5.4e-06       53-      54  1.6870e+02  7.4853e+01  2.5595e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       22-      50  1.4839e+02  7.0309e+01  1.1257e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       72-      55  2.8175e+02  3.8198e+01  2.8305e-03
    1T  2.3e-06       12-      55  3.9738e+02  4.1270e+01  1.7071e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06        2-      48  6.6406e+02  4.1814e+01  2.0601e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-07       69-      54  3.4562e+02  3.6957e+01  9.3941e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       25-      55  5.1114e+02  3.6971e+01  4.8447e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       63-      65  3.5733e+02  3.8216e+01  2.2141e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       55-      53  3.3863e+02  4.1621e+01  2.8740e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-07       53-      60  2.1947e+02  3.7484e+01  1.4361e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       51-      61  5.7196e+02  4.7479e+01  8.6961e-07
    1T  7.0e-06       43-      57  2.5223e+02  4.2351e+01  7.2743e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       44-      60  4.5519e+02  4.7372e+01  1.4032e-05
    1T  8.7e-06       63-      57  1.3827e+03  6.0254e+01  3.8620e-06
    1T -3.2e-06        6-      60  3.9715e+02  4.4206e+01  5.4950e-03
    1T  9.5e-06       63-      39  4.8527e+02  5.4823e+01  3.6798e-06
    1T -1.0e-05       72-      59  1.9743e+02  3.7638e+01  8.5543e-07
    1T -5.8e-06       19-      59  4.2877e+02  4.0886e+01  4.8014e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       18-      54  3.9057e+02  4.6969e+01  5.3433e-04
    1T  9.2e-07       37-      49  4.3313e+02  4.2010e+01  1.5397e-03
    1T -9.5e-07       51-      64  4.0690e+02  3.9971e+01  1.8875e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06        3-      50  8.3421e+02  5.2487e+01  2.5657e-06
    1T -4.0e-06       60-      56  3.6089e+02  4.3249e+01  1.0316e-02
    1T  7.3e-06       20-      43  2.7784e+02  3.9577e+01  3.1980e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       55-      53  2.0581e+02  4.0300e+01  2.9770e-03
    1T -7.5e-06       56-      47  2.1000e+02  3.8153e+01  3.3976e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       66-      59  2.2571e+02  4.1026e+01  7.2167e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       18-      59  2.1913e+02  4.0267e+01  1.7342e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-07        8-      52  2.4428e+02  3.6927e+01  4.0425e-07
    1T  8.3e-06       48-      49  2.6975e+02  3.9753e+01  1.0921e-05
    1T -7.7e-06       41-      60  8.5727e+02  5.0696e+01  4.2419e-03
    1T  9.7e-06       16-      48  2.4736e+02  3.8247e+01  2.0122e-03
    1T  7.2e-07       68-      46  1.5338e+03  5.2113e+01  2.0361e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-07       73-      59  9.9377e+02  4.2319e+01  2.4286e-07
    1T  3.5e-06       35-      64  2.3556e+02  3.9712e+01  1.7223e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       34-      61  2.3455e+02  4.2124e+01  1.7751e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       55-      57  2.2608e+02  4.0668e+01  4.6864e-03
    1T -3.1e-06       53-      61  2.4651e+02  3.8154e+01  2.5308e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       66-      52  2.3213e+02  4.0001e+01  3.1936e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       12-      58  3.5467e+02  4.0235e+01  6.7681e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06        8-      49  2.0574e+02  4.2377e+01  5.4723e-03
    1T  1.4e-06       64-      53  2.7441e+02  3.9572e+01  1.3364e-06
    1T  7.9e-06       20-      60  2.1482e+02  4.6396e+01  8.8541e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       36-      50  2.4319e+02  4.0283e+01  5.3889e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.317684s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06       21-      61  2.2083e+02  3.1472e+01  3.6122e-03
    1T  6.8e-06       64-      69  5.1294e+02  2.7033e+01  3.2367e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       25-      65  1.7483e+03  3.1770e+01  2.8302e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       24-      29  2.8878e+02  5.7234e+01  5.6859e-06
    1T  1.6e-06        7-      58  3.7664e+02  4.2096e+01  3.6187e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       69-      63  4.3351e+02  3.4211e+01  6.5638e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       16-      65  5.6442e+02  2.8733e+01  7.0717e-07
    1T  9.4e-06       67-      67  2.2573e+02  3.2696e+01  1.4125e-05
    1T  2.9e-07       26-      66  5.0279e+02  3.2170e+01  1.6001e-07
    1T -1.5e-06       17-      66  3.6735e+02  3.3025e+01  4.7520e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       69-      52  5.9514e+02  3.1256e+01  4.2221e-06
    1T  3.7e-06       66-      62  3.1793e+02  3.0490e+01  2.5783e-06
    1T  2.1e-09        3-      65  5.3220e+02  2.9887e+01  1.6750e-10
    1T -8.7e-06       60-      63  3.0771e+02  3.1711e+01  1.2657e-06
    1T  7.8e-06       10-      54  6.3095e+02  3.3279e+01  9.6491e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       24-      62  2.4125e+02  3.2709e+01  4.8029e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       47-      70  5.8658e+02  2.7177e+01  8.3969e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       25-      59  4.7254e+02  3.0242e+01  4.2102e-03
    1T -3.0e-06       60-      58  8.0067e+02  4.0127e+01  5.5737e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06        8-      65  5.4423e+02  2.9044e+01  4.6071e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        8-      64  8.6539e+02  3.7650e+01  4.1143e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       27-      55  3.1998e+02  3.8169e+01  6.2178e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       14-      70  2.6224e+02  3.5521e+01  3.2206e-07
    1T -8.6e-06       20-      69  2.4189e+02  3.6212e+01  9.1977e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       62-      59  3.2145e+02  3.7146e+01  2.2209e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       55-      71  2.6429e+02  3.6847e+01  6.6455e-05
    1T -6.7e-06       22-      56  9.7864e+02  3.8969e+01  4.0696e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06        7-      59  2.6974e+02  3.2382e+01  3.8352e-06
    1T  2.7e-06       62-      63  3.3328e+02  4.0894e+01  8.6386e-07
    1T  9.7e-06       56-      59  4.0115e+02  3.9142e+01  8.7248e-06
    1T -2.4e-07       20-      66  2.8629e+02  3.6773e+01  2.1441e-03
    1T -9.9e-06       62-      61  2.6149e+02  3.6592e+01  2.0904e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       38-      57  3.8425e+02  3.6547e+01  2.6504e-06
    1T  2.0e-06       39-      56  2.6189e+03  3.8172e+01  1.8441e-06
    1T  1.0e-05       71-      60  4.7205e+02  3.5843e+01  3.8111e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  2.4e-06       75-      56  3.1206e+02  4.2532e+01  5.3719e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       17-      56  5.4832e+02  3.6067e+01  5.5164e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       61-      62  3.1299e+02  3.7880e+01  2.5426e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06
    1T  7.6e-06       13-      54  4.1573e+02  3.6605e+01  7.0851e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       57-      61  4.3467e+02  3.4569e+01  5.9550e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       55-      57  4.7228e+02  3.5616e+01  3.8531e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.442459s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-07       39-      22  3.5872e+02  3.6976e+01  7.4470e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       43-      64  6.0130e+02  3.1856e+01  8.7417e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       14-      66  3.0136e+02  3.4025e+01  1.6092e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06        4-      72  1.7479e+03  4.3210e+01  3.3035e-07
    1T -7.2e-06        9-      65  6.8604e+02  2.9823e+01  3.1557e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       72-      71  7.8620e+02  2.8137e+01  6.2379e-07
    1T  7.8e-06       41-      69  1.3315e+03  3.0486e+01  7.9043e-07
    1T  9.7e-06       69-      64  7.8548e+02  3.0179e+01  1.0352e-02

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       60-      70  6.9034e+02  2.9330e+01  7.6230e-07
    1T -7.1e-06        7-      57  4.2236e+02  3.7909e+01  4.9424e-03
    1T  3.5e-06       47-      66  8.6066e+02  2.7499e+01  7.6981e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-07       71-      59  9.8966e+02  3.3140e+01  1.4174e-03
    1T  9.0e-06       13-      68  7.4020e+02  2.9337e+01  9.4027e-04
    1T -8.7e-06       29-      57  7.2349e+02  3.1979e+01  2.8022e-03
    1T -1.3e-06       57-      43  5.4021e+02  4.5052e+01  6.2344e-03
    1T  9.4e-06       37-      56  3.4256e+02  3.0616e+01  7.2907e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       63-      60  3.2089e+02  3.0100e+01  1.7154e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-06        1-      71  5.1214e+02  3.3286e+01  5.2186e-07
    1T -8.4e-06        8-      72  4.0293e+02  3.2238e+01  7.8110e-07
    1T -4.8e-06        5-      70  1.5527e+03  3.5228e+01  6.2163e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       25-      58  6.6950e+02  3.0635e+01  5.2620e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06        3-      56  9.1262e+02  3.5600e+01  4.4543e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       51-      53  4.9026e+02  3.3235e+01  3.3210e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       40-      63  3.5347e+02  2.9845e+01  1.2692e-03
    1T -3.9e-06        9-      67  3.5186e+02  3.2742e+01  4.4044e-07
    1T  3.3e-06       75-      61  1.3358e+03  3.1986e+01  4.3721e-03
    1T  6.0e-06        6-      55  4.2629e+02  3.3248e+01  3.8597e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       11-      59  9.9859e+02  3.0845e+01  6.2009e-03
    1T  8.0e-06       71-      56  3.5560e+02  3.2919e+01  4.7426e-06
    1T -7.6e-06       37-      52  4.0941e+02  3.4448e+01  1.0320e-03
    1T  1.0e-05       38-      57  4.4781e+02  3.3557e+01  2.4714e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       52-      52  4.7979e+02  3.1479e+01  3.1210e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    57    23    59   132   171   189   134   197    60     5   117   121    92

  Columns 14 through 26

   137   153    47   111    92    99    10    48   124    10    65    29    14

  Columns 27 through 30

    32    97    53    99


Accuracy =

   99.2467


Accuracy =

   99.2284


Accuracy =

   99.1916


Accuracy =

   99.2284


Accuracy =

   99.1814


Accuracy =

   99.2610


Accuracy =

   99.1998


Accuracy =

   99.3304


Accuracy =

   99.2671


Accuracy =

   99.2324


Accuracy =9.923243e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.3949
  100.0000
  100.0000
   99.7623
   99.2568
   99.9721
   99.9691
   98.0888
   99.9644
   99.8316
   99.7927
   99.9426
  100.0000
   98.7603
   98.1904
   99.6328

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.5349




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       12-      55  1.7134e+02  1.0234e+02  1.4137e-06
    1T  6.6e-06       30-      58  8.2561e+02  1.8743e+02  1.9528e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-06        9-      48  2.0774e+02  4.5930e+01  1.2211e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       12-      47  1.4621e+02  4.0242e+01  3.3827e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       67-      44  1.9175e+02  1.9570e+02  2.8505e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       27-      55  1.6726e+02  1.1032e+02  4.8010e-03
    1T  3.9e-06        3-      42  2.2877e+02  1.2023e+02  2.0865e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       29-      49  1.2727e+02  4.7000e+01  2.5023e-05
    1T -4.7e-06       21-      48  2.4011e+02  6.2234e+01  1.1890e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06        9-      53  2.0635e+02  1.0117e+02  1.2973e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       19-      48  1.4183e+02  4.2189e+01  1.9248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-07       70-      55  2.6787e+02  8.3612e+01  6.5597e-03
    1T  4.4e-06        8-      51  1.5797e+02  1.1179e+02  1.0622e-06
    1T  3.8e-06       42-      58  3.6243e+02  8.2097e+01  1.4434e-06
    1T -2.0e-06       21-      53  1.9547e+02  6.8115e+01  5.7032e-03
    1T -1.5e-06       65-      58  3.0876e+02  9.3472e+01  2.1754e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       24-      44  3.3108e+02  4.5135e+01  3.7041e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       27-      46  2.3813e+02  1.0544e+02  3.6511e-04
    1T -5.6e-06       58-      57  1.5477e+02  1.2451e+02  4.9530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       37-      62  2.0151e+02  8.5035e+01  3.2905e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       72-      51  2.1822e+02  9.1401e+01  8.7540e-04
    1T -5.8e-06       45-      51  1.5601e+02  6.8493e+01  2.0453e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       66-      45  3.0029e+02  1.0814e+02  3.2949e-07
    1T  9.7e-06       46-      52  7.0049e+02  6.5393e+01  3.2162e-06
    1T  2.9e-06       66-      48  6.3472e+02  6.4183e+01  5.2357e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06        3-      55  1.4730e+02  6.0851e+01  3.3168e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       46-      47  2.3530e+02  4.5520e+01  1.3671e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       37-      51  1.8893e+02  1.4590e+02  2.9303e-06
    1T  8.2e-06       61-      51  3.4577e+02  5.5492e+01  9.6710e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       30-      47  2.0183e+02  1.3852e+02  1.7138e-03
    1T  2.4e-06       34-      49  1.7453e+02  5.5151e+01  6.6753e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07       36-      46  1.6834e+02  5.5324e+01  2.6773e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       13-      50  1.8703e+02  1.7058e+02  5.1109e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06        4-      54  1.2054e+03  3.5975e+01  1.5571e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06        3-      60  2.3257e+02  3.7252e+01  1.8920e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       67-      61  2.2599e+02  2.9457e+01  4.3232e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06        2-      57  3.3311e+02  4.0215e+01  1.8505e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06        9-      66  1.9254e+02  3.6232e+01  4.1831e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06        4-      56  2.0159e+03  3.4952e+01  1.1866e-05
    1T  6.5e-06       14-      59  2.4451e+02  3.5394e+01  7.4772e-06
    1T  4.4e-06       72-      63  4.1535e+02  3.4984e+01  5.3557e-06
    1T  6.1e-06       49-      68  1.8071e+02  3.9077e+01  2.1275e-05
    1T  8.1e-06       68-      55  5.0392e+02  3.7489e+01  1.9653e-03
    1T  2.6e-06       45-      61  3.1999e+02  4.0323e+01  6.9236e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       26-      61  5.2046e+02  4.3314e+01  3.9382e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06        4-      63  2.2735e+02  3.9784e+01  3.3194e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-07       10-      61  3.3679e+02  3.7633e+01  3.3544e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-07       74-      62  3.6185e+02  3.0930e+01  4.7982e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       34-      52  1.5988e+03  4.2008e+01  1.8404e-06
    1T  5.1e-06       46-      45  8.9557e+02  4.9902e+01  1.5160e-05
    1T  6.9e-06       47-      67  1.9980e+02  4.0808e+01  1.6444e-03
    1T -6.5e-06       34-      58  2.0258e+02  3.9376e+01  3.2694e-03
    1T  7.6e-06       25-      62  2.1085e+02  4.2594e+01  4.8111e-03
    1T  9.0e-06       26-      63  2.0915e+02  4.1347e+01  2.8446e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       47-      60  2.7914e+02  4.8747e+01  4.4519e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-07       25-      61  2.5692e+02  4.1320e+01  4.1264e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       73-      50  2.7219e+02  3.6182e+01  2.3562e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        2-      52  2.4670e+02  3.9520e+01  1.0648e-05
    1T  9.5e-07       54-      61  2.1519e+02  4.6138e+01  2.9945e-07
    1T -4.2e-07       38-      58  2.0595e+02  4.1258e+01  3.4376e-03
    1T  7.9e-06       40-      58  8.0465e+02  4.2870e+01  3.9216e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       73-      51  2.6610e+02  3.4011e+01  3.8438e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.309912s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       59-      59  3.7931e+02  2.9932e+01  6.8688e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       14-      42  4.9799e+02  8.7485e+01  5.5271e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       47-      63  3.4330e+02  3.0548e+01  4.1629e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       42-      55  8.0274e+02  2.5342e+01  2.0163e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       19-      63  2.2199e+02  3.0891e+01  9.0758e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       52-      71  7.3280e+02  2.9510e+01  3.5560e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-08       27-      66  4.9785e+02  2.7249e+01  5.4455e-09

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       44-      59  3.2411e+02  2.9269e+01  6.7024e-03
    1T  4.4e-06       28-      64  1.4162e+03  4.0160e+01  7.7912e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       14-      64  4.0008e+02  2.9042e+01  8.3096e-03
    1T  2.3e-06       14-      66  4.1548e+02  3.2508e+01  2.3873e-07
    1T  1.6e-06       54-      68  5.2223e+02  2.9994e+01  5.5781e-07
    1T -3.2e-06       63-      57  4.2825e+02  3.1488e+01  4.4998e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       28-      67  6.1165e+02  3.3301e+01  2.0870e-07
    1T -2.5e-06       39-      70  5.2927e+02  3.0591e+01  1.2120e-03
    1T -4.8e-06       35-      62  2.5054e+02  3.1291e+01  3.9316e-05
    1T  1.6e-06       45-      55  4.5731e+02  4.4093e+01  3.8712e-07
    1T -8.1e-06        6-      71  5.9220e+02  2.8138e+01  1.0004e-06
    1T  9.0e-06       55-      61  5.8499e+02  3.6965e+01  1.0068e-05
    1T  7.7e-06        5-      54  4.6814e+02  3.6743e+01  2.0542e-06
    1T  9.4e-06       53-      57  4.2749e+02  3.6746e+01  5.4133e-06
    1T  6.0e-06       72-      67  5.2976e+02  3.0202e+01  6.2331e-03
    1T  9.7e-06       15-      61  5.6466e+02  3.0424e+01  2.0314e-05
    1T  5.7e-06       67-      68  6.4985e+02  2.9983e+01  2.3417e-06
    1T -1.8e-06       12-      54  5.5688e+02  3.0124e+01  1.2981e-03
    1T  7.6e-06       31-      57  2.4257e+02  3.6729e+01  4.7844e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       13-      62  2.8652e+02  3.7278e+01  2.9338e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06        2-      58  2.6107e+02  3.6108e+01  3.9546e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06        9-      71  2.6898e+02  3.8301e+01  3.4236e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       43-      64  8.1584e+02  3.9095e+01  7.9919e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-06       72-      67  5.9216e+02  3.5780e+01  5.3420e-03
    1T  7.3e-07       68-      55  2.8854e+02  3.5257e+01  9.4673e-07
    1T -4.2e-06       49-      56  3.1937e+02  3.6042e+01  1.4195e-03
    1T  3.9e-06       19-      57  2.7261e+02  3.8374e+01  3.2549e-06
    1T  7.2e-06       68-      58  2.5772e+02  3.7456e+01  1.0360e-03
    1T  2.0e-06       23-      62  3.1616e+02  3.9351e+01  1.1058e-06
    1T  6.6e-06       19-      58  2.7723e+02  3.4602e+01  3.9135e-03
    1T  5.7e-06       25-      44  4.6920e+03  6.3632e+01  3.5788e-06
    1T  3.7e-06       28-      62  2.6939e+02  4.1372e+01  2.1041e-06
    1T -7.6e-06       28-      69  7.1150e+02  3.8453e+01  3.1885e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.445735s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       46-      48  3.5020e+02  5.9242e+01  2.9125e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-07        4-      70  2.6356e+03  2.4668e+01  2.1624e-03
    1T  2.1e-06       35-      51  5.6796e+02  6.8281e+01  2.4051e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       58-      71  6.1194e+02  2.4932e+01  4.0016e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       71-      64  3.4776e+02  2.2755e+01  1.0092e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       16-      67  8.1330e+02  2.3373e+01  8.6538e-03
    1T -1.9e-06        7-      63  7.1467e+02  2.6868e+01  8.8287e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.1e-06       74-      67  5.7184e+02  3.7944e+01  4.0471e-03
    1T  2.4e-06       54-      69  6.0386e+02  2.5344e+01  3.0330e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       71-      59  4.4025e+03  4.3523e+01  3.4931e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       14-      68  6.9044e+02  2.3669e+01  2.4805e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       44-      60  1.6860e+03  2.2284e+01  3.7604e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       21-      70  6.5505e+02  2.4600e+01  6.6149e-07
    1T  7.3e-06       71-      58  7.4158e+02  2.6250e+01  7.5308e-03
    1T  4.1e-06       34-      63  8.0142e+02  2.5714e+01  4.1820e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-07       55-      60  5.7498e+02  2.7298e+01  8.8084e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       47-      70  3.8109e+02  2.8562e+01  1.2350e-06
    1T  7.4e-06       69-      64  1.0247e+03  2.9106e+01  4.4999e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       30-      49  1.6805e+03  3.8014e+01  2.0796e-03
    1T  6.3e-06        4-      60  5.0228e+02  2.7265e+01  4.6099e-03
    1T -5.1e-07       52-      65  3.2194e+02  2.7454e+01  1.8563e-03
    1T  7.3e-06       59-      53  4.3728e+02  3.1480e+01  4.9006e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-06       52-      68  5.1443e+02  2.9305e+01  2.5509e-03
    1T  8.8e-06       62-      62  1.0820e+03  3.1971e+01  2.2206e-05
    1T  3.8e-06       40-      67  1.7640e+03  3.0054e+01  6.6303e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       41-      56  4.5356e+02  2.7857e+01  5.1591e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06        5-      53  1.4020e+03  3.8293e+01  2.0400e-06
    1T  9.7e-06       71-      67  7.2822e+02  2.9501e+01  7.8625e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       11-      57  7.5859e+02  3.0580e+01  1.8484e-06
    1T -4.3e-06       30-      68  2.1006e+03  3.0078e+01  1.1728e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       44-      62  3.3032e+02  2.8335e+01  9.4216e-07
    1T -3.4e-06       16-      57  3.2287e+02  3.0162e+01  6.0683e-07
    1T  9.2e-07        3-      55  5.1134e+02  2.9497e+01  3.2290e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       17-      63  1.8960e+03  3.0785e+01  6.4980e-06
    1T  6.7e-06       35-      60  9.7298e+02  3.0538e+01  2.3585e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       63-      58  3.5801e+02  3.0539e+01  2.0459e-03
    1T  6.7e-06       74-      62  3.5256e+02  3.0132e+01  3.8536e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       16-      61  3.5136e+02  2.9744e+01  2.6254e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       45-      51  4.9821e+02  2.8191e+01  3.8882e-06
    1T -3.4e-06       35-      63  3.1217e+02  2.8490e+01  4.4415e-03
    1T  6.5e-06       56-      58  3.2496e+02  2.8672e+01  1.0832e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       41-      60  3.4129e+02  2.7158e+01  9.8804e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       68-      61  4.3169e+02  2.8751e+01  3.8073e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       39-      56  4.0979e+02  2.8547e+01  5.3431e-06
    1T  3.4e-06       11-      44  5.5490e+03  8.1714e+01  1.4959e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       21-      57  3.6089e+02  2.8834e+01  1.6883e-05
    1T  2.3e-06       26-      67  3.2538e+02  2.9109e+01  3.4833e-03
    1T  9.8e-06       39-      56  6.8629e+02  2.9778e+01  1.4428e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       57-      70  3.5237e+02  2.7492e+01  2.0951e-03
    1T -8.4e-06       44-      72  1.7066e+03  3.1501e+01  1.0798e-06
    1T -7.0e-06       55-      66  4.5576e+02  2.9347e+01  1.9107e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   127   107    16    61    32    56   117   113    94    32   121    78    19

  Columns 14 through 26

    85   128    91    95   128   133    86    41   149   147   166   180   168

  Columns 27 through 30

    96    17   175   191


Accuracy =

   99.5081


Accuracy =

   99.5489


Accuracy =

   99.4632


Accuracy =

   99.4591


Accuracy =

   99.5530


Accuracy =

   99.4816


Accuracy =

   99.5102


Accuracy =

   99.5163


Accuracy =

   99.4857


Accuracy =

   99.5367


Accuracy =9.953669e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.7794
   99.5846
  100.0000
   99.2891
   98.9283
   99.9442
   99.9075
   99.6960
  100.0000
   99.5950
   99.0654
   99.9428
  100.0000
   98.2456
   98.4957
  100.0000

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.5296




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       37-      21  1.6860e+02  2.5376e+02  1.8499e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       72-      57  3.3189e+02  3.9282e+01  1.0257e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-07       10-      58  2.9728e+02  8.9833e+01  3.4790e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       42-      60  1.5741e+02  7.5922e+01  2.7213e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       17-      60  3.4550e+02  7.8805e+01  1.0438e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       11-      56  3.3132e+02  8.6518e+01  1.1361e-02
    1T  9.4e-06       24-      59  1.4647e+02  7.7680e+01  8.1193e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-06       61-      45  3.3223e+02  8.5470e+01  5.6811e-03
    1T  8.1e-06       10-      61  2.3621e+02  7.7226e+01  7.7170e-04
    1T -7.7e-06       47-      49  2.2782e+02  5.4582e+01  4.3479e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       16-      54  1.3968e+02  8.0965e+01  2.1009e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06        4-      61  7.1679e+02  7.0210e+01  2.1707e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       14-      55  1.6194e+02  4.8081e+01  3.5139e-03
    1T  4.7e-06        2-      53  1.5700e+02  4.4572e+01  1.3053e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       48-      54  1.5323e+02  5.2644e+01  1.2634e-04
    1T -6.8e-06        1-      59  5.3275e+02  7.1710e+01  5.2633e-03
    1T  2.2e-06       37-      53  1.3920e+02  5.8030e+01  1.1608e-03
    1T  9.7e-06       16-      52  3.5626e+02  6.9873e+01  5.0142e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06        3-      55  1.3749e+02  5.7895e+01  1.5814e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       28-      59  4.5212e+02  7.9957e+01  5.8741e-04
    1T -2.8e-06       55-      61  3.6834e+02  1.0013e+02  8.1823e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       48-      52  1.7591e+02  7.2411e+01  2.9609e-03
    1T -6.8e-06       57-      52  1.5258e+02  1.0738e+02  2.4913e-03
    1T -1.5e-06       45-      39  1.9077e+02  6.5411e+01  1.0710e-03
    1T  7.4e-06       72-      55  1.5693e+02  6.0102e+01  4.9156e-03
    1T  6.6e-06       11-      51  2.6516e+02  6.3332e+01  6.7296e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-07       28-      51  1.6972e+02  5.4185e+01  4.3329e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-07       11-      59  4.2913e+02  9.9663e+01  1.9145e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       10-      58  2.8705e+02  4.8816e+01  4.3148e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       47-      52  2.3720e+02  7.4734e+01  1.7391e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       73-      52  1.4168e+02  5.0277e+01  4.9085e-07
    1T  8.9e-06       17-      61  1.3942e+02  6.1271e+01  2.3487e-06
    1T -4.3e-06       68-      54  1.3554e+02  9.6871e+01  5.8611e-05
    1T -8.2e-06       26-      51  1.7284e+02  5.4850e+01  3.0304e-03
    1T -8.6e-06       16-      62  9.7050e+02  8.2152e+01  6.7717e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06        8-      41  1.4626e+02  7.0299e+01  4.7700e-03
    1T -3.6e-06       61-      56  1.6042e+02  5.6393e+01  2.4479e-03
    1T  3.7e-06       17-      54  5.9936e+02  1.1804e+02  6.7500e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       38-      68  4.5128e+02  3.1983e+01  4.0261e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-07       75-      55  3.9033e+02  3.9183e+01  3.5643e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       41-      62  3.4951e+02  3.6779e+01  6.3228e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       39-      53  2.2213e+02  3.6354e+01  5.1376e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       71-      59  1.1202e+03  5.3570e+01  5.4646e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       10-      49  4.1395e+02  6.1401e+01  1.5620e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       60-      55  3.7900e+02  4.0331e+01  6.0727e-03
    1T -6.3e-06       43-      62  1.8696e+02  4.6184e+01  1.5326e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       58-      60  3.8689e+02  3.7780e+01  5.9661e-03
    1T -4.6e-06       64-      60  2.8588e+02  4.7818e+01  3.1279e-03
    1T -9.2e-06       27-      65  5.1447e+02  3.4695e+01  6.2558e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       71-      55  1.9454e+02  3.9731e+01  2.1057e-03
    1T  4.8e-06        6-      68  5.4164e+02  5.2940e+01  2.5586e-03
    1T  4.7e-07       44-      64  1.9420e+02  4.1127e+01  1.9194e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       55-      56  2.6213e+02  4.3454e+01  9.1249e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       23-      56  2.4329e+02  3.7055e+01  3.6208e-03
    1T  3.4e-06       30-      65  5.7021e+02  3.5032e+01  1.6968e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06        3-      59  2.0794e+02  4.3620e+01  2.0609e-04
    1T  4.1e-06       62-      46  3.6451e+02  4.2825e+01  5.4921e-03
    1T  8.1e-06        7-      55  3.1965e+02  4.3576e+01  6.5304e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       64-      65  2.3458e+02  4.2121e+01  5.4075e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       65-      58  4.9854e+02  4.3689e+01  5.7920e-06
    1T -5.7e-07       31-      51  2.4503e+02  4.3152e+01  5.1113e-08
    1T  3.1e-06       56-      58  4.2595e+02  4.2188e+01  8.2876e-03
    1T  7.4e-06       58-      64  2.2045e+02  3.7038e+01  4.5582e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       75-      65  1.9722e+02  4.9239e+01  1.9352e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       40-      68  3.6453e+02  4.1995e+01  4.5826e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       44-      59  5.0318e+02  6.3845e+01  2.2702e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       47-      51  1.9868e+02  3.8672e+01  2.1334e-03
    1T -8.8e-06       52-      65  2.7069e+02  4.3016e+01  4.0679e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       47-      52  2.0703e+02  4.4282e+01  3.5315e-03
    1T  7.7e-06       31-      60  2.2554e+02  4.4725e+01  2.1352e-03
    1T -3.6e-06        3-      48  2.6807e+02  4.2702e+01  1.5339e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       60-      67  7.2077e+02  4.1749e+01  8.3081e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       39-      51  2.3802e+02  4.3838e+01  5.4156e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       57-      61  2.1590e+02  4.5529e+01  1.0653e-03
    1T  1.9e-06        8-      58  1.0372e+03  4.2118e+01  3.1271e-03
    1T  8.7e-06       74-      65  2.1894e+02  3.8978e+01  6.3894e-06
    1T  1.8e-06       48-      57  2.1450e+02  4.7640e+01  9.2265e-07
    1T  3.0e-06       59-      54  2.3500e+02  4.4071e+01  5.8119e-04
    1T  9.4e-06       22-      54  3.0490e+02  4.2500e+01  3.4037e-03
    1T  6.3e-06       40-      59  3.2446e+02  4.2829e+01  6.0044e-03
    1T  4.3e-06        3-      60  7.6249e+02  4.9143e+01  1.8245e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.301774s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.0e-06       12-      20  2.9386e+02  4.0057e+01  7.3008e-03
    1T  9.6e-06       30-      33  5.5540e+02  5.4341e+01  7.9240e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       60-      50  2.1223e+03  5.1924e+01  4.7670e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       70-      52  2.7200e+02  3.1053e+01  3.5900e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       37-      59  8.2612e+02  3.4848e+01  8.3881e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.6e-06       19-      39  4.8821e+02  4.9335e+01  4.6044e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       48-      65  7.2980e+02  3.4654e+01  2.8845e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-07        2-      53  2.4932e+02  3.5856e+01  3.0466e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       75-      58  6.3662e+02  3.4734e+01  1.2456e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       45-      59  7.2379e+02  3.9672e+01  1.0469e-02

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       49-      56  6.9774e+02  3.3724e+01  1.9155e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       61-      50  4.9252e+02  4.6951e+01  1.1040e-06
    1T -4.3e-06       57-      66  6.5031e+02  3.2833e+01  2.8122e-03
    1T -1.7e-06       27-      61  5.8096e+02  3.3499e+01  2.0712e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       32-      68  5.3354e+02  3.2958e+01  4.2571e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       26-      43  3.6996e+02  5.1180e+01  2.3686e-06
    1T  4.3e-06       72-      62  2.8063e+02  3.5524e+01  2.8740e-03
    1T  9.1e-06       59-      50  2.5485e+03  4.5762e+01  4.7170e-06
    1T -2.0e-06       61-      67  6.9677e+02  4.3740e+01  7.7635e-03
    1T  4.7e-06        5-      63  2.7028e+02  3.9128e+01  1.2905e-06
    1T  2.9e-06       11-      52  4.2509e+02  4.7395e+01  1.2055e-06
    1T -1.7e-06       15-      67  6.6129e+02  4.1352e+01  1.0787e-04
    1T -8.6e-07       37-      45  6.6209e+02  4.6925e+01  5.5417e-03
    1T  6.6e-06       44-      40  5.8067e+02  4.7423e+01  5.0721e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-07       12-      50  2.7551e+02  3.5632e+01  4.8198e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       72-      57  2.4465e+02  3.6715e+01  1.9860e-03
    1T  6.6e-06       53-      58  2.9914e+02  4.1336e+01  1.9863e-05
    1T  8.7e-06       47-      61  2.9243e+02  3.9699e+01  3.0630e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       72-      62  2.5248e+02  3.7595e+01  4.4168e-03
    1T  9.7e-06       38-      64  2.9303e+02  4.0102e+01  5.4858e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06        4-      63  2.6018e+02  3.6255e+01  1.9583e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       26-      57  2.7504e+02  3.7207e+01  2.3664e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-07        7-      65  1.2937e+03  4.2327e+01  7.5325e-03
    1T  3.8e-06       55-      66  2.4908e+02  3.8061e+01  4.7118e-03
    1T  8.3e-06       29-      62  2.8050e+02  3.6437e+01  5.5341e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.5e-06       38-      63  2.5216e+02  3.6993e+01  3.8057e-07
    1T  5.1e-06       25-      56  3.0802e+02  4.0276e+01  5.9473e-03
    1T -1.0e-05       27-      59  3.8188e+02  4.0302e+01  3.5346e-04
    1T  9.8e-06       27-      68  2.3122e+02  3.8264e+01  9.2654e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       35-      54  4.5483e+02  3.5472e+01  1.8792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       21-      52  3.5172e+02  3.5700e+01  4.8063e-03
    1T  6.5e-06       60-      64  3.5308e+02  4.8269e+01  4.2382e-04
    1T  1.8e-06        7-      62  3.7051e+02  3.8421e+01  2.0413e-07
    1T -8.0e-06       57-      49  3.3710e+02  3.8331e+01  3.3879e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       41-      56  2.5634e+02  3.8527e+01  1.1314e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.445638s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       42-      68  1.7381e+03  4.2496e+01  2.6009e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06        6-      71  1.2689e+03  2.7626e+01  5.6689e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       31-      70  1.2370e+03  2.8030e+01  1.0440e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       36-      52  6.1123e+02  5.0349e+01  3.4237e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       68-      50  5.7062e+02  4.5887e+01  1.8585e-06
    1T  6.2e-06       60-      60  6.7915e+02  3.0129e+01  4.6607e-07
    1T  7.4e-06       58-      71  7.5489e+02  2.9423e+01  5.5238e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-06        1-      65  4.8714e+02  2.7634e+01  5.4509e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        3-      71  2.1547e+03  4.3594e+01  2.0071e-07
    1T  1.0e-07       39-      70  7.1327e+02  2.8573e+01  4.5417e-03
    1T  8.4e-06       63-      69  1.0646e+03  4.2445e+01  5.1749e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       22-      59  8.9940e+02  2.9012e+01  1.3664e-03
    1T  4.5e-06       65-      64  1.2079e+03  3.0283e+01  9.4719e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       58-      72  8.5283e+02  2.8969e+01  3.8812e-03
    1T  2.5e-06       63-      72  7.3177e+02  2.8282e+01  1.2180e-06
    1T -2.6e-06       30-      71  1.5638e+03  4.1574e+01  8.4449e-03
    1T -1.7e-06       51-      57  5.1869e+02  3.0581e+01  8.2662e-03
    1T -9.3e-06       44-      68  4.3523e+02  3.3878e+01  4.0887e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       26-      60  6.1596e+02  3.5713e+01  6.7550e-06
    1T  8.7e-06       59-      61  5.0889e+02  3.3130e+01  3.5116e-06
    1T  4.5e-06       65-      63  5.7720e+02  2.8494e+01  1.2277e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       68-      70  3.5839e+02  3.1543e+01  1.9449e-07
    1T  4.1e-06       35-      65  4.0377e+02  3.3010e+01  4.7209e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       50-      66  3.5739e+02  3.4733e+01  5.0591e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       32-      64  3.4467e+02  3.3831e+01  1.5828e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       26-      66  3.1905e+02  3.0010e+01  5.5226e-06
    1T  5.5e-06       50-      66  3.1587e+02  3.3222e+01  4.6507e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       37-      53  4.4088e+02  3.2763e+01  1.0758e-03
    1T  6.6e-06       15-      55  5.0630e+02  3.1853e+01  4.9519e-06
    1T  3.5e-06       47-      59  8.4054e+02  2.7143e+01  3.4761e-05
    1T  3.1e-06       48-      65  4.8515e+02  3.2389e+01  2.5760e-06
    1T  1.4e-06       27-      64  3.9636e+02  3.3728e+01  4.7820e-03
    1T -3.0e-07       35-      57  3.1390e+02  3.3611e+01  2.2427e-03
Parallel pool using the 'local' profile is shutting down.
Caught unexpected fl::except::IInternalException
SVM_train;

indexes =

  Columns 1 through 13

    32    20   116     7    98     4    35   155    65    67   200     8   189

  Columns 14 through 26

   120    66    58    32    18   149    65    94   198   161   196   140    26

  Columns 27 through 30

    82    32    17    97

{Index in position 3 exceeds array bounds (must not exceed 225).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-07       22-      34  1.7940e+02  3.0641e+02  1.0696e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       51-      57  2.4023e+02  6.1074e+01  6.5883e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.3e-06       23-      51  2.5249e+02  6.1961e+01  1.0679e-02

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       25-      55  1.5136e+02  5.1785e+01  4.1080e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06        9-      54  2.4626e+02  5.5234e+01  1.1988e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.0e-06       33-      47  1.6752e+02  4.5645e+01  4.7800e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06        7-      56  1.5510e+02  6.3764e+01  3.9319e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       47-      46  3.7838e+02  6.4301e+01  5.3344e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       55-      52  4.7539e+02  5.9589e+01  4.3331e-03
    1T  8.3e-06       44-      62  1.3726e+02  6.2970e+01  2.6361e-06
    1T -4.1e-06       14-      56  3.9941e+02  7.6843e+01  4.3156e-03
    1T  6.1e-06       22-      56  3.6313e+02  5.5438e+01  3.4324e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       36-      52  3.1275e+02  6.8203e+01  1.2553e-06
    1T  9.2e-07       13-      61  3.3745e+02  4.2235e+01  3.6780e-03
    1T -2.6e-06       21-      62  1.3665e+02  6.4396e+01  2.7725e-03
    1T  6.0e-06        7-      55  1.4399e+02  5.3985e+01  1.3808e-03
    1T  1.7e-06       29-      41  2.7384e+02  5.1833e+01  8.6366e-07
    1T  2.1e-06       26-      40  1.8667e+02  5.4867e+01  3.6721e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       62-      64  3.6479e+02  5.7560e+01  3.2101e-03
    1T  3.9e-06       29-      51  2.4882e+02  7.6666e+01  1.9848e-07
    1T  5.2e-06       60-      53  1.8719e+02  8.9120e+01  3.9514e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       53-      46  1.5171e+02  5.9448e+01  3.3004e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06        4-      53  1.6343e+02  6.6985e+01  5.2469e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       65-      54  1.3536e+02  8.5336e+01  8.5905e-06
    1T  5.3e-06       29-      64  1.5358e+02  5.4485e+01  1.6874e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       69-      51  1.4771e+02  5.8319e+01  4.1349e-03
    1T -3.2e-06       28-      62  1.3720e+02  6.7958e+01  2.4173e-03
    1T  9.3e-06       22-      57  1.5741e+02  5.3154e+01  3.5977e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-07       72-      59  2.7502e+02  6.7932e+01  3.1024e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       33-      59  1.9621e+02  5.5745e+01  5.4002e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       36-      61  1.2081e+02  5.9348e+01  9.8352e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       18-      56  1.6315e+02  8.0893e+01  3.2432e-06
    1T -2.7e-07       54-      52  2.1770e+02  5.4227e+01  1.1010e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       17-      53  1.4843e+02  7.2407e+01  3.4988e-03
    1T  1.6e-06       69-      49  3.0249e+02  8.7952e+01  8.7068e-04
    1T -9.7e-06       45-      51  1.9973e+02  5.7821e+01  4.0474e-03
    1T  2.5e-06       49-      58  4.5109e+02  5.3595e+01  8.1429e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       73-      69  4.5296e+02  2.9239e+01  7.5696e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06        7-      56  2.4971e+02  3.1305e+01  5.2170e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       69-      65  5.8346e+02  3.0933e+01  2.3564e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       32-      60  2.9707e+02  3.7344e+01  3.9059e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       55-      51  2.5204e+02  3.3733e+01  2.2417e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       27-      61  2.3693e+02  3.3510e+01  1.3451e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       71-      62  1.1913e+03  3.2543e+01  4.3892e-06
    1T  7.7e-07       24-      54  2.7234e+02  3.1051e+01  1.7226e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       40-      52  4.1858e+02  3.4347e+01  1.8454e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       15-      54  2.1388e+02  2.9671e+01  5.1492e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       48-      66  3.9823e+02  3.1521e+01  7.6752e-04
    1T  4.8e-06       47-      54  2.1491e+03  3.6803e+01  2.1037e-05
    1T  1.0e-06       66-      68  5.2826e+02  3.4718e+01  6.5548e-07
    1T -6.9e-06       28-      58  2.6104e+02  2.9560e+01  6.5853e-03
    1T  2.8e-06       55-      55  2.5775e+02  3.4338e+01  3.9851e-03
    1T  8.0e-06        4-      61  2.4467e+02  3.1147e+01  5.1080e-03
    1T -3.8e-06        9-      68  4.6816e+02  3.1349e+01  3.6187e-03
    1T  2.1e-06       27-      45  2.7155e+02  3.6493e+01  2.1057e-03
    1T -3.1e-08       45-      58  5.8127e+02  3.5229e+01  1.8906e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-07       42-      58  4.5498e+02  3.4901e+01  2.9634e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       66-      59  3.8704e+02  3.6909e+01  4.0248e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       61-      57  2.8812e+02  3.5656e+01  1.0224e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       74-      60  2.3972e+02  3.5453e+01  6.3424e-03
    1T  3.9e-07       63-      40  4.2959e+02  4.1173e+01  8.2413e-04
    1T  7.7e-06       57-      49  4.1790e+02  3.9503e+01  1.3997e-05
    1T  4.1e-06       58-      44  3.4859e+02  4.6801e+01  3.4265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       46-      62  2.8025e+02  4.0781e+01  1.0205e-05
    1T  2.4e-06       11-      65  5.8074e+02  4.5531e+01  5.1617e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       70-      60  2.4407e+02  3.8531e+01  5.5875e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       22-      69  2.0404e+02  3.6245e+01  1.5362e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-07       74-      55  2.0484e+02  3.3292e+01  1.6540e-07
    1T  4.0e-06       27-      55  2.0189e+02  3.3729e+01  4.1837e-06
    1T -5.7e-06       39-      64  6.0487e+02  3.6392e+01  2.1934e-03
    1T -7.1e-06       13-      64  2.3815e+02  3.4348e+01  7.7382e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.7e-06       10-      62  2.6037e+02  3.1706e+01  5.4591e-03
    1T  9.4e-06       64-      61  1.9942e+02  3.4013e+01  6.6010e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       41-      69  2.2373e+02  3.4522e+01  5.3250e-04
    1T -5.0e-06       26-      56  3.2424e+02  3.0324e+01  4.3416e-03
    1T  9.1e-06       64-      57  2.4776e+02  3.4677e+01  3.1206e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       52-      67  5.6888e+02  3.2591e+01  2.3782e-06
    1T  3.6e-06       34-      52  2.0844e+02  3.1400e+01  5.5330e-04
    1T  5.0e-06       62-      53  4.5374e+02  3.2537e+01  7.4455e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       43-      56  2.3330e+02  3.4849e+01  4.4937e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06        3-      59  4.5906e+02  3.6008e+01  2.6651e-06
    1T  7.9e-06        3-      51  2.2625e+02  3.1499e+01  4.4983e-03
    1T  1.5e-06       50-      66  2.2571e+02  3.5939e+01  4.8783e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-07       15-      53  4.5929e+02  3.1719e+01  8.5837e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05       32-      63  3.9167e+02  3.5133e+01  3.8998e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       70-      66  6.2574e+02  3.1086e+01  2.7980e-03
    1T  9.7e-06       58-      65  2.1488e+02  3.4607e+01  4.6257e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       46-      64  1.1188e+03  4.6689e+01  7.0960e-07
    1T -3.3e-06       64-      62  5.4778e+02  3.4130e+01  5.6594e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       57-      64  6.7700e+02  3.1233e+01  1.9132e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       19-      67  5.6355e+02  3.4108e+01  2.6817e-03
    1T  6.5e-06       71-      57  6.2559e+02  3.0299e+01  5.1124e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-07       73-      55  5.2916e+02  3.5131e+01  6.0074e-03
    1T  7.1e-06       27-      69  6.0997e+02  3.1597e+01  3.8092e-07
    1T -8.6e-06       18-      22  2.5655e+03  3.2885e+01  2.5688e-06
    1T -6.1e-06       60-      51  2.6162e+02  2.9799e+01  4.3179e-03
    1T  8.6e-06       18-      62  5.8896e+02  3.5634e+01  5.3946e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       75-      58  4.4231e+02  3.5479e+01  4.7251e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       41-      71  6.7905e+02  3.3570e+01  2.5080e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       19-      66  6.7249e+02  3.3513e+01  4.6844e-03
    1T -2.0e-06       25-      61  2.8245e+02  3.7641e+01  4.7686e-03
    1T -3.7e-06       59-      55  8.8799e+02  4.3285e+01  2.7652e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       10-      55  3.9694e+02  3.2553e+01  7.4645e-03
    1T -2.9e-06        8-      67  2.3863e+02  3.8888e+01  1.8561e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       62-      49  2.6716e+02  3.6936e+01  1.3158e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       67-      62  8.0088e+02  4.2340e+01  1.6859e-06
    1T -3.0e-06       37-      58  2.8444e+02  3.6620e+01  5.4968e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       19-      49  3.0337e+02  3.7403e+01  5.5115e-03
    1T  9.7e-07       14-      62  2.6640e+02  3.6838e+01  3.9565e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       25-      67  2.6574e+02  3.9486e+01  1.7095e-03
    1T  2.8e-06       40-      65  3.1719e+02  4.2400e+01  2.5286e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       52-      70  2.3118e+02  3.9051e+01  5.9690e-07
    1T  6.4e-06       29-      60  2.8093e+02  3.9124e+01  1.0831e-03
    1T  2.0e-07       20-      59  2.5952e+02  3.9633e+01  5.1689e-03
    1T -4.0e-06       53-      69  2.5609e+02  3.8516e+01  4.8655e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       62-      59  3.3040e+02  3.5899e+01  1.4253e-06
    1T  3.3e-06        3-      68  2.6262e+02  3.9519e+01  2.2543e-03
    1T -7.2e-06        8-      66  2.7186e+02  3.6721e+01  2.0426e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       61-      61  3.0518e+02  3.8081e+01  7.2693e-06
    1T  5.2e-07       62-      69  3.1371e+02  3.8900e+01  3.1476e-03
    1T  9.2e-06       68-      52  3.3530e+02  3.3425e+01  3.2507e-03
    1T  8.2e-06       59-      58  3.3150e+02  3.3960e+01  1.0790e-03
    1T  5.9e-06       18-      58  9.9676e+02  3.8108e+01  2.9855e-06
    1T  8.6e-06       25-      61  2.8628e+02  3.7622e+01  4.5365e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.408929s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       11-      69  9.2109e+02  2.9926e+01  1.2217e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       63-      64  2.4129e+03  3.3998e+01  4.4244e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       41-      61  3.2356e+02  3.4402e+01  1.1909e-06
    1T  1.4e-08       63-      65  1.0673e+03  3.0986e+01  1.1725e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       28-      56  4.4235e+02  3.1130e+01  5.6477e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-08       63-      49  7.2510e+02  3.1946e+01  1.9802e-08
    1T -4.3e-07        4-      60  4.7761e+02  3.2431e+01  8.1242e-03
    1T  2.8e-06       60-      64  1.8307e+03  3.1455e+01  8.5860e-03
    1T  4.0e-06       10-      71  7.6638e+02  2.9020e+01  1.5164e-03
    1T  1.1e-06       33-      64  4.0203e+02  3.2528e+01  7.3531e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06        2-      73  7.7188e+02  2.9338e+01  1.3200e-07
    1T  7.0e-06       62-      61  6.6235e+02  3.1109e+01  6.8343e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       11-      55  5.1477e+02  3.3683e+01  1.0992e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       45-      64  1.5451e+03  3.5738e+01  3.5213e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       53-      53  5.1497e+02  3.5738e+01  2.5732e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       24-      63  4.1525e+02  3.4073e+01  3.8668e-03
    1T  8.4e-06       60-      64  4.2576e+02  3.3777e+01  4.4658e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       64-      63  3.0385e+02  3.5088e+01  4.0806e-07
    1T  8.5e-06       69-      65  3.6401e+02  3.5134e+01  4.2034e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       55-      67  3.3465e+02  3.3570e+01  2.0551e-03
    1T  6.5e-06        5-      64  3.5360e+02  3.4851e+01  3.4745e-03
    1T -3.3e-06       30-      61  4.4157e+02  3.4893e+01  5.0498e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       54-      62  3.0778e+02  3.4426e+01  4.4701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       24-      60  3.8322e+02  3.5305e+01  3.6345e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       59-      59  3.7722e+02  3.7577e+01  3.1229e-03
    1T  3.1e-06       54-      57  3.5101e+02  3.6193e+01  1.7848e-06
    1T -6.3e-06       11-      56  4.1744e+02  3.0710e+01  2.0202e-03
    1T -6.0e-06       54-      48  3.7702e+02  3.0668e+01  4.0919e-03
    1T -2.8e-06       33-      61  3.1456e+02  3.5556e+01  2.3108e-07
    1T  6.9e-06       41-      57  3.9680e+02  3.6114e+01  4.4698e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       32-      56  4.0338e+02  3.5031e+01  5.5633e-06
    1T  5.0e-06       42-      46  4.2527e+02  3.0808e+01  2.0334e-03
    1T  7.1e-06       23-      61  3.8775e+02  3.7657e+01  4.9964e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    96    44   121   179   150    30   134   147   107    39    34    93   180

  Columns 14 through 26

     7    72   147    47   128   179   167    69   143    51    12    83   187

  Columns 27 through 30

    66    14    54    63


Accuracy =

   99.6283


Accuracy =

   99.6079


Accuracy =

   99.6222


Accuracy =

   99.6344


Accuracy =

   99.6303


Accuracy =

   99.5731


Accuracy =

   99.6201


Accuracy =

   99.6140


Accuracy =

   99.6630


Accuracy =

   99.5956


Accuracy =9.959561e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.6154
   99.8814
   99.8880
   98.7261
   98.5549
  100.0000
   99.8146
   99.5684
  100.0000
   99.6632
   99.5859
  100.0000
   99.7593
   99.2754
   99.0715
  100.0000

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.5878




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       14-      46  1.3505e+02  4.3340e+01  4.2291e-03
    1T  2.3e-06       14-      46  1.3505e+02  4.3340e+01  4.2291e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       14-      46  1.3505e+02  4.3340e+01  4.2291e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       74-      63  4.2700e+02  4.8780e+01  7.1297e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       46-      51  1.7087e+02  4.8401e+01  3.7311e-03
    1T  9.0e-06       21-      56  2.7950e+02  6.5400e+01  5.2536e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       45-      60  7.5972e+02  7.5301e+01  1.4013e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       74-      65  3.0081e+02  5.8816e+01  5.6464e-07
    1T -3.5e-06       16-      48  1.5126e+02  4.5544e+01  1.2579e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        3-      58  1.7095e+02  5.0544e+01  1.5585e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       36-      55  6.9688e+02  6.5385e+01  5.2807e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       75-      52  2.0072e+02  5.0316e+01  5.3520e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       54-      63  7.2580e+02  8.0048e+01  1.1939e-06
    1T  8.9e-06       34-      60  3.3319e+02  7.9180e+01  2.6287e-03
    1T -7.8e-06       73-      57  2.4474e+02  4.7490e+01  2.8447e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       25-      61  1.3875e+02  5.6287e+01  4.4766e-03
    1T  7.9e-06       43-      60  7.7815e+02  5.5387e+01  1.7663e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       68-      57  6.2767e+02  4.8894e+01  6.2221e-07
    1T -3.0e-06       33-      51  1.3272e+02  4.9022e+01  3.5940e-03
    1T  7.7e-06       56-      64  1.4548e+02  5.5299e+01  1.6933e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06        7-      60  2.4289e+02  5.1004e+01  5.0855e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       71-      55  9.7427e+02  5.5098e+01  8.0756e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       24-      51  1.4475e+02  5.4762e+01  2.7252e-04
    1T -2.4e-06       49-      47  3.3394e+02  6.4198e+01  4.4520e-03
    1T -3.1e-06       57-      56  4.0910e+02  7.9178e+01  7.2664e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       25-      47  8.1161e+02  6.2006e+01  3.5514e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-07       36-      52  6.3391e+02  6.4381e+01  4.7862e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       24-      50  1.6036e+02  5.0470e+01  3.3233e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       54-      61  1.4967e+02  5.4872e+01  3.8189e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-07       18-      58  1.7619e+02  5.9207e+01  2.8946e-04
    1T  2.1e-08        4-      49  1.9620e+02  5.3280e+01  1.4363e-09

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       39-      46  1.3747e+02  5.6439e+01  5.0732e-03
    1T -6.9e-07       53-      54  1.5208e+02  5.9753e+01  5.7174e-03
    1T -1.7e-06       43-      52  1.5568e+02  6.3179e+01  5.0433e-03
    1T  9.2e-06        8-      55  1.9130e+02  7.5701e+01  6.8428e-06
    1T -5.7e-06       49-      57  1.8435e+02  5.0095e+01  3.0334e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       13-      46  1.7010e+02  6.3259e+01  9.1827e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       19-      50  1.4217e+02  5.5091e+01  3.3739e-03
    1T -7.0e-06       50-      57  2.1159e+02  5.7468e+01  3.2203e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06        9-      58  1.6254e+02  5.6041e+01  2.7363e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       11-      48  2.8099e+02  4.4353e+01  8.0086e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       11-      48  2.8099e+02  4.4353e+01  8.0086e-04
    1T -9.9e-06       11-      48  2.8099e+02  4.4353e+01  8.0086e-04
    1T -9.9e-06       11-      48  2.8099e+02  4.4353e+01  8.0086e-04
    1T -8.5e-07       24-      51  1.9114e+02  4.0448e+01  2.5083e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       11-      48  2.8099e+02  4.4353e+01  8.0086e-04
    1T  8.2e-07       55-      62  1.5888e+02  4.6117e+01  2.3323e-03
    1T  3.9e-07        9-      48  1.4693e+02  6.1960e+01  3.3004e-03
    1T -9.3e-06       39-      46  1.6369e+02  4.3635e+01  4.4402e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       11-      48  2.8099e+02  4.4353e+01  8.0086e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       53-      59  4.1802e+02  3.7807e+01  1.6005e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       25-      54  3.2835e+02  3.3609e+01  7.2062e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06        9-      52  2.7418e+02  4.2186e+01  1.0738e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06        9-      52  2.7418e+02  4.2186e+01  1.0738e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       66-      58  4.1562e+02  3.2120e+01  1.5161e-03
    1T  3.4e-06       19-      58  1.7628e+02  4.2085e+01  7.8252e-06
    1T  2.4e-06        6-      59  4.7994e+02  3.6463e+01  4.6612e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-07       47-      61  3.5812e+02  3.9835e+01  4.2324e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-07       70-      48  2.2985e+02  3.7877e+01  7.0046e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06        9-      52  2.7418e+02  4.2186e+01  1.0738e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06        9-      52  2.7418e+02  4.2186e+01  1.0738e-04
    1T  1.0e-05       16-      59  2.1183e+02  4.6116e+01  5.4132e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       37-      66  4.6503e+02  3.7104e+01  1.1426e-04
    1T  8.4e-06       16-      51  2.0309e+02  4.6860e+01  1.9324e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       60-      61  3.9490e+02  3.9900e+01  8.8206e-06
    1T  1.9e-06       46-      56  3.7474e+02  4.7690e+01  6.3455e-04
    1T  3.5e-06       57-      59  2.0600e+02  4.4349e+01  6.3400e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.9e-06       69-      58  2.3254e+02  4.4791e+01  2.9284e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-07       10-      64  3.6569e+02  4.5056e+01  1.4315e-03
    1T  7.5e-06       28-      61  1.9703e+02  4.1634e+01  2.7692e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       19-      54  2.4152e+02  5.1108e+01  1.2591e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       31-      63  1.9314e+02  4.4553e+01  9.8815e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       65-      56  8.7910e+02  4.7678e+01  3.1421e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       41-      56  2.8322e+02  4.7364e+01  1.7581e-06
    1T  4.0e-08        7-      59  1.9487e+02  4.4370e+01  8.3119e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       38-      60  2.1702e+02  4.2957e+01  4.6352e-06
    1T -3.5e-06       35-      63  1.9938e+02  4.6206e+01  5.0018e-03
    1T -6.3e-06        2-      61  6.0957e+02  4.8936e+01  5.0578e-03
    1T  9.7e-06       58-      63  2.5388e+02  4.4607e+01  5.8459e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       65-      53  2.4247e+02  5.0723e+01  5.7454e-03
    1T  4.9e-06       35-      46  2.3255e+02  4.8833e+01  4.8631e-03
    1T  6.4e-06       58-      53  9.0568e+02  6.3764e+01  3.3346e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06        7-      46  2.1455e+03  7.7989e+01  1.6369e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.302979s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       42-      71  7.6066e+02  3.1174e+01  6.5173e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       50-      63  3.6476e+02  3.4710e+01  6.7791e-03
    1T  8.2e-06        5-      62  4.4762e+02  3.6822e+01  3.9910e-03
    1T  9.8e-06       42-      71  6.2116e+02  3.0200e+01  6.9587e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       42-      64  3.8177e+02  3.1771e+01  5.0455e-03
    1T  9.7e-06       27-      55  6.5770e+02  3.5971e+01  4.7928e-03
    1T -5.5e-06       35-      68  8.3016e+02  4.1345e+01  2.4792e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       32-      62  2.8558e+02  3.7221e+01  5.3092e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       74-      62  5.0162e+02  3.5691e+01  7.5870e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06        3-      46  5.8235e+02  4.9849e+01  5.2600e-06
    1T  3.5e-06       25-      58  7.6756e+02  3.4899e+01  1.2638e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       33-      60  2.7860e+02  3.7317e+01  1.7455e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-07       59-      59  2.9048e+02  3.8237e+01  8.1606e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-07       15-      63  2.9652e+02  3.8847e+01  6.1870e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       59-      65  3.2757e+02  4.2967e+01  1.5300e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       47-      65  1.6049e+03  3.9437e+01  2.5550e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       65-      60  2.5248e+02  3.7988e+01  7.7533e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06        3-      64  2.9968e+02  3.8396e+01  5.1959e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-07       61-      62  1.4963e+03  4.0937e+01  1.9794e-03
    1T  5.3e-06       34-      58  2.3924e+02  3.7499e+01  4.6706e-03
    1T -5.7e-07       34-      61  2.5096e+02  3.6463e+01  6.8746e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       22-      57  4.5714e+02  3.7775e+01  3.8571e-03
    1T  7.4e-06       75-      64  3.2295e+02  4.1842e+01  7.2356e-06
    1T  4.7e-06       60-      68  2.6382e+02  3.9492e+01  6.5069e-04
    1T -6.3e-06       18-      62  2.7450e+02  3.7448e+01  3.1485e-03
    1T  4.2e-06       75-      64  2.8308e+02  4.0238e+01  3.2702e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       75-      59  2.8366e+02  4.0760e+01  7.1983e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
    1T  5.2e-06       34-      56  3.3645e+02  4.0869e+01  4.8568e-03
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06        5-      60  2.3692e+02  3.9791e+01  4.0156e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       61-      71  2.9235e+02  3.7313e+01  6.5212e-04
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
    1T -7.5e-07       19-      55  2.9321e+02  3.5118e+01  4.8286e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.438798s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       27-      65  3.2385e+02  3.0060e+01  1.6215e-06
    1T -4.8e-06       13-      69  8.1481e+02  2.6082e+01  5.8711e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       75-      66  1.3523e+03  3.7101e+01  4.2755e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      53  4.8524e+02  2.6535e+01  8.8635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      53  4.8524e+02  2.6535e+01  8.8635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      53  4.8524e+02  2.6535e+01  8.8635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      53  4.8524e+02  2.6535e+01  8.8635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      53  4.8524e+02  2.6535e+01  8.8635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       71-      69  7.0644e+02  2.6186e+01  5.2056e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06        6-      63  7.6983e+02  2.4990e+01  9.1751e-06
    1T -8.4e-06       36-      65  7.5004e+02  2.5368e+01  9.7654e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       11-      64  1.0750e+03  2.9255e+01  9.9557e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06       73-      61  4.6928e+02  2.7020e+01  7.4814e-03
    1T  4.8e-06       22-      66  2.4351e+03  2.7774e+01  2.3021e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       17-      63  3.4412e+02  3.4003e+01  1.1631e-06
    1T  2.7e-06        6-      58  5.2448e+02  2.8140e+01  5.6346e-06
    1T  2.5e-06       14-      72  6.3243e+02  2.6857e+01  2.2947e-07
    1T -3.0e-06       29-      44  4.7245e+02  3.4510e+01  4.3915e-03
    1T  3.4e-07       14-      56  8.6889e+02  4.4502e+01  4.0617e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       23-      53  4.8524e+02  2.6535e+01  8.8635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       12-      60  3.2305e+02  3.0634e+01  4.8023e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       73-      57  3.9308e+02  2.8675e+01  3.9304e-06
    1T -7.6e-06       41-      65  3.7051e+02  3.1275e+01  3.8475e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       58-      59  4.3446e+02  3.0056e+01  7.3463e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       58-      54  3.8390e+02  3.0157e+01  4.9768e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.1e-06       15-      63  3.8473e+02  3.0034e+01  2.9226e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       36-      59  3.5829e+02  3.2505e+01  6.1702e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       14-      57  3.5805e+02  2.9789e+01  4.3607e-03
    1T  6.7e-06       16-      62  7.2582e+02  3.1157e+01  3.8773e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       71-      63  3.6190e+02  2.9934e+01  2.2026e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       70-      56  3.6825e+02  3.0729e+01  5.5276e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       52-      47  4.2349e+02  2.6384e+01  7.6275e-05
    1T  4.5e-06       51-      57  3.8199e+02  2.9272e+01  2.7307e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       68-      58  3.8974e+02  3.0175e+01  4.2758e-03
    1T  5.2e-06       75-      60  3.7629e+02  3.0676e+01  1.0260e-06
    1T  2.9e-06       70-      61  3.3435e+02  3.0731e+01  2.1905e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06        4-      52  3.7646e+02  2.9968e+01  3.5581e-03
    1T  2.2e-06       42-      66  3.4326e+02  3.0133e+01  2.1170e-07
    1T  9.7e-07       57-      61  3.5459e+02  3.0583e+01  4.5010e-07
    1T -7.0e-06       57-      61  1.9329e+03  3.0158e+01  1.9991e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06        8-      56  3.8098e+02  2.8889e+01  3.9826e-03
    1T  2.6e-06       20-      60  5.4105e+02  2.8421e+01  1.3793e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-07        1-      51  3.2589e+02  2.9854e+01  2.3247e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-07       38-      63  3.0916e+02  3.1158e+01  1.5794e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  6.3e-06       27-      56  3.6246e+02  3.0836e+01  3.2898e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       10-      57  3.1046e+02  2.9449e+01  1.5406e-07
    1T  4.5e-06       19-      65  3.3694e+02  3.5922e+01  2.0128e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T -4.1e-06       47-      67  3.7710e+02  3.0956e+01  3.4955e-07
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
    1T  1.2e-06       75-      56  6.2365e+02  2.9269e+01  1.4170e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    64   139   147    12   181   142     3    67    21   118    98   154    38

  Columns 14 through 26

    25   172    59   165    34   187   130   143   188   195    10   133   195

  Columns 27 through 30

   145   124    86     8


Accuracy =

   99.3022


Accuracy =

   99.3736


Accuracy =

   99.3165


Accuracy =

   99.3246


Accuracy =

   99.3838


Accuracy =

   99.2736


Accuracy =

   99.2573


Accuracy =

   99.2573


Accuracy =

   99.3022


Accuracy =

   99.3573


Accuracy =9.935729e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.6696
  100.0000
   99.8323
   99.8420
   97.7329
  100.0000
   99.7535
   98.8622
   99.9822
   99.5280
   99.7940
   99.8854
  100.0000
   98.5582
   98.6614
   99.7559

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.4911




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.4e-06       19-      52  1.9335e+02  3.9217e+01  7.6436e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       15-      66  5.5923e+02  6.8799e+01  5.8424e-03
    1T  8.7e-06       43-      62  2.7258e+02  5.7053e+01  8.7930e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       11-      57  2.7930e+02  3.8898e+01  2.1385e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06        5-      55  1.3684e+02  5.4026e+01  1.1177e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.9e-06       15-      53  1.6205e+02  4.8471e+01  3.3479e-03
    1T -3.0e-06       68-      44  1.7536e+02  4.3156e+01  3.9969e-03
    1T  5.8e-06       26-      56  2.1766e+02  4.3485e+01  5.9179e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       21-      61  1.7884e+02  7.6308e+01  4.9721e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       38-      47  1.1695e+03  6.1532e+01  8.2251e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       54-      50  1.8048e+02  5.6068e+01  2.0779e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06        5-      61  2.4829e+02  6.8809e+01  3.7648e-07
    1T  8.5e-06        3-      46  7.6199e+02  5.2401e+01  1.8879e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        7-      54  3.3642e+02  6.7112e+01  2.5686e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        7-      54  3.3642e+02  6.7112e+01  2.5686e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        7-      54  3.3642e+02  6.7112e+01  2.5686e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        7-      54  3.3642e+02  6.7112e+01  2.5686e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        7-      54  3.3642e+02  6.7112e+01  2.5686e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        7-      54  3.3642e+02  6.7112e+01  2.5686e-06
    1T  3.2e-06        7-      54  4.0787e+02  4.6425e+01  1.6156e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       59-      56  1.4238e+02  4.8637e+01  2.0817e-07
    1T  7.4e-06       13-      49  1.7059e+03  9.1956e+01  5.6030e-06
    1T  6.1e-06       74-      54  1.9828e+02  6.3859e+01  1.4121e-06
    1T -5.5e-06        9-      56  3.9474e+02  5.2060e+01  5.7254e-03
    1T -2.3e-06       61-      40  2.2588e+02  6.9756e+01  5.0720e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       12-      46  2.8925e+02  1.1686e+02  1.6304e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       10-      58  1.8743e+02  7.6956e+01  4.1439e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       36-      58  6.3591e+02  7.3613e+01  1.1460e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       57-      55  7.1610e+02  8.1309e+01  4.3544e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       58-      50  1.5558e+02  5.6899e+01  4.4112e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       20-      49  1.6394e+02  5.5027e+01  3.1353e-03
    1T -6.4e-06       46-      59  1.3785e+02  5.1896e+01  3.6847e-03
    1T -1.6e-06       14-      58  5.5807e+02  7.7170e+01  3.5148e-03
    1T  7.3e-06       46-      58  1.8387e+02  5.6816e+01  1.5826e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-06       70-      52  1.5712e+02  5.1831e+01  3.5991e-03
    1T  6.3e-06        7-      57  1.4101e+02  4.9773e+01  2.6291e-07
    1T  9.7e-06       67-      59  2.3949e+02  5.5251e+01  2.2671e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       31-      58  1.4732e+02  5.6831e+01  5.1307e-03
    1T -3.8e-06       23-      44  1.5693e+02  5.7530e+01  3.4134e-03
    1T  4.7e-06       54-      51  1.4208e+02  5.5805e+01  1.8833e-05
    1T  2.1e-06       23-      52  1.4883e+02  5.5938e+01  4.8354e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       34-      41  3.2843e+02  7.3925e+01  1.2500e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       34-      41  3.2843e+02  7.3925e+01  1.2500e-06
    1T  1.5e-06       34-      41  3.2843e+02  7.3925e+01  1.2500e-06
    1T  1.5e-06       34-      41  3.2843e+02  7.3925e+01  1.2500e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        6-      61  1.8185e+02  3.3882e+01  3.7889e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       47-      57  2.6473e+02  2.7551e+01  9.6430e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       51-      62  5.5424e+02  4.2810e+01  5.0148e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       36-      56  2.1252e+02  3.6274e+01  2.8714e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-06       57-      67  3.8179e+02  3.5284e+01  5.9310e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       66-      59  5.9728e+02  3.6618e+01  1.0264e-02
    1T -5.2e-06       31-      50  2.2763e+02  4.0783e+01  3.2745e-03
    1T  4.9e-06       57-      60  2.3824e+02  3.5915e+01  4.8122e-03
    1T  2.9e-06        4-      52  2.0660e+02  3.4328e+01  1.6558e-06
    1T -9.5e-06       68-      62  6.7241e+02  4.4014e+01  1.3425e-03
    1T -3.4e-06       22-      51  2.2456e+03  3.8385e+01  5.5085e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       70-      54  4.2025e+02  5.2174e+01  2.0701e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       33-      66  3.6594e+02  3.3706e+01  2.6484e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       37-      36  6.6120e+02  5.9324e+01  3.4615e-07
    1T  3.7e-06       25-      60  5.7144e+02  2.7522e+01  4.6451e-03
    1T  7.0e-06       56-      60  4.1276e+02  4.0773e+01  1.5640e-03
    1T  4.0e-06        3-      52  2.5052e+02  3.7360e+01  3.5421e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06        1-      52  2.0831e+02  4.1680e+01  2.6921e-03
    1T  7.7e-07        4-      64  2.1925e+02  3.5954e+01  1.2947e-03
    1T -2.4e-06       52-      56  2.0409e+02  3.8295e+01  1.0714e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-07       43-      54  2.4734e+02  3.9748e+01  2.2862e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       62-      58  2.5858e+02  4.4750e+01  1.1072e-03
    1T -2.4e-06       49-      51  8.0597e+02  3.7713e+01  2.6496e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       55-      59  2.0949e+02  3.3776e+01  2.2096e-06
    1T -4.4e-06       21-      45  2.5780e+02  3.5336e+01  3.3018e-03
    1T  8.3e-06       32-      58  4.3247e+02  4.2759e+01  2.6935e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.9e-06       31-      66  2.1558e+02  4.0523e+01  2.7153e-04
    1T -4.6e-06       26-      61  6.3312e+02  4.2384e+01  6.9896e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06       37-      52  3.4543e+02  3.7518e+01  8.3247e-04
    1T  3.8e-06       74-      60  2.0690e+02  3.9786e+01  4.2612e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       11-      59  2.2457e+02  3.7099e+01  2.1951e-03
    1T -7.7e-06       55-      62  2.5483e+02  3.7222e+01  4.2515e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       70-      57  2.3242e+02  4.0661e+01  1.5923e-05
    1T  2.6e-06       38-      57  3.3997e+02  3.4301e+01  4.9481e-06
    1T -4.9e-06       29-      56  2.1259e+02  3.2066e+01  2.9882e-03
    1T -1.6e-07       11-      52  2.1363e+02  3.8926e+01  2.5670e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       73-      54  4.4164e+02  2.7451e+01  9.0252e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       61-      56  2.9960e+02  2.6842e+01  3.5485e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       65-      64  5.2110e+02  3.1340e+01  2.3189e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-07       32-      61  2.5881e+02  2.9375e+01  2.2992e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       60-      50  3.8327e+02  3.6093e+01  5.0583e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-06        2-      57  1.0704e+03  2.8423e+01  5.1243e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       26-      72  6.5857e+02  4.8421e+01  2.2497e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.0e-07       66-      65  4.3662e+02  2.7311e+01  4.2213e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       56-      62  4.3069e+02  2.9060e+01  7.9491e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       54-      61  4.2399e+02  3.3133e+01  3.2493e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       74-      59  8.9133e+02  2.7325e+01  7.9010e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       75-      72  9.8270e+02  4.4635e+01  5.1809e-07
    1T  1.8e-08        4-      65  5.3782e+02  3.6975e+01  9.2409e-09

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       41-      71  3.7987e+02  2.7986e+01  3.9244e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       25-      60  4.3499e+02  2.9706e+01  5.3680e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       62-      62  2.7185e+02  2.8530e+01  9.9866e-05
    1T -1.9e-06       18-      66  2.8143e+02  3.4167e+01  1.9811e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       32-      56  4.1182e+02  3.1826e+01  1.8891e-05
    1T  9.7e-06       34-      53  2.7789e+02  3.4753e+01  2.6188e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-07       62-      56  2.7234e+02  3.0104e+01  2.0479e-03
    1T  5.6e-06       74-      67  6.0206e+02  2.7871e+01  3.9470e-07
    1T -8.8e-06       16-      59  4.2180e+02  3.0263e+01  3.1821e-04
    1T  9.2e-06       30-      52  3.3247e+02  3.0091e+01  3.1302e-03
    1T  5.8e-06       20-      62  4.2690e+02  2.8363e+01  8.9601e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-07       73-      67  3.7181e+02  2.9393e+01  7.3592e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       16-      67  7.1898e+02  3.3476e+01  3.7126e-03
    1T  7.9e-06       27-      62  5.6831e+02  3.4541e+01  3.9237e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06        1-      57  5.9122e+02  3.0426e+01  1.6679e-03
    1T  7.1e-06        3-      57  2.6694e+02  2.7106e+01  6.0057e-03
    1T  6.7e-07        1-      72  7.3903e+02  4.6960e+01  1.4207e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       58-      68  5.2462e+02  2.7952e+01  1.8429e-06
    1T  5.4e-06       39-      51  3.5058e+02  3.2132e+01  3.1649e-06
    1T  6.7e-06       16-      69  2.0327e+03  2.8221e+01  5.3327e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-07       37-      53  3.3532e+02  3.2207e+01  1.2678e-07
    1T -3.1e-06        3-      55  6.4940e+02  3.1583e+01  4.0472e-03
    1T  3.3e-06       73-      59  4.2095e+02  3.0392e+01  8.4985e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       63-      53  4.7565e+02  3.8061e+01  5.2343e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       13-      62  3.2942e+02  3.3604e+01  7.2916e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       47-      60  3.3394e+02  3.1217e+01  6.5885e-07
    1T  2.5e-06       50-      51  3.5532e+03  6.1455e+01  1.3645e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       34-      62  8.0289e+02  3.1293e+01  3.0572e-03
    1T  5.1e-06        2-      66  2.5139e+02  3.2195e+01  9.2643e-06
    1T -1.6e-06       45-      57  2.7455e+02  3.4044e+01  5.2198e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       43-      59  2.5766e+02  3.2953e+01  4.7618e-03
    1T -7.3e-06        5-      59  3.0853e+02  3.3699e+01  2.3164e-03
    1T  5.9e-06       47-      61  3.8461e+02  3.4158e+01  2.3968e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       13-      62  6.0203e+02  3.1872e+01  3.3785e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       26-      66  2.6333e+02  3.4291e+01  2.3079e-06
    1T -5.2e-06       25-      50  3.0279e+02  3.3479e+01  8.3012e-04
    1T  1.1e-06        7-      59  2.9658e+02  3.4864e+01  1.6760e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       25-      56  1.3231e+03  3.5181e+01  4.7838e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06        5-      66  2.7959e+02  3.6167e+01  1.8476e-03
    1T  2.3e-06       63-      59  2.5877e+02  3.3246e+01  5.5758e-03
    1T -6.2e-06       41-      59  5.7795e+02  3.6871e+01  7.5948e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       62-      41  4.7623e+03  1.2897e+02  5.1728e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.43687s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       50-      24  3.5586e+02  3.0318e+01  5.1540e-06
    1T -8.2e-06       50-      24  3.5586e+02  3.0318e+01  5.1540e-06
    1T -8.2e-06       50-      24  3.5586e+02  3.0318e+01  5.1540e-06
    1T -8.2e-06       50-      24  3.5586e+02  3.0318e+01  5.1540e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       50-      24  3.5586e+02  3.0318e+01  5.1540e-06
    1T -8.2e-06       50-      24  3.5586e+02  3.0318e+01  5.1540e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       62-      66  3.2755e+03  2.6844e+01  3.1954e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       61-      66  5.7611e+02  2.6283e+01  7.7726e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       61-      63  6.6315e+02  2.5499e+01  6.0634e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       18-      62  1.3732e+03  2.8064e+01  5.2643e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       40-      24  3.6444e+02  2.9831e+01  2.8284e-06
    1T -9.9e-06       58-      71  7.3643e+02  2.4964e+01  7.2404e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06        3-      71  1.1387e+03  2.5368e+01  2.0553e-07
    1T  5.3e-06       29-      69  5.5852e+02  2.5629e+01  5.5587e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       10-      65  7.4468e+02  2.9824e+01  1.2638e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       13-      71  7.6901e+02  2.4264e+01  1.3024e-03
    1T  9.9e-06       68-      72  6.2773e+02  2.4875e+01  4.8875e-03
    1T -9.2e-06       56-      59  2.7750e+03  2.7016e+01  8.1659e-03
    1T  9.5e-06       17-      61  8.3913e+02  2.9431e+01  1.0424e-02
    1T  5.1e-06        3-      61  4.8902e+02  2.6875e+01  4.9448e-03
    1T -8.3e-06       11-      70  9.8489e+02  2.5554e+01  5.5601e-07
    1T  4.5e-06       28-      63  7.7769e+02  3.0658e+01  3.6198e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-07       60-      68  1.0573e+03  3.8675e+01  1.7798e-03
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       26-      65  3.5856e+02  2.8834e+01  1.9508e-03
    1T -9.5e-06       30-      61  4.0361e+03  3.2087e+01  9.2366e-03
    1T  4.7e-06       47-      65  3.9524e+02  2.9404e+01  4.5283e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       57-      46  4.1979e+02  2.6409e+01  5.4517e-07
    1T  8.6e-06       20-      60  1.6099e+03  2.9438e+01  1.2200e-05
    1T -8.0e-06       25-      67  9.2881e+02  2.6408e+01  3.5494e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       33-      65  1.9480e+03  3.3516e+01  4.3531e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       52-      63  3.4531e+02  2.6075e+01  3.3095e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.6e-07       71-      66  4.1233e+02  2.6795e+01  3.7185e-03
    1T  4.1e-07       18-      64  6.3237e+02  3.3556e+01  3.6446e-07
    1T -2.8e-06       74-      67  3.4756e+02  2.6941e+01  4.4739e-03
    1T -5.2e-06       48-      58  3.1429e+02  2.6099e+01  1.3655e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       35-      64  1.3071e+03  2.6897e+01  1.7727e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       65-      59  3.2882e+02  2.5131e+01  1.8394e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       23-      62  3.9243e+02  2.7416e+01  1.9406e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       39-      59  3.5396e+02  2.6398e+01  5.1017e-03
    1T  1.4e-06       71-      62  3.2534e+02  2.5486e+01  1.0823e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-06       23-      60  3.5432e+02  2.6230e+01  3.8503e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        4-      65  4.1993e+02  2.6892e+01  4.3745e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       60-      62  1.3385e+03  2.5290e+01  5.4029e-03
    1T -8.8e-06       39-      55  7.3102e+02  2.7333e+01  1.4029e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06        5-      62  3.9115e+02  2.6322e+01  5.0002e-06
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  5.3e-06       35-      70  6.5110e+02  2.9779e+01  6.8219e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-07       41-      57  3.6034e+02  2.7490e+01  3.6334e-03
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
    1T  1.0e-06        1-      65  1.0274e+03  2.5139e+01  7.4468e-07
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   195   200    84   110   188   156    82   177    83    22   183     5    49

  Columns 14 through 26

    58   177    48   168    30    60    56    38   187   149    27   104   121

  Columns 27 through 30

    84   136    68    23


Accuracy =

   99.4777


Accuracy =

   99.5695


Accuracy =

   99.6083


Accuracy =

   99.5940


Accuracy =

   99.6083


Accuracy =

   99.5817


Accuracy =

   99.5063


Accuracy =

   99.5246


Accuracy =

   99.5287


Accuracy =

   99.5328


Accuracy =9.953278e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.9450
   99.9407
  100.0000
   99.4444
   98.6788
  100.0000
   99.8458
   99.5102
  100.0000
   99.4960
   99.4819
  100.0000
  100.0000
  100.0000
   98.3445
   99.8165

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.6565




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-06       34-      48  1.6893e+02  9.5847e+01  5.7712e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       22-      50  3.6174e+02  9.6671e+01  4.0490e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       25-      50  1.7453e+02  8.8668e+01  6.6969e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        9-      48  1.7137e+02  4.7518e+01  3.6834e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       62-      47  1.7720e+02  8.4454e+01  9.2426e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       10-      53  7.6805e+02  4.2801e+01  7.1195e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06        2-      61  3.2276e+02  8.8545e+01  5.9940e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06        2-      52  2.1981e+02  4.8527e+01  6.7663e-03
    1T  9.9e-06        8-      57  1.6104e+02  4.7030e+01  1.9979e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06        6-      69  2.3137e+02  5.8928e+01  2.2660e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       10-      60  4.5548e+02  4.1593e+01  4.9481e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-07       40-      58  3.4505e+02  4.0995e+01  1.1974e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       60-      34  2.3293e+02  5.0475e+01  3.2147e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       66-      52  3.6367e+02  4.7443e+01  3.5599e-07
    1T  1.7e-06       51-      55  3.4039e+02  4.8282e+01  8.9018e-03
    1T  4.7e-06       42-      53  1.8240e+02  5.2119e+01  4.1750e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       39-      59  2.8296e+02  5.2309e+01  2.7073e-03
    1T  1.9e-06       71-      60  1.9059e+02  4.5270e+01  1.5057e-06
    1T -9.6e-06       54-      57  3.3574e+02  6.2127e+01  5.1175e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       24-      42  1.7165e+02  5.2496e+01  1.3607e-05
    1T  1.9e-06       17-      59  3.5711e+02  8.8792e+01  6.0692e-03
    1T  1.2e-06       25-      57  2.0223e+02  4.3266e+01  8.1336e-05
    1T  6.4e-06       21-      64  3.1760e+02  5.8053e+01  6.1809e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       73-      55  2.6084e+02  4.3244e+01  4.6290e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-07       60-      56  1.9085e+02  7.9568e+01  1.9049e-04
    1T -6.7e-06       32-      59  1.4554e+02  7.4034e+01  4.4214e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       63-      61  4.6270e+02  4.4937e+01  3.9710e-03
    1T -7.0e-06       18-      58  1.6468e+02  5.5968e+01  1.7876e-03
    1T -4.4e-07       38-      52  1.7647e+02  4.8863e+01  3.5043e-03
    1T  8.0e-06       65-      60  5.9471e+02  7.1764e+01  8.9625e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       65-      60  5.9471e+02  7.1764e+01  8.9625e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       65-      60  5.9471e+02  7.1764e+01  8.9625e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       29-      55  2.0361e+02  4.2787e+01  7.1808e-04
    1T  4.3e-07       55-      51  1.6541e+02  3.7152e+01  1.7778e-07
    1T  9.0e-06       34-      44  1.5701e+02  4.8881e+01  1.8235e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       36-      53  3.7096e+02  5.3050e+01  6.8366e-03
    1T  6.1e-06       20-      69  2.5241e+02  5.9887e+01  2.5802e-06
    1T  9.0e-06       40-      62  1.5118e+02  4.5340e+01  1.7491e-03
    1T  5.6e-06       30-      59  1.5137e+02  4.1116e+01  5.3576e-07
    1T  9.6e-06       21-      52  1.6112e+02  4.7399e+01  4.4842e-03
    1T -5.1e-06       22-      57  1.5324e+02  1.0091e+02  1.0448e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       34-      46  3.3626e+02  4.5271e+01  1.3661e-04
    1T -1.1e-06       32-      52  2.7413e+02  4.5227e+01  9.2385e-08
    1T -9.1e-06       37-      60  1.4869e+02  8.3225e+01  3.4238e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       46-      51  1.7802e+02  4.8854e+01  9.8084e-07
    1T  1.7e-06        1-      48  1.6204e+02  1.0869e+02  4.5302e-03
    1T  4.4e-06       31-      54  1.9042e+02  1.2591e+02  2.6771e-03
    1T  2.6e-07       56-      54  1.5197e+02  4.5425e+01  5.4992e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       60-      42  1.5406e+02  4.2784e+01  3.8096e-04
    1T -1.0e-05       20-      53  1.3741e+02  5.7826e+01  1.0952e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  2.2680e+02  4.1660e+01  2.1892e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  2.2680e+02  4.1660e+01  2.1892e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  2.2680e+02  4.1660e+01  2.1892e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  2.2680e+02  4.1660e+01  2.1892e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  2.2680e+02  4.1660e+01  2.1892e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       24-      44  2.2680e+02  4.1660e+01  2.1892e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       60-      42  1.5406e+02  4.2784e+01  3.8096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       60-      42  1.5406e+02  4.2784e+01  3.8096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       60-      42  1.5406e+02  4.2784e+01  3.8096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       60-      42  1.5406e+02  4.2784e+01  3.8096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       60-      42  1.5406e+02  4.2784e+01  3.8096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-06       30-      48  1.7387e+02  3.6227e+01  5.1137e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       60-      66  3.5938e+02  4.8881e+01  8.8866e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       62-      60  7.8305e+02  3.4753e+01  2.8563e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       65-      56  5.1242e+02  3.8219e+01  2.6485e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       49-      52  2.2885e+02  3.0242e+01  4.5392e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       63-      62  5.2173e+02  3.2131e+01  4.2610e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       45-      57  3.6343e+02  3.3751e+01  8.1330e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       50-      52  2.2344e+02  4.2802e+01  6.6249e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       14-      60  3.0245e+02  3.4577e+01  2.2617e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       46-      66  1.9937e+02  3.8928e+01  2.7410e-06
    1T  1.9e-06       73-      63  3.9445e+02  3.1869e+01  2.2497e-04
    1T -1.2e-06       28-      63  4.0015e+02  3.0226e+01  6.7244e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       58-      59  5.1674e+02  3.7193e+01  8.7173e-03
    1T  4.6e-06        9-      58  3.6663e+02  3.6654e+01  7.7930e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       32-      67  4.3483e+02  2.9619e+01  3.2554e-07
    1T -7.8e-06       43-      59  2.8840e+02  3.5909e+01  6.2104e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       11-      61  3.8033e+02  3.1439e+01  2.6433e-07
    1T  1.3e-06       55-      59  3.9661e+02  3.2472e+01  2.3301e-03
    1T  4.7e-06        7-      66  2.1373e+02  3.3216e+01  4.1954e-03
    1T -9.8e-06       23-      67  4.8206e+02  2.9818e+01  6.0522e-03
    1T  2.0e-06       31-      66  3.4212e+02  3.0327e+01  5.3109e-06
    1T -5.1e-06       52-      64  3.7731e+02  2.9857e+01  1.3358e-03
    1T -6.7e-06       34-      66  3.7197e+02  3.2122e+01  3.7789e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       64-      66  4.5015e+02  2.8221e+01  4.7900e-03
    1T  5.5e-06       73-      55  2.5427e+02  3.9243e+01  2.3728e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       67-      61  3.5844e+02  3.7023e+01  1.1858e-02
    1T  8.5e-06        8-      56  3.5413e+02  6.7696e+01  7.2346e-06
    1T  7.5e-06       37-      52  1.9198e+02  3.5568e+01  4.5947e-03
    1T  9.8e-06       36-      58  3.0048e+02  3.6325e+01  9.9769e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       41-      64  7.8071e+02  3.8856e+01  9.1676e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       58-      54  2.2575e+02  3.3254e+01  2.2924e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       30-      63  1.9348e+02  3.4642e+01  4.3774e-07
    1T  4.5e-06        6-      55  1.9487e+02  3.5438e+01  1.8002e-06
    1T -4.2e-06       64-      58  1.9634e+02  3.4467e+01  2.7217e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       60-      53  2.1296e+02  3.5962e+01  3.9250e-03
    1T  4.5e-06       43-      61  2.3465e+02  3.5867e+01  1.7468e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       37-      58  2.7559e+02  3.6814e+01  3.6496e-03
    1T  8.3e-06       53-      56  2.5064e+02  4.1968e+01  2.7661e-06
    1T  3.4e-06       61-      60  2.1660e+02  3.1999e+01  2.2888e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       40-      61  2.0301e+02  3.9743e+01  2.5196e-06
    1T  6.8e-06       66-      55  2.3541e+02  3.5743e+01  3.0806e-06
    1T  6.6e-06       14-      60  2.2125e+02  3.8227e+01  1.7584e-06
    1T  5.3e-06       54-      58  2.2999e+02  4.1614e+01  3.0099e-06
    1T -2.8e-07       32-      50  2.5734e+02  3.6869e+01  2.2538e-08
    2T -2.7e-06       31-      49  2.5734e+02  3.6869e+01  2.4435e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-07       42-      63  2.9292e+02  2.8730e+01  1.0431e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       27-      64  4.8963e+02  2.8633e+01  5.6992e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-07       37-      64  4.5712e+02  2.8978e+01  9.6711e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06        3-      57  1.2171e+03  3.3782e+01  5.8066e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       45-      21  2.8221e+02  3.8257e+01  1.2886e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06        6-      64  1.3505e+03  4.0023e+01  2.2590e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06        9-      64  4.5520e+02  2.8611e+01  8.4024e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       21-      68  2.4206e+03  3.9863e+01  4.2563e-07
    1T -3.3e-06       23-      60  3.6804e+02  3.2397e+01  3.2438e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       24-      63  5.3195e+02  2.9843e+01  2.7707e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       61-      72  7.4267e+02  4.5483e+01  2.9370e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       23-      66  2.5498e+02  2.8756e+01  1.9136e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       56-      67  6.7743e+02  2.6665e+01  5.7567e-03
    1T  4.0e-06       75-      63  6.5903e+02  2.9069e+01  2.8768e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       44-      63  8.4840e+02  3.3392e+01  2.8058e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       36-      69  6.3937e+02  4.4129e+01  6.7543e-07
    1T  8.9e-06        3-      63  4.2058e+02  3.2610e+01  1.1270e-02
    1T  6.3e-06       38-      64  8.2650e+02  4.1852e+01  1.7487e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       34-      55  9.2282e+02  3.4965e+01  2.1717e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       65-      61  3.2557e+02  2.7816e+01  2.3969e-03
    1T -2.1e-06       40-      51  8.2174e+02  3.0088e+01  4.3237e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       19-      69  4.7452e+02  2.8230e+01  5.0354e-07
    1T  5.9e-06        8-      60  4.2472e+02  2.9839e+01  7.9775e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       34-      37  5.2685e+02  4.4358e+01  2.4930e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06        4-      65  3.9249e+02  3.3632e+01  8.6619e-06
    1T  8.1e-06       39-      54  1.8391e+03  4.5604e+01  4.8675e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       37-      67  5.1637e+02  2.7163e+01  1.0538e-05
    1T  5.8e-06       37-      58  2.8247e+02  3.0186e+01  1.0244e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       59-      63  4.3873e+02  3.1152e+01  1.8297e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       39-      63  4.6935e+02  3.0899e+01  1.1053e-02
    1T  3.3e-06       14-      53  3.8290e+02  3.0961e+01  2.8391e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       24-      54  9.6058e+02  5.1201e+01  6.2814e-06
    1T -9.4e-06       40-      56  2.8575e+02  2.9551e+01  1.9635e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       70-      59  3.0964e+02  3.2352e+01  3.6562e-06
    1T  6.3e-06       37-      66  2.8714e+02  3.2246e+01  2.2230e-05
    1T -1.2e-07       12-      63  2.9366e+02  3.2714e+01  4.5924e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       44-      68  2.4229e+02  3.2773e+01  8.7003e-04
    1T -1.7e-06       68-      58  3.4469e+02  3.0780e+01  5.3338e-03
    1T -2.1e-06       61-      49  2.8741e+02  3.0668e+01  3.1938e-03
    1T  1.1e-06       43-      62  1.0220e+03  3.2367e+01  1.1852e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       36-      55  2.7882e+02  3.0748e+01  3.5915e-03
    1T  3.1e-06       68-      56  8.7438e+02  3.7301e+01  4.2060e-03
    1T  9.2e-06       59-      58  7.5461e+02  3.3581e+01  4.8525e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       57-      66  2.8192e+02  3.1691e+01  3.2449e-07
    1T  7.3e-06       75-      63  2.6985e+02  3.1748e+01  3.6910e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       33-      49  3.0264e+02  2.8123e+01  3.2748e-03
    1T  6.0e-06       14-      52  3.1810e+02  3.1454e+01  2.8820e-06
    1T  3.3e-07       33-      60  2.7188e+02  3.1315e+01  2.0223e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       56-      59  2.6416e+02  3.3344e+01  3.7545e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       33-      51  2.9922e+02  2.9400e+01  7.8055e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-07       73-      57  3.1124e+02  3.0811e+01  5.0290e-03
    1T  9.8e-06       68-      60  2.1967e+03  3.8246e+01  2.7261e-05
    1T  8.2e-06       18-      57  3.6905e+02  3.2309e+01  2.4803e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-07       45-      57  3.5852e+02  3.0744e+01  9.0602e-08
    1T -6.6e-06       25-      54  2.6075e+02  3.0647e+01  3.8739e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       47-      57  3.5810e+02  3.1457e+01  3.6537e-06
    1T  3.0e-07       63-      55  2.7020e+02  3.2827e+01  1.4255e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-06       75-      59  2.5780e+02  3.2488e+01  3.7871e-03
    1T  5.2e-06       45-      67  1.4777e+03  4.0671e+01  2.0965e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-07       48-      51  1.9016e+03  4.7966e+01  7.0333e-07
    1T  3.7e-07       44-      53  3.1864e+02  3.5219e+01  2.1698e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       26-      63  2.6664e+02  3.4669e+01  2.8768e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       40-      46  3.1217e+02  2.6301e+01  1.2677e-03
    1T  6.6e-06       70-      61  3.4317e+02  3.3161e+01  3.3213e-06
    1T  3.2e-06       75-      52  3.4371e+02  2.8118e+01  2.5193e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.417657s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       28-      44  3.7334e+02  6.0213e+01  1.8737e-06
    1T  4.0e-06       28-      44  3.7334e+02  6.0213e+01  1.8737e-06
    1T  4.0e-06       28-      44  3.7334e+02  6.0213e+01  1.8737e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       28-      44  3.7334e+02  6.0213e+01  1.8737e-06
    1T  4.0e-06       28-      44  3.7334e+02  6.0213e+01  1.8737e-06
    1T  4.0e-06       28-      44  3.7334e+02  6.0213e+01  1.8737e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       74-      56  6.1715e+02  2.6394e+01  4.5447e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       31-      60  3.5106e+02  2.7323e+01  6.3987e-05
    1T -7.9e-06       61-      70  1.3536e+03  4.3343e+01  7.6506e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       66-      55  1.4053e+03  3.4654e+01  3.7541e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-07       69-      69  7.4379e+02  2.7333e+01  7.3883e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       11-      56  1.2291e+03  3.4557e+01  3.7997e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       75-      61  7.3579e+02  2.8599e+01  7.0967e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       69-      71  8.7277e+02  2.6824e+01  9.9806e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       39-      69  7.0907e+02  2.8204e+01  1.6136e-03
    1T -9.2e-06       47-      72  1.0958e+03  2.8697e+01  7.6508e-07
    1T  4.4e-06       24-      67  5.0634e+02  3.3291e+01  7.2732e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       39-      65  4.4424e+02  3.0690e+01  5.9906e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       65-      68  1.4578e+03  2.6774e+01  3.7867e-03
    1T -3.3e-06       39-      57  7.0154e+02  2.9362e+01  3.9188e-03
    1T  3.2e-07       26-      64  6.0454e+02  2.6667e+01  1.6503e-04
    1T -3.5e-06       56-      68  1.1351e+03  3.8229e+01  4.6528e-03
    1T  5.3e-06       11-      69  5.2329e+02  2.8726e+01  6.1448e-04
    1T -5.9e-07        4-      59  8.9488e+02  3.2128e+01  5.0625e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       53-      57  5.4789e+02  3.2079e+01  6.9054e-07
    1T  5.4e-06       58-      72  7.8476e+02  2.7116e+01  3.7000e-03
    1T  6.8e-06        1-      67  8.2850e+02  2.7145e+01  5.8527e-03
    1T  3.8e-06       57-      58  7.9974e+02  2.8996e+01  1.7813e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06       30-      68  8.3187e+02  2.7183e+01  6.2936e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       11-      69  1.0828e+03  3.2758e+01  7.0442e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       55-      69  9.6954e+02  3.0958e+01  5.4974e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06        4-      61  5.6104e+02  3.4453e+01  9.2956e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-07       63-      69  1.2636e+03  3.3967e+01  1.1141e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       23-      60  4.1849e+02  2.9604e+01  1.2607e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       45-      57  3.4425e+02  3.2546e+01  5.4544e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.5e-06       25-      51  3.5281e+02  2.9779e+01  6.8303e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-06       25-      59  3.7815e+02  3.0015e+01  4.9192e-03
    1T -9.2e-06       50-      47  3.1273e+02  3.0028e+01  1.0237e-06
    1T  7.6e-06       30-      61  3.6891e+02  3.0060e+01  5.6208e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       60-      66  3.5630e+02  3.1035e+01  3.4550e-03
    1T -6.6e-07       55-      70  3.0536e+02  3.3469e+01  4.9953e-03
    1T -6.1e-06       53-      67  1.6706e+03  3.0568e+01  4.1812e-07
    1T -5.6e-06       10-      58  3.4394e+02  3.0655e+01  5.6314e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       37-      61  1.1243e+03  3.1992e+01  9.6241e-06
    1T  4.7e-06       42-      55  4.7319e+02  3.3386e+01  8.4260e-06
    1T -9.7e-06        2-      68  3.2572e+02  3.1161e+01  7.5511e-07
    1T  3.6e-06       28-      71  3.5703e+02  2.9911e+01  2.8796e-07
    1T  9.3e-06       32-      58  1.7757e+03  3.0268e+01  7.1305e-07
    1T -3.1e-06       60-      53  3.6505e+02  2.9552e+01  1.6722e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       58-      61  4.4417e+02  3.2782e+01  6.9656e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   152    22   126    25   151    93   148    22   183    16    94     7    90

  Columns 14 through 26

   160    10   154    31    35    81   181   189   119   185    60   125   122

  Columns 27 through 30

   156    17   145     6


Accuracy =

   99.7081


Accuracy =

   99.6224


Accuracy =

   99.6877


Accuracy =

   99.6306


Accuracy =

   99.6653


Accuracy =

   99.7061


Accuracy =

   99.6469


Accuracy =

   99.6632


Accuracy =

   99.6163


Accuracy =

   99.6653


Accuracy =9.966527e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.9450
   99.8221
  100.0000
   98.9707
   99.2568
   99.9721
   99.9076
   99.6571
  100.0000
   99.5956
   99.7927
   99.9426
   99.8789
   98.4488
   99.2089
   99.7555

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.6347




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       70-      60  2.3481e+02  6.4099e+01  7.5853e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       16-      50  1.2239e+02  4.1326e+01  5.3543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       11-      50  1.4381e+02  3.5495e+01  3.7125e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06        9-      50  1.5084e+02  4.3580e+01  5.3559e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.1e-06        8-      59  2.5148e+02  5.0087e+01  6.0797e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       71-      53  1.3657e+02  4.6774e+01  1.2030e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       57-      56  1.9168e+02  4.4607e+01  3.4558e-03
    1T  4.4e-06       52-      49  1.2808e+02  3.6389e+01  2.1571e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       26-      54  1.8584e+02  5.3314e+01  1.8361e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       37-      61  2.9196e+02  3.9926e+01  6.8792e-06
    1T  6.0e-06       45-      47  3.2034e+02  7.4888e+01  4.3367e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       15-      48  1.8460e+02  5.0448e+01  2.4274e-03
    1T  2.6e-06       34-      49  4.8399e+02  5.4312e+01  1.0567e-02
    1T  3.3e-06       35-      52  2.3755e+03  1.0012e+02  4.9379e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       54-      41  1.4014e+02  4.0420e+01  3.8390e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-07       36-      58  2.9257e+02  4.5577e+01  1.4987e-03
    1T  9.4e-06        2-      52  1.9301e+02  5.0325e+01  6.7777e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-07       13-      51  1.8286e+02  4.4187e+01  2.0352e-07
    1T  4.8e-06       19-      60  1.7158e+02  4.3197e+01  2.4273e-06
    1T -2.0e-07       26-      67  1.4224e+02  5.1359e+01  4.2629e-03
    1T  1.7e-06       39-      56  4.7309e+02  4.8386e+01  2.9569e-06
    1T  5.6e-06       13-      56  9.7600e+02  4.9121e+01  2.5682e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.2e-06       45-      57  1.7677e+02  4.3209e+01  1.9491e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       69-      51  1.8456e+02  3.9818e+01  3.2686e-03
    1T -2.1e-06       49-      49  1.5060e+02  4.1413e+01  4.2345e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       50-      53  2.6892e+02  3.9905e+01  1.5677e-03
    1T -1.7e-06       57-      52  1.5340e+02  4.7701e+01  2.7403e-03
    1T -9.1e-06        7-      60  1.8593e+02  5.0330e+01  1.0975e-03
    1T -6.3e-06       57-      49  1.5977e+02  3.9058e+01  7.4919e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       63-      52  2.0096e+02  4.2429e+01  9.2996e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       57-      51  2.2884e+02  4.1762e+01  1.6774e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       35-      54  2.7463e+02  5.1783e+01  6.6755e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06        6-      52  1.5843e+02  4.0609e+01  2.2172e-03
    1T  8.3e-06       10-      44  4.8509e+02  7.3845e+01  4.0695e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06        7-      45  1.8373e+02  3.9800e+01  1.0587e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       25-      51  2.0215e+02  3.9312e+01  5.1423e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       51-      49  4.4819e+02  4.9614e+01  4.4291e-06
    1T  2.7e-06       16-      50  1.4932e+02  3.8913e+01  1.1526e-03
    1T -2.7e-06       14-      55  1.7316e+02  3.9189e+01  2.6158e-03
    1T  3.7e-07       21-      63  1.5003e+02  4.0529e+01  4.2550e-03
    1T -4.1e-06       23-      59  1.4927e+02  4.3732e+01  4.9964e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06        3-      61  1.7591e+02  3.9565e+01  2.8626e-07
    1T  1.3e-06       72-      56  3.0256e+02  4.2894e+01  5.6397e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       45-      67  6.3326e+02  4.5074e+01  4.7481e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       56-      64  6.8376e+02  4.4640e+01  7.6878e-03
    1T  9.7e-06       46-      64  3.5098e+02  3.5665e+01  4.9770e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-07       26-      47  2.2949e+02  3.9299e+01  5.0503e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       15-      66  4.2076e+02  3.2508e+01  1.3943e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       50-      63  4.7986e+02  3.3875e+01  1.7604e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       74-      56  7.8695e+02  4.3363e+01  1.5546e-05
    1T -1.4e-06       68-      62  1.8023e+02  3.3687e+01  2.6037e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       67-      65  5.0163e+02  2.9328e+01  3.8031e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       16-      65  4.8040e+02  3.3716e+01  7.4490e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       70-      50  2.2352e+02  3.7304e+01  5.3677e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       45-      65  2.5216e+02  4.0803e+01  6.8572e-07
    1T -4.0e-06        9-      57  3.6344e+02  3.7041e+01  4.8478e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-07       20-      66  5.0971e+02  3.2966e+01  6.2108e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06        3-      66  3.6728e+02  3.4335e+01  2.5188e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.8e-06        8-      61  4.3347e+02  2.7052e+01  2.4391e-07
    1T  3.6e-06        4-      57  2.0723e+03  5.4902e+01  1.9543e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       30-      66  4.7892e+02  4.6224e+01  8.5229e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-06       73-      71  4.9088e+02  3.3295e+01  6.6542e-07
    1T  8.0e-06       14-      63  5.2356e+02  3.3280e+01  4.5745e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       15-      66  4.0854e+02  3.1684e+01  2.4567e-06
    1T  9.1e-06       15-      58  4.1820e+02  3.9688e+01  8.1587e-06
    1T  8.4e-06       49-      64  3.7950e+02  3.1854e+01  5.2628e-06
    1T  5.7e-07       11-      64  2.1705e+02  3.4697e+01  2.0997e-03
    1T -3.5e-06       32-      45  3.9641e+02  5.0662e+01  3.9159e-07
    1T  9.9e-06        3-      60  5.8577e+02  3.5070e+01  4.1968e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       10-      53  3.2891e+02  3.5770e+01  8.1280e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06        7-      57  2.2970e+02  3.9345e+01  5.4885e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       16-      47  2.0780e+02  3.7707e+01  7.6373e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       34-      43  3.2629e+02  5.4634e+01  6.3564e-03
    1T -6.6e-06       62-      49  2.4636e+02  3.3855e+01  3.6602e-03
    1T -9.1e-06       59-      60  3.2396e+02  4.1219e+01  2.9868e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       72-      46  1.7455e+03  5.2566e+01  3.1692e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       71-      52  2.8867e+03  6.4721e+01  1.1500e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       67-      64  2.3747e+02  3.6496e+01  4.5344e-07
    1T  9.8e-06       11-      62  2.3694e+02  3.9979e+01  5.5416e-07
    1T -8.3e-06       49-      51  2.1681e+02  3.8016e+01  3.1766e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06       74-      50  3.1897e+02  3.9568e+01  1.4530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06        5-      50  2.6018e+02  4.1412e+01  5.0121e-03
    1T  8.3e-06       22-      60  7.5406e+02  3.4707e+01  2.4136e-05
    1T -9.6e-06        4-      57  2.7827e+02  3.5588e+01  2.7134e-03
    1T  1.5e-06        2-      58  2.5405e+02  4.1612e+01  9.1937e-07
    1T  1.8e-06       27-      52  2.7305e+02  4.2215e+01  5.9686e-07
    1T  9.5e-06        4-      50  2.7555e+02  3.9257e+01  5.1022e-03
    1T  1.4e-06        2-      54  2.3409e+02  4.0230e+01  4.6396e-07
    1T -4.8e-06       11-      55  2.0151e+02  3.9203e+01  5.4950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       64-      43  3.0637e+02  3.4350e+01  2.1169e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      56  2.7206e+02  2.6136e+01  8.7742e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06        5-      59  5.9276e+02  3.3498e+01  5.8696e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       50-      60  6.1437e+02  2.7266e+01  3.6932e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        8-      66  2.3091e+02  3.2065e+01  1.6755e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       22-      60  2.9558e+02  2.7358e+01  3.6582e-03
    1T  3.4e-06       36-      64  1.1320e+03  4.3195e+01  1.6864e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       37-      54  2.5715e+02  2.5902e+01  4.4636e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       26-      65  2.6474e+02  3.2226e+01  1.1058e-06
    1T -5.4e-06       50-      62  6.9419e+02  3.3837e+01  2.8960e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06        7-      60  2.9888e+02  2.7384e+01  1.3564e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       54-      62  1.2894e+03  3.4515e+01  1.4815e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06        7-      63  1.9584e+03  3.6553e+01  6.5796e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       61-      65  2.8068e+02  3.6716e+01  5.9825e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       20-      42  4.6790e+02  4.7355e+01  1.7580e-06
    1T -7.0e-06       63-      72  6.1007e+02  2.8163e+01  5.6205e-07
    1T  3.4e-06       25-      64  5.3076e+02  3.2638e+01  5.5351e-03
    1T -5.9e-06       73-      61  6.0770e+02  2.8911e+01  1.6642e-03
    1T  9.3e-06       60-      67  5.9546e+02  2.9422e+01  3.4984e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-06       24-      58  2.5945e+02  3.8367e+01  3.5769e-03
    1T  5.1e-06       55-      63  3.3916e+02  3.4794e+01  3.8390e-03
    1T  9.9e-06        4-      63  1.2932e+03  2.8551e+01  1.6694e-03
    1T -9.2e-06       11-      58  4.6403e+02  3.0120e+01  5.8215e-03
    1T  5.7e-06       71-      69  4.8627e+02  2.8887e+01  1.8309e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       43-      53  4.2496e+02  3.3189e+01  4.6448e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       22-      64  2.7261e+02  3.3743e+01  4.4809e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       47-      65  3.9343e+02  3.5017e+01  2.9151e-03
    1T  6.6e-06       73-      57  2.6364e+02  3.8220e+01  9.1503e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       48-      62  3.3478e+02  3.3915e+01  3.5743e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       54-      59  2.7078e+02  3.2630e+01  4.1558e-03
    1T  3.4e-06       24-      61  2.9604e+02  3.5123e+01  2.9525e-04
    1T  9.2e-06       10-      58  2.3983e+02  3.6846e+01  2.2267e-03
    1T -5.2e-06       61-      54  3.6827e+02  3.5597e+01  4.7140e-07
    1T -9.7e-06       10-      70  2.6862e+02  3.5073e+01  4.1364e-03
    1T  7.7e-06       75-      61  2.4231e+02  3.3945e+01  4.5535e-03
    1T  7.5e-06       52-      55  2.6410e+02  3.0329e+01  2.7962e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       54-      62  2.9242e+02  3.2543e+01  4.6311e-03
    1T -9.0e-06       16-      64  2.6036e+02  3.3733e+01  4.8603e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       65-      67  1.2380e+03  3.7913e+01  3.5616e-05
    1T -7.5e-06       65-      52  5.6162e+02  3.4875e+01  5.7027e-03
    1T  2.2e-06       37-      66  2.7336e+02  3.3516e+01  5.1747e-03
    1T  6.3e-06       48-      66  2.9093e+02  3.4228e+01  4.5277e-07
    1T -8.4e-06       33-      58  6.8164e+02  3.3911e+01  1.0348e-03
    1T -7.4e-07       18-      58  3.0587e+02  3.4215e+01  7.3595e-05
    1T  3.1e-06       68-      60  2.5904e+02  3.4970e+01  1.1830e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-06       45-      53  2.6820e+02  3.4153e+01  5.0141e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.413204s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       18-      70  5.5356e+02  2.9953e+01  6.4255e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       71-      60  6.8076e+02  3.4071e+01  2.4090e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       42-      68  6.2622e+02  4.6185e+01  2.4734e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       52-      62  5.9282e+02  3.3949e+01  4.2894e-06
    1T  8.7e-06       43-      69  8.5285e+02  3.0178e+01  2.5870e-03
    1T -9.9e-07       49-      50  4.9676e+02  3.0667e+01  4.5363e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       48-      67  6.6663e+02  2.7534e+01  1.2099e-03
    1T -4.9e-06       50-      65  3.0395e+02  3.3123e+01  3.4094e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       31-      68  1.0999e+03  4.2639e+01  2.6362e-03
    1T -8.4e-06        7-      66  7.0989e+02  2.7736e+01  3.6718e-03
    1T -6.6e-06       11-      64  6.6901e+02  3.6179e+01  4.2633e-03
    1T  8.2e-06       72-      70  9.0948e+02  4.6359e+01  6.8042e-07
    1T  8.0e-06       69-      68  7.5081e+02  3.0034e+01  1.1477e-03
    1T  2.5e-06       54-      67  3.4133e+02  3.3486e+01  1.0219e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       61-      65  3.4465e+02  3.1285e+01  1.8058e-03
    1T  2.6e-06       38-      69  5.0111e+02  2.8654e+01  1.2378e-03
    1T  1.1e-07       59-      66  1.1969e+03  4.0593e+01  2.9699e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       11-      66  5.5497e+02  3.3371e+01  5.3568e-03
    1T  6.2e-06        7-      64  3.5358e+02  3.1871e+01  1.7087e-05
    1T  6.9e-07       21-      56  5.7913e+02  3.1123e+01  2.9413e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       19-      67  1.1958e+03  3.5350e+01  2.4064e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       61-      61  3.4624e+02  3.0578e+01  1.1948e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       52-      54  3.3855e+02  3.3706e+01  1.1623e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       16-      53  3.8846e+02  3.1338e+01  2.6614e-03
    1T -5.5e-06       69-      57  3.3678e+02  3.1705e+01  1.9072e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       56-      60  5.0756e+02  3.0456e+01  3.1417e-03
    1T  9.1e-06        1-      62  4.2217e+02  3.0661e+01  2.3959e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       54-      53  4.0923e+02  3.1433e+01  1.2744e-03
    1T  7.2e-06       42-      54  3.8388e+02  3.1530e+01  9.9482e-06
    1T -2.7e-06       51-      56  3.6120e+02  3.0330e+01  1.0957e-03
    1T  5.4e-06       51-      60  6.7227e+02  3.2178e+01  4.8550e-03
    1T  9.2e-06       49-      48  4.9060e+02  2.9929e+01  5.8651e-06
    1T  2.9e-06       26-      55  1.2649e+03  3.3198e+01  2.0948e-05
    1T -1.7e-07       14-      69  3.9637e+02  3.0896e+01  5.7786e-03
    1T  5.1e-06       58-      60  3.5214e+02  3.1036e+01  3.6144e-06
    1T -6.4e-06       65-      58  3.2963e+02  2.9518e+01  1.2646e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06        4-      55  4.4967e+02  2.9957e+01  3.2006e-03
    1T  9.1e-06       73-      58  1.0495e+03  3.7150e+01  2.9973e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06       58-      53  5.5209e+02  3.2838e+01  3.5908e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-07       70-      66  4.3064e+02  3.6092e+01  1.4013e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   170    30    36    41   173    95    58    32   101   103   184   173    90

  Columns 14 through 26

    40   145   133    84   146   162    44   197    74   171    58    31     7

  Columns 27 through 30

   117   145    12   117


Accuracy =

   99.7121


Accuracy =

   99.7081


Accuracy =

   99.6897


Accuracy =

   99.7101


Accuracy =

   99.7040


Accuracy =

   99.6815


Accuracy =

   99.6876


Accuracy =

   99.6978


Accuracy =

   99.7387


Accuracy =

   99.7489


Accuracy =9.974888e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.3966
   99.8812
  100.0000
   98.3386
   99.4639
  100.0000
   99.9072
   99.8823
  100.0000
   99.6964
   99.8965
  100.0000
  100.0000
   99.3808
   99.3466
  100.0000

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.6994




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        5-      54  2.1176e+02  5.3921e+01  1.6830e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       64-      58  1.2421e+02  5.2865e+01  1.4213e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       63-      63  3.5443e+02  4.6155e+01  1.7168e-06
    1T -2.8e-06       71-      51  2.7237e+02  4.9450e+01  8.6709e-05
    1T  7.2e-07       33-      51  9.0642e+02  8.3848e+01  2.8003e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       11-      57  3.0460e+02  3.9117e+01  2.6010e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       71-      51  3.4500e+02  4.5823e+01  6.7612e-04
    1T -6.8e-06       60-      54  9.0316e+02  5.0819e+01  4.7570e-03
    1T  1.9e-06       22-      63  5.4793e+02  8.2886e+01  2.5551e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       40-      58  3.1671e+02  5.7360e+01  1.5198e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       58-      49  2.9579e+02  6.2547e+01  2.9044e-03
    1T  6.8e-06       64-      59  3.2389e+02  7.8106e+01  6.0895e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       72-      59  2.4111e+02  5.7541e+01  4.0728e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        1-      66  3.0919e+02  5.0803e+01  1.5046e-03
    1T  3.7e-06        3-      37  1.6485e+02  6.1231e+01  2.6806e-07
    1T  5.4e-06       27-      51  1.7523e+02  7.8459e+01  2.2110e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       74-      64  6.6408e+02  6.5319e+01  1.8379e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.9e-06       55-      53  1.7614e+02  5.7993e+01  3.9123e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06        4-      40  1.5008e+02  5.6731e+01  9.7224e-04
    1T  2.4e-06        2-      42  1.8686e+02  6.9081e+01  2.8015e-07
    1T  2.0e-06       66-      58  5.2747e+02  7.0876e+01  3.6295e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       21-      57  7.0456e+02  6.8239e+01  8.7942e-04
    1T -3.7e-07       12-      60  1.4332e+02  5.1513e+01  1.6099e-03
    1T -3.2e-08       57-      64  1.5925e+02  6.6448e+01  4.8749e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-06       67-      50  2.3981e+02  5.8158e+01  1.9278e-03
    1T  9.6e-07       54-      57  1.3888e+02  5.1687e+01  4.8122e-07
    1T -4.7e-06       56-      57  3.0376e+02  6.7359e+01  2.3164e-03
    1T  7.0e-06        4-      50  1.5448e+02  7.3554e+01  7.0340e-06
    1T  8.5e-08        8-      56  1.6596e+02  8.1925e+01  1.5510e-08
    1T  7.8e-06       44-      45  1.6312e+02  6.0554e+01  1.1482e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       25-      52  3.0783e+02  4.0696e+01  3.2195e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       69-      53  2.7428e+02  6.1234e+01  7.7203e-04
    1T -7.4e-06       25-      56  1.6849e+02  8.9232e+01  2.3928e-03
    1T -4.4e-06       71-      49  2.0544e+02  6.5441e+01  4.9113e-07
    1T  3.8e-06        9-      57  1.3551e+02  7.3294e+01  4.4540e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       38-      40  1.5903e+02  5.8039e+01  7.9161e-07
    1T -8.0e-06       32-      60  1.8175e+02  6.4665e+01  1.2136e-03
    1T  3.3e-06       32-      56  1.9714e+02  6.7632e+01  3.7558e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       45-      55  2.5322e+02  3.4531e+01  3.2362e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-06       36-      62  1.9439e+02  3.8178e+01  4.1920e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-07        5-      60  3.9079e+02  3.6498e+01  3.8516e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       69-      54  6.7555e+02  3.6830e+01  1.5902e-03
    1T  5.9e-06       25-      60  4.2510e+02  3.3019e+01  5.9781e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        9-      60  4.6404e+02  3.6614e+01  2.1797e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       64-      65  3.7008e+02  5.5257e+01  4.0182e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       42-      61  8.7519e+02  3.8248e+01  2.2068e-06
    1T -1.9e-06       51-      62  2.4462e+02  4.1969e+01  4.5036e-03
    1T  8.1e-08       21-      57  2.6794e+02  3.4843e+01  2.4111e-08
    1T  6.2e-06       75-      58  3.4902e+02  3.6432e+01  3.3664e-05
    1T  6.1e-07       48-      53  5.0384e+02  3.5091e+01  2.6568e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       30-      63  4.5482e+02  3.8016e+01  2.7500e-03
    1T  5.3e-06       64-      63  1.9725e+02  4.1340e+01  4.0525e-03
    1T  3.0e-06       17-      53  6.0872e+02  3.4953e+01  3.9825e-06
    1T -9.0e-06       24-      47  2.4328e+02  4.3665e+01  2.8419e-04
    1T  6.4e-06       19-      52  2.7295e+02  5.0614e+01  4.5737e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       47-      44  2.8297e+02  6.0960e+01  3.6076e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       52-      55  2.6751e+02  5.5262e+01  3.2266e-06
    1T  9.2e-07        5-      47  1.9587e+02  4.5082e+01  3.6102e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       19-      61  4.9804e+02  4.2779e+01  2.8186e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       39-      59  1.2084e+03  4.8635e+01  1.9329e-06
    1T  1.6e-06       62-      49  1.8049e+02  4.7345e+01  4.7866e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06       52-      58  2.2585e+02  5.5706e+01  3.5302e-03
    1T  6.6e-06       32-      58  2.1962e+02  5.1146e+01  5.3329e-03
    1T -6.3e-06       43-      62  2.1462e+02  5.0324e+01  5.3866e-03
    1T  4.2e-06       29-      61  2.2662e+02  5.0506e+01  1.8396e-03
    1T -4.5e-06        9-      63  2.5168e+02  5.1024e+01  3.8741e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-07       17-      64  2.3933e+02  5.1477e+01  1.0596e-06
    1T  3.6e-06        7-      55  1.1104e+03  4.7685e+01  4.4314e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-08       24-      48  2.5002e+02  4.6924e+01  1.5440e-03
    1T -6.2e-06       26-      54  2.2203e+02  4.9231e+01  1.8905e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-07       38-      62  3.0402e+02  4.8116e+01  1.1600e-07
    1T  5.0e-06       24-      49  4.6343e+02  4.2758e+01  1.0041e-05
    1T  3.5e-06       45-      58  4.7327e+02  3.4367e+01  6.0812e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       38-      58  2.7954e+02  5.0747e+01  8.5633e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       45-      58  3.6236e+02  5.2820e+01  2.6426e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       51-      57  3.1932e+02  4.6543e+01  5.3250e-03
    1T -7.1e-06       61-      53  2.3673e+02  4.7720e+01  1.8329e-03
    1T  3.2e-06       69-      50  1.9059e+02  4.3994e+01  9.4277e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       40-      62  3.1071e+02  5.0920e+01  4.1756e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.316546s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       36-      60  9.3867e+02  3.0856e+01  1.8191e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       33-      71  7.8539e+02  4.2121e+01  1.3942e-07
    1T -7.5e-06       11-      64  5.7674e+02  3.3080e+01  1.1051e-03
    1T  7.4e-06       57-      60  7.0062e+02  3.0784e+01  1.6247e-05
    1T  4.6e-06       65-      68  1.3397e+03  4.0033e+01  3.5178e-03
    1T  4.4e-06       51-      62  6.0500e+02  2.7153e+01  6.4682e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       55-      57  3.7236e+02  3.9929e+01  6.2732e-06
    1T  2.3e-06       67-      44  3.4878e+02  3.3922e+01  3.6227e-04
    1T -9.5e-06       16-      49  3.5149e+02  3.2589e+01  8.0357e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       55-      45  2.8735e+02  3.5131e+01  2.0960e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06       51-      59  5.7348e+02  3.5026e+01  1.1915e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       20-      49  2.6531e+02  3.3048e+01  3.6096e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       46-      63  2.4531e+02  3.1920e+01  4.4821e-04
    1T -5.5e-06       37-      68  4.5100e+02  3.4650e+01  5.1956e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-06       16-      61  3.1898e+02  3.2471e+01  3.7400e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       28-      62  2.5332e+02  3.3449e+01  2.0517e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       38-      60  3.5795e+02  3.5280e+01  1.9961e-06
    1T  5.5e-06       19-      65  2.3998e+02  3.2649e+01  1.0499e-03
    1T -1.9e-06       65-      51  2.8015e+02  3.2111e+01  1.1264e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-07       17-      58  2.8834e+02  3.6300e+01  1.5836e-03
    1T  9.5e-07       47-      57  2.5257e+02  3.2356e+01  5.5468e-07
    1T -3.4e-06       63-      57  2.7384e+02  3.3329e+01  1.9906e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06        4-      61  2.6572e+02  3.4797e+01  6.5037e-06
    1T -6.6e-06       56-      56  3.6983e+02  3.1752e+01  2.2401e-03
    1T  2.6e-06       65-      60  2.7826e+02  3.3785e+01  6.3978e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       50-      62  4.1786e+02  3.1825e+01  3.1057e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       16-      57  2.7625e+02  3.6057e+01  1.2642e-06
    1T -7.5e-06       58-      64  3.5071e+02  3.3075e+01  8.7063e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.44967s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        6-      63  5.7131e+02  2.3880e+01  2.7870e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       42-      70  7.7910e+02  2.3898e+01  2.8221e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06        5-      65  7.7665e+02  3.0342e+01  5.2924e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       47-      71  7.6027e+02  2.4774e+01  1.3357e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       57-      64  4.9858e+02  2.8280e+01  7.4044e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        1-      66  3.1671e+03  2.4716e+01  5.4434e-03
    1T  3.1e-06       61-      70  8.1200e+02  2.4389e+01  2.0151e-07
    1T -9.9e-06       63-      68  2.4648e+03  2.6959e+01  2.5090e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.0e-07       32-      69  6.0391e+02  2.5206e+01  5.9842e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       20-      71  7.5698e+02  2.3469e+01  5.7346e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       70-      60  7.4767e+02  2.7357e+01  1.6070e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.9e-06       37-      54  3.6563e+02  2.7595e+01  3.6493e-03
    1T  2.5e-06       65-      68  4.1364e+02  2.7362e+01  2.1364e-03
    1T  5.1e-06       65-      73  9.0495e+02  4.1633e+01  4.6107e-07
    1T  4.7e-06       70-      65  4.1893e+02  2.6615e+01  4.3688e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06       22-      61  8.7061e+02  2.8614e+01  4.9805e-03
    1T  5.8e-06       65-      68  1.2510e+03  2.8825e+01  5.3167e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-06       52-      70  1.1787e+03  2.5471e+01  4.7304e-07
    1T  8.2e-06       31-      60  3.1177e+02  2.8239e+01  1.1127e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       60-      54  7.1444e+02  3.7405e+01  8.3405e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-07        3-      66  4.3673e+02  2.7205e+01  2.3426e-03
    1T -5.9e-06       44-      63  1.2034e+03  2.7730e+01  3.2893e-03
    1T  5.4e-06       41-      63  2.2092e+03  3.0230e+01  1.8985e-05
    1T -9.5e-07       67-      67  1.7883e+03  2.9890e+01  6.0820e-03
    1T -7.6e-06       42-      59  3.8311e+02  2.7660e+01  2.1958e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-07       65-      63  3.4022e+02  2.8325e+01  5.5476e-07
    1T  5.2e-07       71-      64  8.0109e+02  2.6562e+01  5.1099e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       56-      67  3.3329e+02  2.8581e+01  1.4606e-04
    1T  6.9e-07       70-      70  3.0850e+02  2.8353e+01  5.4599e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-06       50-      70  2.9459e+02  2.7681e+01  4.7400e-03
    1T  8.5e-06       49-      62  5.6792e+02  2.8805e+01  4.3539e-06
    1T -5.3e-06       37-      61  3.5664e+02  2.8563e+01  5.1468e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.3e-06       47-      58  7.8278e+02  2.7672e+01  8.4067e-04
    1T  2.4e-06       44-      68  1.4732e+03  3.0402e+01  6.2082e-03
    1T  7.2e-06       28-      70  3.5616e+02  2.7638e+01  5.0971e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-07       11-      62  8.7909e+02  2.9224e+01  6.4912e-03
    1T -4.8e-06        6-      59  6.1600e+02  2.9387e+01  3.8307e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       63-      61  3.8479e+02  2.9583e+01  2.2549e-05
    1T  7.6e-06       39-      68  3.9349e+02  2.7149e+01  2.7907e-03
    1T -6.4e-06       30-      56  4.9461e+02  2.6369e+01  2.1311e-03
    1T  1.4e-07       22-      60  3.0919e+02  2.7256e+01  9.3570e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   115    18   197    41   140    79   152     9    63   157    81    82    16

  Columns 14 through 26

    84   133   162   111    63   194    81   165   115   140   143    64    80

  Columns 27 through 30

   193    43   119   185


Accuracy =

   99.6100


Accuracy =

   99.6304


Accuracy =

   99.6243


Accuracy =

   99.6263


Accuracy =

   99.6161


Accuracy =

   99.6365


Accuracy =

   99.6774


Accuracy =

   99.6182


Accuracy =

   99.5447


Accuracy =

   99.6325


Accuracy =9.963247e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

  100.0000
  100.0000
   99.9441
   98.9748
  100.0000
   99.9162
   99.4129
   99.3429
   99.9643
   99.9326
   99.3814
  100.0000
   99.7599
   98.3437
   99.2703
   99.9387

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.6364




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       21-      61  2.9549e+02  1.8349e+02  4.0375e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-06       34-      41  2.1847e+02  5.3744e+01  2.0278e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       29-      58  2.5452e+02  1.5767e+02  1.0251e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       62-      54  4.4150e+02  1.2795e+02  5.5040e-03
    1T  6.4e-06       16-      44  1.4060e+02  1.0138e+02  1.0704e-06
    1T  6.2e-06        7-      51  1.2884e+02  5.3965e+01  1.3562e-03
    1T -8.8e-06       47-      59  2.5447e+02  5.4254e+01  1.6042e-03
    1T  5.7e-06        2-      60  2.9433e+02  6.1633e+01  3.0946e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-07       28-      52  2.6108e+02  6.7704e+01  6.9154e-03
    1T  2.5e-06       50-      48  3.5729e+02  8.1538e+01  3.6097e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-07       67-      50  1.9078e+02  6.0894e+01  5.1425e-03
    1T  3.6e-06       64-      48  3.4988e+02  6.5890e+01  9.7544e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       28-      54  1.5455e+02  8.5089e+01  2.5029e-03
    1T  7.6e-06       37-      58  1.6450e+02  6.6984e+01  3.7883e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-07       47-      48  1.7940e+02  1.5791e+02  1.8041e-07
    1T -2.8e-07       43-      43  2.0081e+02  4.7742e+01  7.5371e-04
    1T  4.2e-06       25-      52  1.8058e+02  7.0023e+01  1.1748e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       55-      54  1.4028e+02  6.6688e+01  3.6968e-04
    1T  8.8e-06       14-      60  3.7759e+02  7.7381e+01  1.7922e-03
    1T  6.1e-06       28-      54  1.8004e+02  5.4781e+01  4.1230e-05
    1T -5.8e-06       45-      48  2.6411e+02  8.8016e+01  4.5126e-03
    1T  2.2e-06       63-      49  2.2288e+02  5.6935e+01  7.4491e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       65-      51  1.5225e+02  5.8712e+01  1.9277e-03
    1T  7.8e-07       32-      50  1.7428e+02  5.3398e+01  3.5318e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       13-      55  2.3888e+02  6.6584e+01  1.1052e-06
    1T  4.6e-07       62-      45  1.6556e+02  6.7933e+01  3.6552e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       23-      59  1.5161e+02  3.7162e+02  1.6649e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       45-      26  2.7614e+02  7.3864e+01  3.3924e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-06       26-      51  4.8767e+02  4.7469e+01  8.4257e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       51-      64  5.1036e+02  3.9887e+01  5.0443e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       42-      58  4.2809e+02  3.4478e+01  2.0300e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       16-      24  4.6278e+02  7.0852e+01  5.6235e-06
    1T  1.1e-06       16-      54  5.2216e+02  3.5913e+01  8.7810e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       50-      59  6.1175e+02  3.9492e+01  2.7923e-03
    1T -5.7e-06       41-      62  3.1028e+02  4.9080e+01  8.6904e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       63-      54  4.4037e+02  3.9817e+01  1.8279e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-07       71-      59  2.5209e+02  4.4300e+01  2.5514e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       11-      53  1.9528e+02  3.2741e+01  1.6956e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       23-      68  7.4251e+02  5.3858e+01  1.4709e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       73-      47  2.7315e+02  3.8583e+01  2.8165e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       75-      64  6.2238e+02  4.3623e+01  4.6329e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       59-      47  2.1680e+02  4.2846e+01  6.9563e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       60-      62  3.3251e+02  5.4581e+01  1.3156e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       70-      65  6.6859e+02  4.5155e+01  4.2172e-03
    1T  3.5e-06        3-      59  2.0062e+02  4.4079e+01  5.7780e-06
    1T  1.2e-06        3-      58  3.9092e+02  3.4468e+01  5.8136e-07
    1T  4.7e-06       46-      59  1.8828e+02  3.8702e+01  2.0067e-03
    1T -5.2e-06       46-      61  3.5951e+02  3.6649e+01  5.5157e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       48-      56  2.4525e+02  4.8176e+01  8.5596e-06
    1T -6.4e-06       17-      47  4.0312e+02  3.8887e+01  9.6042e-03
    1T  4.7e-06       25-      64  8.4254e+02  4.3037e+01  1.5979e-05
    1T  8.8e-06       59-      56  2.4372e+02  4.4928e+01  4.8527e-06
    1T  6.1e-06       28-      65  3.5820e+02  3.5848e+01  6.8529e-03
    1T  9.5e-07       36-      57  4.0529e+02  4.3293e+01  5.9661e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       50-      59  3.0555e+02  4.1598e+01  9.6425e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       31-      52  1.8537e+02  4.2934e+01  1.4739e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       22-      43  2.9534e+02  4.0336e+01  2.7979e-03
    1T  8.2e-06       14-      48  3.5713e+02  4.0843e+01  2.0455e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       31-      59  2.1778e+02  4.1786e+01  2.4217e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.3e-06       58-      52  2.6002e+02  3.6491e+01  3.7951e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.5e-06       29-      61  2.1884e+02  3.8322e+01  5.4017e-03
    1T  4.0e-06       72-      65  2.3356e+02  4.1253e+01  5.1731e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06        4-      53  4.9656e+02  3.3590e+01  4.4367e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       70-      66  1.9731e+02  3.8640e+01  3.7346e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       36-      57  1.8631e+02  3.8293e+01  7.3050e-07
    1T -2.6e-06       53-      67  3.7249e+02  4.1619e+01  2.1905e-03
    1T  8.6e-06       14-      65  2.0869e+02  3.8299e+01  5.4378e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       13-      54  4.4176e+02  4.3595e+01  5.0224e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       25-      63  2.5451e+02  5.2743e+01  1.4008e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       46-      56  2.5565e+02  3.7805e+01  5.3122e-03
    1T  6.8e-06       25-      54  6.4937e+02  4.5054e+01  8.5317e-04
    1T  6.0e-06       29-      59  1.9420e+02  4.0237e+01  9.2098e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       12-      55  2.3972e+02  3.5811e+01  8.1067e-04
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       31-      70  6.7848e+02  2.4025e+01  8.9205e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       40-      70  7.8181e+02  3.4448e+01  4.4487e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       53-      57  1.4625e+03  2.4664e+01  6.1589e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-06        2-      69  7.0344e+02  2.2733e+01  1.4611e-03
    1T  2.7e-06       32-      68  7.8813e+02  2.2777e+01  2.1323e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06        4-      63  2.3868e+02  2.7260e+01  3.3614e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       36-      65  3.1979e+02  2.7998e+01  1.3023e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-06       61-      62  4.5040e+02  2.7728e+01  9.4956e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-07       74-      59  4.8431e+02  2.8123e+01  5.1162e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       16-      67  6.5925e+02  2.5898e+01  2.1388e-05
    1T  4.0e-06       22-      42  2.9701e+02  5.0887e+01  4.7813e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       28-      60  5.5105e+02  2.2994e+01  7.7803e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       42-      67  4.5670e+02  2.2346e+01  6.6228e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       28-      57  4.3154e+02  2.6975e+01  5.1456e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-07       74-      63  4.6985e+02  2.8358e+01  3.1545e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       48-      65  5.4189e+02  2.3468e+01  5.0930e-06
    1T  9.3e-06        4-      64  2.4466e+02  2.8143e+01  3.7508e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       21-      55  2.4624e+02  3.0701e+01  2.1266e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.0e-06       21-      57  5.4805e+02  2.8357e+01  8.1528e-03
    1T  9.1e-06       43-      71  6.0072e+02  2.6113e+01  3.5856e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       65-      60  2.6915e+02  2.9462e+01  2.2842e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       51-      55  6.9563e+02  4.2090e+01  1.8606e-06
    1T  8.4e-06       36-      63  5.9246e+02  3.0403e+01  3.8245e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       39-      55  3.5000e+02  3.1365e+01  1.6903e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       42-      66  1.0101e+03  2.4849e+01  3.7197e-03
    1T -3.4e-06       21-      59  3.9566e+02  2.9260e+01  6.5623e-03
    1T  3.8e-07       59-      64  6.1851e+02  2.3342e+01  2.2849e-06
    1T  9.3e-06       41-      59  3.2883e+02  2.8958e+01  4.8560e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       34-      59  5.5155e+02  3.2799e+01  1.3982e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       11-      68  6.3399e+02  2.2862e+01  4.3192e-03
    1T  9.5e-07       21-      72  9.8272e+02  3.7798e+01  7.7897e-08
    1T -7.2e-06       31-      63  4.0593e+02  2.7895e+01  8.8392e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       42-      67  4.6903e+02  2.2039e+01  1.3011e-03
    1T -7.9e-06       51-      55  4.2029e+02  3.2824e+01  2.9802e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       39-      62  5.3461e+02  2.6886e+01  7.1399e-03
    1T  6.3e-06       32-      69  6.1104e+02  2.4957e+01  3.7469e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       30-      71  5.1271e+02  2.5891e+01  6.2047e-03
    1T  8.5e-06       65-      59  9.2094e+02  3.3892e+01  5.7854e-06
    1T  1.4e-06       27-      55  2.5806e+02  3.4541e+01  1.6027e-06
    1T -8.4e-06        1-      69  6.0047e+02  2.5807e+01  4.6505e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-07       25-      55  2.7766e+02  3.0709e+01  4.8027e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       34-      56  6.1735e+02  5.0160e+01  4.5032e-06
    1T  7.9e-06       12-      60  3.7729e+02  3.0977e+01  6.4131e-06
    1T  3.0e-06       21-      51  2.5302e+02  3.1864e+01  1.8930e-03
    1T  2.6e-06        1-      68  3.5928e+02  3.1835e+01  4.2699e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.4e-06       48-      62  3.0724e+02  3.0642e+01  2.8393e-03
    1T  4.2e-06       23-      65  2.7916e+02  3.0872e+01  5.1154e-03
    1T  1.1e-06       12-      59  2.8862e+02  3.1604e+01  4.4991e-03
    1T  3.4e-06       44-      60  2.4174e+02  2.9876e+01  3.3779e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       21-      63  2.8250e+02  3.1635e+01  5.5649e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-07        6-      44  7.8649e+02  2.4581e+01  3.4427e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       14-      59  4.1926e+02  2.8660e+01  3.7527e-05
    1T  7.5e-06       25-      65  1.3729e+03  3.1047e+01  9.6030e-07
    1T  7.8e-06       15-      54  1.0198e+03  4.0811e+01  3.9821e-04
    1T  9.0e-06       55-      55  6.5437e+02  2.9373e+01  5.4417e-03
    1T  2.2e-06       26-      63  3.1103e+02  3.1338e+01  5.5227e-03
    1T -3.9e-06       43-      60  2.8101e+02  3.0749e+01  5.4805e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06        7-      57  3.2891e+02  2.6962e+01  4.1677e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       61-      59  8.8220e+02  3.4796e+01  2.1270e-03
    1T  4.2e-06       25-      64  3.3576e+02  2.6940e+01  4.7922e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       58-      56  3.2442e+02  2.6752e+01  1.2313e-03
    1T  7.0e-06       74-      62  3.3499e+02  2.6128e+01  5.1806e-06
    1T -2.4e-06       40-      63  5.1754e+02  2.7479e+01  4.8857e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.41144s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       58-      60  4.9757e+02  2.8132e+01  6.9356e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       39-      74  6.7834e+02  3.2083e+01  5.9593e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       39-      74  6.7834e+02  3.2083e+01  5.9593e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       39-      74  6.7834e+02  3.2083e+01  5.9593e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       39-      74  6.7834e+02  3.2083e+01  5.9593e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       39-      74  6.7834e+02  3.2083e+01  5.9593e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       41-      68  6.1655e+02  3.6917e+01  2.9640e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       75-      68  2.7233e+02  3.7644e+01  3.6567e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       39-      74  6.7834e+02  3.2083e+01  5.9593e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-06       64-      67  1.9454e+03  3.8103e+01  3.9540e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       33-      69  9.0043e+02  3.1386e+01  1.9070e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-07       54-      53  4.6770e+02  3.3808e+01  7.8008e-08
    1T -1.2e-06       11-      70  6.9206e+02  3.0578e+01  5.0022e-03
    1T  1.6e-06        5-      70  7.1584e+02  3.1387e+01  4.2656e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-07        4-      61  1.3382e+03  3.6888e+01  1.3932e-07
    1T  4.6e-06        3-      59  7.0129e+02  3.5938e+01  4.2106e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       22-      66  8.2919e+02  2.9620e+01  4.3571e-03
    1T  7.5e-06        5-      48  4.5016e+02  3.9988e+01  3.2969e-03
    1T  4.1e-06       64-      53  4.8126e+02  3.6386e+01  4.1976e-03
    1T  3.1e-06       33-      52  7.2968e+02  5.3849e+01  8.7466e-06
    1T -6.5e-06       31-      60  9.6420e+02  3.2919e+01  8.5924e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06       33-      68  5.4359e+02  3.1110e+01  4.3172e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.3e-08       10-      62  4.8347e+02  3.5932e+01  4.5718e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.3e-06        3-      59  3.1988e+02  3.7639e+01  2.4555e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-07        8-      63  3.7287e+02  4.1269e+01  4.7275e-03
    1T -4.4e-06       66-      61  3.1252e+02  3.7798e+01  5.3392e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       56-      67  3.3684e+02  3.9006e+01  1.3546e-03
    1T -1.4e-06       63-      55  3.2323e+02  4.1723e+01  4.6663e-03
    1T -7.7e-06       56-      61  2.8829e+02  3.8606e+01  1.1156e-03
    1T  6.3e-06       10-      69  3.0464e+02  3.9086e+01  1.7191e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.6e-06       49-      60  2.9812e+02  3.5403e+01  5.6930e-03
    1T  3.0e-06       65-      60  4.1437e+02  4.5698e+01  1.0062e-05
    1T  9.5e-06       31-      61  4.0646e+02  3.3648e+01  1.3925e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       41-      54  4.3645e+02  2.9794e+01  3.7187e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    32   129   180    57    65   169   151   140   179    73     1    44    45

  Columns 14 through 26

   181   100    42   149   133    54    68   132    96   178   199   132    23

  Columns 27 through 30

   197    80    40   106


Accuracy =

   99.6775


Accuracy =

   99.6918


Accuracy =

   99.6224


Accuracy =

   99.6897


Accuracy =

   99.6714


Accuracy =

   99.7142


Accuracy =

   99.6754


Accuracy =

   99.6571


Accuracy =

   99.7204


Accuracy =

   99.6489


Accuracy =9.964891e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.9450
   99.6150
  100.0000
   99.6838
   99.2158
  100.0000
   99.8149
   99.5777
  100.0000
   99.9325
   99.3789
   99.9428
   99.7599
  100.0000
   98.9049
   99.8167

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.7243




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save('Dictionary','dictionary');

else
   load('Dictionary');
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       43-      63  4.8245e+02  1.1432e+02  5.7623e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       37-      40  1.5931e+02  3.8032e+02  8.5195e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       70-      53  6.3221e+02  9.0172e+01  3.9731e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       12-      45  1.5577e+02  1.0117e+02  3.1939e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       34-      58  3.6547e+02  6.4225e+01  5.3955e-06
    1T  1.9e-06       68-      49  2.1230e+02  6.1794e+01  1.3936e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       44-      59  1.8892e+02  5.8850e+01  6.0089e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.7e-06       68-      59  3.4366e+02  1.1377e+02  5.2550e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       69-      55  1.6279e+02  5.7567e+01  4.9747e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-07       53-      53  1.2331e+02  5.6097e+01  8.1209e-08
    1T  3.1e-06       22-      57  1.0012e+03  1.3922e+02  2.5703e-06
    1T  9.9e-06       26-      43  3.3134e+02  1.0894e+02  1.1263e-02
    1T  7.4e-06       34-      52  1.4552e+02  8.3931e+01  3.8641e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       26-      49  2.5904e+02  7.5496e+01  1.1255e-02

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       43-      53  3.3648e+02  6.9958e+01  1.0253e-03
    1T  8.0e-06       60-      53  1.7487e+02  9.1501e+01  1.4373e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       59-      54  3.5422e+02  7.8222e+01  1.2667e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       58-      63  1.3559e+02  7.2909e+01  2.8777e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       36-      51  1.5137e+02  5.8082e+01  2.5470e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       10-      46  1.9006e+02  6.9431e+01  4.5188e-03
    1T -2.8e-06       59-      52  1.6972e+02  8.1873e+01  2.1208e-07
    1T -6.4e-06       62-      50  1.5796e+02  6.6850e+01  3.7203e-03
    1T  9.7e-06       44-      54  1.9909e+02  7.0531e+01  4.2467e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06        9-      40  2.3429e+02  8.0371e+01  5.3835e-07
    1T  9.2e-06       30-      49  1.6904e+02  6.6879e+01  8.4385e-04
    1T  3.9e-06       47-      59  1.5375e+02  9.1349e+01  1.5524e-06
    1T  5.5e-07       43-      45  1.8509e+02  8.9625e+01  4.1823e-03
    1T -2.9e-06       32-      46  1.5130e+02  5.2500e+01  3.4690e-03
    1T  8.7e-06       11-      56  1.7070e+02  1.4239e+02  2.8639e-06
    1T  1.7e-06       20-      53  1.5086e+02  8.3037e+01  4.0085e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       58-      51  1.5753e+02  9.3357e+01  3.9151e-08
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       40-      38  2.4612e+02  8.3069e+01  2.4516e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-07       74-      53  2.2421e+03  4.8508e+01  6.7335e-07
    1T -7.7e-06       51-      51  2.0885e+02  3.5715e+01  3.1401e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-06       50-      61  5.4582e+02  3.1377e+01  7.3167e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-08       43-      68  4.3799e+02  3.5569e+01  1.1775e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       14-      58  3.6976e+02  4.9498e+01  2.9822e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       61-      63  3.3032e+02  3.4622e+01  5.5137e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       74-      62  8.3498e+02  4.1457e+01  6.0013e-06
    1T -2.0e-06       55-      67  4.1327e+02  3.5737e+01  3.7879e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       38-      50  2.9831e+02  3.5356e+01  3.1522e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.9e-06       12-      54  1.0798e+03  5.8114e+01  1.9065e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.2e-06       31-      63  2.1620e+02  4.0929e+01  4.6560e-03
    1T -2.1e-06       41-      58  8.3420e+02  3.8007e+01  1.9581e-03
    1T  7.6e-07       36-      66  3.7696e+02  3.3679e+01  5.2649e-03
    1T  6.1e-06       20-      52  4.6506e+02  3.2028e+01  7.9407e-03
    1T  4.4e-06       18-      65  5.5513e+02  3.3560e+01  6.6928e-03
    1T  2.3e-06       66-      68  4.4587e+02  3.4208e+01  1.6564e-07
    1T  1.0e-05       26-      61  1.8498e+02  3.7253e+01  5.3727e-04
    1T  4.2e-06       38-      54  4.9660e+02  2.9767e+01  3.9068e-03
    1T -1.7e-06       74-      56  8.7719e+02  3.4219e+01  5.5119e-03
    1T  1.3e-06       43-      67  5.0378e+02  3.4238e+01  5.7212e-07
    1T  4.4e-06       32-      50  3.5822e+02  3.5021e+01  3.8121e-06
    1T  2.2e-06       50-      60  2.0373e+02  3.7157e+01  1.6879e-06
    1T  7.7e-06       39-      67  3.1645e+02  5.2667e+01  5.3610e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.4e-06       43-      66  5.4421e+02  3.2362e+01  1.4486e-03
    1T  8.3e-06       72-      52  2.6715e+02  4.6032e+01  5.3473e-06
    1T -9.1e-06       19-      50  3.7434e+02  4.0955e+01  5.5439e-03
    1T  8.8e-06       20-      60  3.1936e+02  4.1958e+01  1.0969e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       27-      55  4.1427e+02  6.1704e+01  5.9941e-03
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       72-      49  4.9647e+02  3.9504e+01  5.2934e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       46-      58  1.8997e+02  3.7860e+01  2.8318e-03
    1T  1.7e-07       72-      60  2.2216e+02  3.7505e+01  2.4611e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       49-      62  2.1810e+02  3.7508e+01  2.6013e-03
    1T  2.9e-06       61-      66  1.9575e+02  3.9841e+01  2.4669e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       53-      58  2.0763e+02  3.6181e+01  1.3377e-03
    1T  9.6e-06       57-      59  2.3090e+02  3.7639e+01  4.1634e-03
    1T  7.3e-07       55-      61  1.2121e+03  4.5254e+01  4.1925e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-06       31-      57  2.1410e+02  4.1692e+01  5.5810e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.6e-07       41-      51  2.5451e+02  3.5000e+01  7.4088e-04
    1T -6.8e-06       28-      51  2.4401e+02  4.4353e+01  5.5420e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       40-      56  2.2393e+02  4.4441e+01  5.8011e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        1-      51  2.7193e+02  4.2532e+01  1.4366e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T  2.5e-06       58-      50  2.4484e+02  4.0278e+01  2.1020e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T  2.2e-06       27-      61  2.5569e+02  3.9614e+01  3.3825e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06        8-      50  3.6624e+02  3.1477e+01  7.7246e-03
    1T  9.0e-06       63-      59  2.5140e+02  4.2928e+01  9.3516e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       53-      55  2.1076e+02  4.3230e+01  4.2355e-03
    1T -9.9e-06        8-      55  3.2381e+02  3.9830e+01  9.0109e-07
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       66-      66  2.2729e+02  3.3083e+01  3.9741e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       66-      66  2.2729e+02  3.3083e+01  3.9741e-03
    1T  7.2e-06       66-      66  2.2729e+02  3.3083e+01  3.9741e-03
    1T  7.2e-06       66-      66  2.2729e+02  3.3083e+01  3.9741e-03
    1T  7.2e-06       66-      66  2.2729e+02  3.3083e+01  3.9741e-03
    1T -9.2e-06        7-      54  5.3865e+02  2.7294e+01  7.2926e-03
    1T  2.0e-06       29-      56  4.3505e+02  3.0562e+01  2.9052e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06        7-      58  3.0039e+02  2.6328e+01  4.7859e-06
    1T  1.5e-06       49-      53  6.4612e+02  3.0380e+01  9.5103e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-06       12-      56  6.1528e+02  2.7727e+01  4.5556e-03
    1T  7.8e-06       31-      72  5.4515e+02  2.9099e+01  4.8463e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-07       58-      66  6.9796e+02  3.0968e+01  1.3509e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.0e-06       55-      59  3.9527e+02  2.8391e+01  7.9035e-03
    1T -9.2e-06       27-      63  6.2080e+02  2.9274e+01  2.7697e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       66-      56  6.9912e+02  4.6525e+01  2.2453e-03
    1T  2.5e-06        6-      60  5.3394e+02  2.9317e+01  3.2425e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       51-      67  5.7147e+02  2.8663e+01  3.2931e-03
    1T  5.3e-06       71-      60  3.8687e+02  3.0787e+01  2.2208e-06
    1T -7.5e-06       68-      62  1.0803e+03  3.1680e+01  8.0731e-03
    1T  1.2e-06       55-      59  4.1183e+02  2.7400e+01  5.2383e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       18-      56  3.3877e+02  4.3674e+01  8.3533e-06
    1T  1.7e-06       20-      56  2.6583e+02  3.5525e+01  3.7160e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       43-      62  1.0463e+03  3.9145e+01  2.9747e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       60-      56  2.6575e+02  3.4304e+01  2.2408e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       11-      58  1.9877e+03  3.3699e+01  1.0513e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       55-      67  3.0233e+02  3.6513e+01  4.8435e-07
    1T -3.9e-06       16-      57  2.9240e+02  3.7391e+01  5.2532e-03
    1T  3.6e-06       52-      58  1.2545e+03  4.2705e+01  1.9262e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       28-      57  4.0313e+02  3.4670e+01  4.7367e-03
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       75-      59  3.3530e+02  3.3496e+01  2.3299e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       33-      62  1.0729e+03  3.6935e+01  7.8567e-07
    1T  9.2e-06       70-      59  2.6756e+02  3.5010e+01  2.5567e-03
    1T -6.4e-06       26-      67  2.5845e+02  3.6228e+01  3.8216e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       27-      61  3.1453e+02  3.2337e+01  3.9890e-03
    1T  2.8e-06       75-      59  3.1430e+02  3.6322e+01  1.4969e-06
    1T  2.9e-06       50-      55  5.6855e+02  3.2852e+01  5.1122e-03
    1T  6.4e-06       12-      66  3.4455e+02  3.6373e+01  1.0883e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06        1-      53  3.1313e+02  3.5171e+01  4.6842e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [224x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.437752s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       35-      64  4.3183e+02  2.8247e+01  1.7086e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       54-      66  6.7709e+02  2.8312e+01  4.6273e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       16-      67  7.0013e+02  2.8290e+01  9.3783e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-06       51-      69  6.9919e+02  2.8071e+01  3.9714e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       10-      72  8.3244e+02  4.7595e+01  3.1005e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        1-      71  1.6829e+03  4.2704e+01  7.7304e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       55-      59  8.8601e+02  3.5156e+01  5.1320e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       13-      71  8.3291e+02  4.7896e+01  3.3524e-07
    1T -7.1e-06       54-      65  6.7993e+02  2.7707e+01  5.9739e-03
    1T  5.5e-06       23-      65  1.3672e+03  2.9985e+01  7.4540e-07
    1T  8.4e-06       29-      70  6.7259e+02  2.8213e+01  3.0755e-03
    1T -6.6e-06       43-      70  3.0970e+03  4.1332e+01  7.2541e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       45-      60  5.2613e+02  2.9583e+01  3.2344e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       71-      69  6.8614e+02  4.3277e+01  3.8054e-06
    1T  7.2e-06       58-      55  7.1154e+02  3.2423e+01  5.8471e-06
    1T  3.1e-06       60-      65  7.6512e+02  2.8568e+01  7.6654e-05
    1T  1.7e-06       71-      63  6.9432e+02  3.6100e+01  5.6896e-07
    1T  7.4e-06        7-      69  6.9325e+02  2.8535e+01  1.1640e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       57-      65  8.5872e+02  3.4061e+01  7.5400e-06
    1T  1.3e-07        5-      68  2.1079e+03  2.9695e+01  1.0530e-08
    1T  2.4e-06       11-      44  4.3050e+02  3.1570e+01  1.1296e-03
    1T -3.6e-06       63-      62  3.1027e+02  3.3226e+01  3.3062e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       28-      52  1.2800e+03  4.1044e+01  4.6681e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       57-      60  3.2125e+02  3.3973e+01  3.5362e-06
    1T  1.0e-05       69-      57  5.0245e+02  3.3956e+01  1.2105e-04
    1T -6.5e-06       22-      65  1.0716e+03  3.4959e+01  9.3012e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       55-      55  1.3677e+03  3.9546e+01  3.7141e-03
    1T  6.6e-06       42-      65  5.4265e+02  3.0528e+01  5.4237e-06
    1T -7.4e-06       63-      67  3.3268e+02  3.2045e+01  4.3880e-03
    1T  3.7e-06       58-      59  3.0297e+02  3.5528e+01  2.3978e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       18-      62  1.6857e+03  3.6984e+01  3.3783e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-07       74-      60  1.0010e+03  3.4002e+01  1.1344e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-08       30-      58  5.0994e+02  3.0840e+01  1.4973e-08
    1T  4.3e-06       38-      50  5.2087e+03  5.0484e+01  7.7682e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       55-      59  3.3468e+02  3.2535e+01  4.5402e-07
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       25-      72  3.4480e+02  3.2834e+01  4.7934e-03
    1T  3.0e-06        9-      61  7.2842e+02  3.3112e+01  1.4021e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       16-      54  5.1146e+02  3.1250e+01  1.1732e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T  1.8e-06       66-      66  1.6528e+03  3.6191e+01  3.8691e-03
    1T  2.6e-06       24-      57  4.3263e+02  3.5566e+01  2.6384e-03
    1T -7.9e-06       72-      64  3.3318e+02  3.3295e+01  3.5497e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-06       25-      67  1.2131e+03  2.8383e+01  1.8616e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06        5-      52  4.0581e+02  2.9198e+01  4.9396e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06       55-      60  3.2988e+02  3.2658e+01  4.0509e-03
    1T -9.3e-06       13-      63  3.6299e+02  3.3100e+01  3.0146e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T -5.1e-06        7-      61  6.2200e+02  3.2631e+01  4.7950e-03
    1T  7.3e-06       28-      68  1.0241e+03  2.7864e+01  4.0507e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    44    87   152   109   187    60    44   174   139   152   102   178    98

  Columns 14 through 26

    82   177   145    36   137   190    61   151    67   151   172   157   172

  Columns 27 through 30

    90    72   175   189


Accuracy =

   99.5183


Accuracy =

   99.6245


Accuracy =

   99.4632


Accuracy =

   99.5163


Accuracy =

   99.4816


Accuracy =

   99.5346


Accuracy =

   99.4795


Accuracy =

   99.4346


Accuracy =

   99.5183


Accuracy =

   99.5061


Accuracy =9.950607e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.8897
  100.0000
  100.0000
   98.5771
   98.1443
  100.0000
   99.7535
   99.3923
   99.9643
   99.2585
  100.0000
  100.0000
   99.7587
   99.2754
   99.0875
   99.1469

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.5155




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=1;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       16-      58  1.5326e+02  5.6612e+01  8.9030e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       54-      55  3.1926e+02  3.7995e+01  6.2735e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-07       75-      59  3.8747e+02  5.1128e+01  5.0569e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       20-      61  4.0533e+02  8.0019e+01  3.6546e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       58-      58  3.8860e+02  4.4403e+01  1.4802e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       68-      60  2.0871e+02  5.6875e+01  4.7391e-03
    1T -5.6e-08       12-      53  2.2456e+02  4.3670e+01  2.5887e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       45-      46  3.9699e+02  9.1167e+01  5.6954e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-07       59-      55  2.6062e+02  4.1302e+01  6.1512e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       45-      45  2.3155e+02  8.8145e+01  5.9474e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       57-      56  2.8879e+02  6.2011e+01  2.7919e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       50-      56  2.4009e+02  6.3286e+01  7.9049e-06
    1T -9.6e-06       30-      50  1.2283e+02  3.7235e+01  1.9495e-03
    1T  7.9e-06       58-      45  1.5743e+02  6.1676e+01  5.0318e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-07       35-      56  3.0266e+02  4.5229e+01  5.0365e-04
    1T  7.4e-06       61-      57  3.4282e+02  4.3047e+01  5.9926e-03
    1T  2.7e-06       67-      60  3.2239e+02  6.2247e+01  9.8227e-08
    1T -9.8e-06       43-      48  1.6461e+02  6.2128e+01  1.2998e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       57-      54  9.1548e+02  5.2323e+01  5.8108e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       11-      51  1.7451e+02  7.3931e+01  1.0265e-06
    1T -2.5e-06       63-      57  4.7865e+02  6.1685e+01  4.3410e-03
    1T  7.1e-06       38-      60  2.7103e+02  5.0858e+01  2.3485e-03
    1T -9.6e-06       39-      47  3.5021e+02  4.6440e+01  3.5280e-03
    1T -3.4e-06       17-      57  4.1566e+02  5.7761e+01  3.8325e-03
    1T  1.1e-06       31-      59  2.3314e+02  6.3401e+01  1.3222e-06
    1T -4.5e-06       14-      61  7.0399e+02  6.5445e+01  3.5789e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       53-      55  2.2213e+02  7.2815e+01  2.2719e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       52-      57  1.2590e+02  5.8037e+01  3.1075e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.7e-06       68-      61  1.1457e+02  5.2532e+01  5.9710e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-07       53-      54  1.7482e+02  7.2196e+01  5.7883e-07
    1T  5.4e-08       63-      58  1.4532e+02  6.5506e+01  1.6997e-03
    1T  1.0e-05       52-      47  2.4031e+02  5.5816e+01  4.0218e-03
    1T  6.5e-06       63-      63  1.2658e+02  5.5522e+01  2.5245e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       27-      54  1.5794e+02  5.6223e+01  4.5016e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-08       21-      57  1.0113e+02  6.6862e+01  4.0226e-03
    1T  9.6e-06       39-      56  6.5193e+02  6.0376e+01  7.5380e-06
    1T  1.9e-06        2-      55  2.7848e+02  7.7314e+01  3.2917e-07
    1T -8.7e-06       20-      55  1.1553e+02  6.1553e+01  4.5236e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       21-      49  1.1731e+02  5.7956e+01  2.5681e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-06       68-      46  1.2238e+02  5.9827e+01  4.0928e-03
    1T  1.5e-06       12-      52  2.0451e+02  6.6883e+01  3.7521e-03
    1T  6.2e-06       22-      48  1.4443e+02  6.5152e+01  1.0750e-03
    1T  2.1e-06       45-      58  1.4517e+02  4.7020e+01  6.5741e-07
    1T -1.3e-06        2-      56  1.2959e+02  7.7521e+01  5.0342e-03
    1T  6.2e-06       22-      48  1.4443e+02  6.5152e+01  1.0750e-03
    1T  6.2e-06       22-      48  1.4443e+02  6.5152e+01  1.0750e-03
    1T -9.3e-06       43-      46  1.2758e+02  5.4872e+01  4.8618e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       22-      48  1.4443e+02  6.5152e+01  1.0750e-03
    1T  6.2e-06       22-      48  1.4443e+02  6.5152e+01  1.0750e-03
    1T  6.2e-06       22-      48  1.4443e+02  6.5152e+01  1.0750e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       70-      60  4.7534e+02  3.3700e+01  1.4895e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       17-      58  4.6731e+02  3.7497e+01  3.0006e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       67-      59  4.3982e+02  2.9218e+01  3.6609e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       25-      43  2.2513e+02  3.7611e+01  2.1673e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       63-      56  1.3970e+02  3.3495e+01  2.1286e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.6e-06       63-      61  4.7587e+02  5.1830e+01  5.2217e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-07       61-      65  5.1448e+02  3.3695e+01  4.3191e-08
    1T  4.6e-06       60-      67  3.8441e+02  2.9077e+01  2.9846e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       44-      57  4.4109e+02  3.5356e+01  3.9382e-03
    1T  9.8e-06        1-      52  1.8122e+02  3.2815e+01  1.3667e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06        9-      55  3.6913e+02  3.4769e+01  4.8574e-06
    1T -8.8e-06        7-      60  1.9504e+02  3.8781e+01  4.8674e-07
    1T -9.5e-06       64-      55  4.2707e+02  3.7264e+01  2.1973e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       21-      60  3.0953e+02  3.0884e+01  1.2023e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       69-      63  3.4531e+02  3.9814e+01  9.4132e-03
    1T  8.5e-06       27-      60  4.3942e+02  3.5372e+01  3.2302e-06
    1T  4.6e-06       38-      61  5.0644e+02  3.4646e+01  8.3756e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.7e-06       70-      56  1.6544e+02  3.8053e+01  7.7408e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06        9-      58  1.1724e+03  5.3429e+01  4.7814e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       38-      51  2.0886e+02  3.6025e+01  3.5180e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       51-      62  2.0726e+02  3.7289e+01  1.1089e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06        5-      53  2.7377e+02  3.5769e+01  6.2391e-07
    1T -2.8e-06       25-      54  2.0819e+02  3.4116e+01  3.5481e-03
    1T  4.3e-06       17-      67  1.9606e+02  3.9130e+01  1.5003e-06
    1T  2.1e-06       51-      61  1.7850e+02  3.7480e+01  9.6549e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       66-      58  1.7293e+02  3.7324e+01  3.4162e-03
    1T -9.0e-06       72-      55  1.8780e+02  3.6925e+01  3.4607e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       50-      58  1.5737e+02  3.7197e+01  1.8547e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       72-      60  3.7260e+02  4.0090e+01  9.8870e-06
    1T  3.8e-06       57-      54  4.9443e+02  3.4567e+01  4.9015e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       30-      61  4.2559e+02  3.8204e+01  2.1344e-06
    1T  5.4e-06       38-      56  2.4738e+02  3.6857e+01  4.4354e-03
    1T  3.7e-06       54-      58  1.6140e+02  4.6659e+01  6.2598e-05
    1T -3.3e-06       52-      65  2.5470e+02  3.8585e+01  1.7800e-03
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-06       37-      40  2.1056e+02  3.4788e+01  4.3315e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-06       75-      53  1.8692e+02  3.4603e+01  3.0444e-03
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06
    1T  3.1e-06       53-      55  2.2674e+02  3.6670e+01  8.1339e-06
    1T -9.0e-06       23-      67  1.9912e+02  3.8105e+01  1.9676e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       24-      62  2.5617e+02  3.3611e+01  2.7957e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       15-      65  6.8933e+02  4.1643e+01  5.7530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       15-      65  6.8933e+02  4.1643e+01  5.7530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       15-      65  6.8933e+02  4.1643e+01  5.7530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       15-      65  6.8933e+02  4.1643e+01  5.7530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       58-      63  1.9583e+02  3.5272e+01  6.8523e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        2-      69  9.8689e+02  4.6653e+01  3.2839e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.4e-06       54-      62  2.9813e+02  3.2943e+01  5.5940e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       15-      65  6.8933e+02  4.1643e+01  5.7530e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       10-      65  6.5116e+02  3.2084e+01  5.9056e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       15-      61  1.7278e+03  2.8716e+01  6.9158e-07
    1T  2.0e-06       39-      67  6.3710e+02  2.9236e+01  6.2468e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.1e-06       75-      71  7.9112e+02  4.4959e+01  4.4463e-07
    1T  8.0e-06       69-      68  6.0642e+02  2.8904e+01  5.5427e-07
    1T  5.2e-06       58-      62  2.0185e+02  3.4638e+01  2.4577e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06       13-      63  5.6638e+02  2.9647e+01  3.8583e-03
    1T -5.2e-07       38-      59  2.3667e+02  3.1238e+01  3.8014e-03
    1T  6.0e-06       19-      68  8.1002e+02  2.8883e+01  1.1472e-05
    1T  2.1e-06       56-      55  2.6478e+03  3.9093e+01  9.0550e-06
    1T  2.4e-06       51-      57  4.8770e+02  3.5954e+01  5.2099e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       59-      66  5.5157e+02  2.7752e+01  1.9660e-03
    1T  1.0e-06       16-      68  4.0470e+02  2.9088e+01  5.6332e-08
    1T  9.3e-06       37-      46  4.1332e+02  4.4361e+01  8.7789e-07
    1T -9.4e-06       31-      68  6.4672e+02  3.5224e+01  8.6640e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.5e-07       72-      65  4.7281e+02  3.1372e+01  9.9097e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       68-      60  4.3151e+02  3.0776e+01  7.7742e-03
    1T  8.2e-06        4-      56  8.6937e+02  5.3181e+01  1.5237e-05
    1T -9.1e-06       14-      60  4.5986e+02  3.0799e+01  6.9042e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       38-      61  8.3402e+02  4.0255e+01  3.2893e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       48-      61  2.4139e+02  3.6814e+01  2.1382e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       40-      51  4.3823e+02  6.4649e+01  2.1986e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.8e-06       48-      69  4.1754e+02  3.5721e+01  4.7334e-03
    1T  3.1e-07       17-      67  2.3262e+02  3.3565e+01  1.5750e-06
    1T  4.5e-06       48-      53  4.5764e+02  3.3791e+01  7.0052e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       18-      66  2.0205e+02  3.5105e+01  1.2666e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.8e-07        5-      61  2.2091e+02  3.5078e+01  3.4781e-08
    1T -5.2e-06       31-      65  2.4090e+02  3.8943e+01  3.7302e-03
    1T  8.2e-06       68-      60  2.2084e+02  3.4274e+01  3.7598e-06
    1T  5.0e-06       46-      69  1.8391e+02  3.6576e+01  4.9418e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       68-      60  2.7597e+02  3.4130e+01  2.8621e-07
    1T  2.7e-06        5-      57  2.5364e+02  3.8786e+01  1.0129e-06
    1T  1.7e-06       14-      57  2.0494e+02  3.4764e+01  3.5970e-03
    1T -3.0e-06       10-      70  2.0837e+02  3.5692e+01  2.6887e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       69-      69  8.0340e+02  3.6584e+01  3.9755e-07
    1T -7.4e-06       65-      58  2.2205e+02  3.4990e+01  2.8223e-03
    1T  4.1e-06       45-      64  2.5960e+02  3.8575e+01  1.2784e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       17-      63  6.5646e+02  4.0378e+01  5.3513e-06
    1T  6.2e-06       62-      55  2.7925e+02  3.6735e+01  3.1191e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.429429s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06       66-      62  1.1907e+03  3.1450e+01  3.2995e-03
    1T  4.9e-06       17-      21  6.5225e+02  4.0657e+01  2.1925e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       62-      71  7.5181e+02  3.1071e+01  6.2607e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       18-      59  3.0754e+02  2.9724e+01  3.8184e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       55-      68  9.3146e+02  3.1666e+01  4.5551e-04
    1T  9.7e-06       66-      62  2.4539e+02  3.4862e+01  3.3510e-06
    1T -7.2e-06       58-      68  7.1196e+02  3.1127e+01  2.4080e-03
    1T  2.8e-06       19-      69  6.1029e+02  3.2600e+01  1.7275e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-07       48-      62  4.6004e+02  3.8849e+01  1.8545e-03
    1T  4.1e-06       14-      62  6.4646e+02  3.4915e+01  5.3042e-03
    1T  7.4e-06       60-      63  3.6379e+02  3.8392e+01  1.1149e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       14-      60  2.6329e+02  3.0960e+01  2.7272e-03
    1T  6.1e-06        1-      62  6.5660e+02  3.4716e+01  3.6733e-03
    1T  6.9e-06       49-      67  5.4994e+02  3.6557e+01  4.0285e-03
    1T -8.0e-06       39-      50  6.8387e+02  5.6438e+01  6.4509e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       51-      59  4.7697e+02  3.3941e+01  5.4885e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       69-      56  3.2439e+02  4.0156e+01  1.6622e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       16-      57  3.1035e+02  4.0373e+01  2.7381e-06
    1T -4.1e-06       13-      56  2.6034e+02  4.3570e+01  6.6555e-04
    1T -2.5e-06       74-      61  3.1922e+02  4.0197e+01  2.2685e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.5e-08       23-      55  3.3042e+02  3.9562e+01  4.4360e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.4e-06       70-      71  3.3170e+02  3.8263e+01  4.3299e-04
    1T  8.4e-06       25-      59  2.5206e+02  4.0760e+01  2.0860e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.1e-06       35-      58  2.6692e+02  3.9530e+01  4.5840e-03
    1T -8.1e-06       51-      55  2.3409e+02  3.8861e+01  3.2202e-03
    1T  4.6e-06       75-      57  3.7525e+02  3.9045e+01  3.5810e-03
    1T -8.1e-07       25-      56  3.5955e+02  3.9622e+01  4.8770e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-07       52-      64  4.4829e+02  3.6210e+01  4.6618e-03
    1T -8.1e-06       54-      55  6.8427e+02  4.0330e+01  2.6661e-03
    1T  9.8e-06       19-      57  2.8333e+02  3.8225e+01  6.6178e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       10-      52  3.7758e+02  3.5363e+01  2.1795e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   137   186   183   118    80   145    46    65    84    85    36    44   148

  Columns 14 through 26

   135   163   150    38    67    11     2     6   118    66    40   140    47

  Columns 27 through 30

   138   176   173     3


Accuracy =

   99.5979


Accuracy =

   99.5509


Accuracy =

   99.6121


Accuracy =

   99.5877


Accuracy =

   99.5652


Accuracy =

   99.5856


Accuracy =

   99.5897


Accuracy =

   99.5591


Accuracy =

   99.6407


Accuracy =

   99.5101


Accuracy =9.951008e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.2303
  100.0000
   99.9440
   99.1270
   99.4633
   99.9721
   99.9075
   99.2842
  100.0000
   99.5278
   99.8963
  100.0000
   99.5175
   99.6901
   98.4506
  100.0000

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   99.6257




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true

Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       48-       9  6.4447e+03  4.3638e+02  1.5142e-05
    1T  8.1e-06       17-      10  6.3988e+03  4.2775e+02  2.9908e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06        3-      13  7.4983e+03  1.1638e+02  7.0321e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       60-      22  8.9517e+03  6.2242e+02  1.6886e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    80    11   177    45   130    36   190   177   121    82    71   180   197

  Columns 14 through 26

   148     6    63    95    88     8   151   195   100     4    56   163    90

  Columns 27 through 30

    98   141   126    48

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   58.5442


Accuracy =

   58.9103


Accuracy =

   57.4136


Accuracy =

   58.0274


Accuracy =

   57.7474


Accuracy =

   57.3274


Accuracy =

   57.8551


Accuracy =

   58.3504


Accuracy =

   57.5105


Accuracy =

   57.7797


Accuracy =5.777969e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

    9.5238
   46.5278
   45.2855
   19.8157
   67.2018
   71.7523
   46.1538
   75.6944
   33.3333
   42.5968
   63.2148
   40.9683
   55.3763
   83.2898
   44.4126
   57.6471

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   50.1746




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=0;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true

Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       17-      10  6.3988e+03  4.2775e+02  2.9908e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       48-       9  6.4447e+03  4.3638e+02  1.5142e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.3e-06        3-      13  7.4983e+03  1.1638e+02  7.0321e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       60-      22  8.9517e+03  6.2242e+02  1.6886e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   189   147    69   156    43   130   182    74   129   155     5   176   108

  Columns 14 through 26

   172    24    56    76   106    32    96     9    90   200   113    42    22

  Columns 27 through 30

    70   135   192   182

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   57.3213


Accuracy =

   57.7519


Accuracy =

   56.9121


Accuracy =

   58.4625


Accuracy =

   57.9350


Accuracy =

   58.2041


Accuracy =

   58.3872


Accuracy =

   58.3010


Accuracy =

   58.0642


Accuracy =

   57.9242


Accuracy =5.792420e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

    2.3810
   53.3643
   43.8247
   21.2963
   65.5172
   67.1212
   42.3077
   90.2778
         0
   43.9909
   60.2604
   41.7132
   42.1622
   81.9214
   47.0255
   57.1429

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   47.5192




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines');

load('Indian_pines_gt');
image=indian_pines;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   220


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       32-      71  2.2867e+03  6.5497e+01  2.5946e-06
    1T  1.3e-07       13-      64  1.0685e+03  6.5659e+01  1.4666e-06
    1T  9.5e-06       11-      72  1.8805e+03  6.6680e+01  2.4510e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       48-      62  1.2198e+03  5.4882e+01  8.0917e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-07       14-      64  1.3005e+03  5.7299e+01  1.1383e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.4e-06       53-      70  1.9832e+03  4.7623e+01  1.4431e-05
    1T  7.9e-06       27-      74  3.6037e+03  5.6132e+01  9.0529e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.7e-06       37-      65  1.8977e+03  4.6649e+01  1.3412e-05
    1T -7.0e-06       26-      70  2.0718e+03  5.5168e+01  4.0422e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       21-      70  3.5768e+03  6.0327e+01  6.9539e-06
    1T  8.6e-06       68-      72  3.2952e+03  6.0835e+01  1.7366e-05
    1T -8.0e-06       34-      62  2.0486e+03  5.6087e+01  8.2774e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [220x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
[Warning: It is recommended to format this tensor with fmt (conversion took
0.436509s).] 
[> In fmt (line 211)
  In sdf_core (line 161)
  In sdf_nls (line 145)
  In FactorizeTensor (line 18)] 
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true

Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    84    62     6   114   190   111    15    82    29   185   118   132   185

  Columns 14 through 26

    49    36     6    61    96   133   192   103    80    51    47    15    28

  Columns 27 through 30

   155    15     2   165

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   97.0661


Accuracy =

   97.1201


Accuracy =

   96.8396


Accuracy =

   97.0445


Accuracy =

   96.6023


Accuracy =

   97.0769


Accuracy =

   97.0338


Accuracy =

   96.5807


Accuracy =

   96.7533


Accuracy =

   96.7857


Accuracy =9.678568e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   85.7143
   93.5759
   98.0053
   93.9535
   97.0183
   97.7273
   76.9231
  100.0000
  100.0000
   97.6109
   97.5665
   91.7910
   96.2366
   98.8626
   98.2857
   97.6471

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   95.0574




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    31   108    35    43    23     7   122    76    78    30    57   106    25

  Columns 14 through 26

    14   151   176   135   132    97    85   163   129    99   127   150    84

  Columns 27 through 30

    25    33    18    72


Accuracy =

   97.0572


Accuracy =

   97.0225


Accuracy =

   97.0776


Accuracy =

   97.0592


Accuracy =

   97.0429


Accuracy =

   97.0348


Accuracy =

   97.1429


Accuracy =

   97.0572


Accuracy =

   96.9368


Accuracy =

   97.0511


Accuracy =9.705108e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.8353
   99.8814
   99.9441
   98.1804
   99.4224
   99.9721
  100.0000
   92.6554
   99.9288
   99.7305
  100.0000
  100.0000
  100.0000
   99.8969
   90.4957
   99.2638

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.7004




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   195    87    84    50   150    93    56   146     7   156   130    92   193

  Columns 14 through 26

    25    90   177    64    70    57   133    29    85    92   128    45   159

  Columns 27 through 30

   130   116    48   172


Accuracy =

   96.9737


Accuracy =

   97.0860


Accuracy =

   97.1043


Accuracy =

   96.9982


Accuracy =

   97.0472


Accuracy =

   97.0063


Accuracy =

   97.0227


Accuracy =

   97.0268


Accuracy =

   97.0635


Accuracy =

   97.0737


Accuracy =9.707372e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

  100.0000
   99.9406
   99.6644
   98.7302
   99.6697
   99.9441
  100.0000
   93.3960
   99.9822
   99.6968
   99.5868
  100.0000
  100.0000
   99.7934
   89.2645
   99.7552

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.7140




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   152   187   148   114   135    36    45   136    72   183    89    65   140

  Columns 14 through 26

    11    30    81   129   101   178   187   187   171   197   146    11    75

  Columns 27 through 30

   143   165    75     8


Accuracy =

   96.7486


Accuracy =

   96.7996


Accuracy =

   96.8303


Accuracy =

   96.7955


Accuracy =

   96.7894


Accuracy =

   96.8813


Accuracy =

   96.7343


Accuracy =

   96.8466


Accuracy =

   96.7098


Accuracy =

   96.8139


Accuracy =9.681392e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.9449
   99.8514
   99.8878
   97.9365
   99.0928
   99.9721
  100.0000
   93.2255
   99.9644
   99.6964
   99.6885
  100.0000
  100.0000
   99.8966
   87.8875
  100.0000

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.5653




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    95   197   157    75   140   182    89   155    74    50   140   103   114

  Columns 14 through 26

   121    11   194    35    33    39   148    71    61    66    52   155   124

  Columns 27 through 30

   181     4   102   141


Accuracy =

   96.9077


Accuracy =

   96.8914


Accuracy =

   96.9568


Accuracy =

   96.9935


Accuracy =

   96.9057


Accuracy =

   96.8955


Accuracy =

   96.9649


Accuracy =

   96.8546


Accuracy =

   96.9139


Accuracy =

   96.9425


Accuracy =9.694246e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.1740
   99.7626
   99.9441
   98.1702
   99.5052
   99.9721
   99.9383
   93.0771
  100.0000
   99.7976
  100.0000
  100.0000
   99.8791
   99.0702
   89.2863
   99.4516

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.5643




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

     3    11   169    40   145    25   182   198   154    59    77     5   111

  Columns 14 through 26

    31   101    37    99    65    50    70   196    62   136   120   196   158

  Columns 27 through 30

    39   174    52    11


Accuracy =

   96.9261


Accuracy =

   96.7627


Accuracy =

   96.7893


Accuracy =

   96.9486


Accuracy =

   96.7362


Accuracy =

   96.9506


Accuracy =

   96.7076


Accuracy =

   96.7995


Accuracy =

   96.8281


Accuracy =

   96.8587


Accuracy =9.685872e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.5592
   99.7921
   99.9441
   98.2595
   99.5458
   99.9162
   99.7215
   93.6654
   99.9822
   99.7640
   99.8964
  100.0000
  100.0000
   99.8969
   87.8539
   98.5924

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.5244




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   153    87   191   117   187    21    74   144   132   182    84   114    96

  Columns 14 through 26

    38   185    90    97   109    27   143    34    14   189   192    27   106

  Columns 27 through 30

    48    21   164   188


Accuracy =

   97.0018


Accuracy =

   97.0630


Accuracy =

   96.9814


Accuracy =

   97.0651


Accuracy =

   97.0222


Accuracy =

   96.9896


Accuracy =

   96.9691


Accuracy =

   96.9487


Accuracy =

   97.0283


Accuracy =

   96.9834


Accuracy =9.698343e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.6150
   99.8813
  100.0000
   97.7778
   99.1354
   99.9442
   99.9692
   92.5839
   99.9644
   98.8552
  100.0000
  100.0000
  100.0000
   99.5872
   90.7985
   99.1427

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.5784




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    19   128   110     9    72    52    72   197    41   168     7   116   112

  Columns 14 through 26

   126    20   121    94   145    31    41    53    31   141   157   157   156

  Columns 27 through 30

    16    30   151    38


Accuracy =

   97.0507


Accuracy =

   97.0691


Accuracy =

   97.0364


Accuracy =

   96.9915


Accuracy =

   97.0691


Accuracy =

   96.9221


Accuracy =

   97.0854


Accuracy =

   96.9997


Accuracy =

   97.1242


Accuracy =

   97.0793


Accuracy =9.707929e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

  100.0000
   99.8517
   99.9440
   98.0143
   99.6700
   99.9443
   98.9496
   93.2987
  100.0000
   99.7642
   99.5868
  100.0000
  100.0000
   99.3802
   90.0335
  100.0000

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.6523




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   187   168    53    27   117    73    25    92    24    58    32   177   113

  Columns 14 through 26

   115    67   182   187   152   149    99    86    14   173   125   149    70

  Columns 27 through 30

    91    30   176    18


Accuracy =

   97.0324


Accuracy =

   97.0222


Accuracy =

   97.0610


Accuracy =

   97.0671


Accuracy =

   97.1467


Accuracy =

   97.0365


Accuracy =

   97.1977


Accuracy =

   97.0365


Accuracy =

   97.1181


Accuracy =

   97.0202


Accuracy =9.702016e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.9450
   99.7628
   99.9442
   99.2076
   97.9373
  100.0000
  100.0000
   93.2300
  100.0000
   99.2590
   99.5863
  100.0000
  100.0000
   99.4835
   90.0395
   99.2083

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.6002




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    95   110    72   119   137    31   160    29    60   174    38    64   155

  Columns 14 through 26

    77   162   107    40    38    62    21    36   161    11   181   190   124

  Columns 27 through 30

   155    54   131     7


Accuracy =

   96.9879


Accuracy =

   97.0124


Accuracy =

   97.0512


Accuracy =

   97.0349


Accuracy =

   96.9635


Accuracy =

   97.0185


Accuracy =

   97.0573


Accuracy =

   96.9308


Accuracy =

   97.0226


Accuracy =

   96.9981


Accuracy =9.699814e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.0664
   99.8519
   99.8884
   97.7848
   99.6289
   99.9443
  100.0000
   93.1653
   99.9822
   99.7977
  100.0000
  100.0000
  100.0000
   99.3834
   89.4929
   99.6330

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.6012




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Salinas');

load('Salinas_gt');
image=salinas;
image_gt=salinas_gt;
size(image)

ans =

   512   217   224


train_on_image=0;

databaseID=1;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.3e-06       19-      16  1.5324e+03  2.9700e+01  8.0914e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06        3-      17  1.3085e+03  3.1555e+01  2.6373e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      16  1.3145e+03  3.1401e+01  3.2219e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       25-      14  1.5837e+03  3.2940e+01  4.4006e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       19-      17  1.3961e+03  2.4809e+01  4.2794e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        3-      15  1.5895e+03  3.3486e+01  3.3426e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07        3-      13  1.5876e+03  3.3252e+01  1.8749e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        3-      13  1.5893e+03  3.3282e+01  4.5946e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.1e-06        3-      15  1.5894e+03  3.3090e+01  3.7387e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06        3-      17  1.3624e+03  2.5065e+01  3.0599e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       49-      19  1.1818e+03  1.9379e+01  1.6368e-04
    1T -2.4e-06       40-      13  9.6432e+02  7.4289e+00  5.6829e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        3-      13  1.5813e+03  3.2662e+01  3.7400e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06        3-      16  1.5844e+03  3.3463e+01  7.5265e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.5e-06       52-      17  2.8164e+03  2.8424e+01  1.6236e-05
    1T -6.3e-06       73-      18  2.3772e+03  3.2868e+01  3.8157e-05
    1T -7.2e-06        2-      20  2.9944e+03  3.0727e+01  2.3589e-04
    1T  6.6e-06       62-      19  1.7870e+03  2.8751e+01  8.7785e-05
    1T  9.8e-06       41-      19  2.1565e+03  3.2042e+01  1.3712e-04
    1T -6.2e-06       52-      18  4.0518e+03  4.1780e+01  6.6441e-05
    1T -3.8e-06       73-      17  2.0967e+03  3.0447e+01  2.3779e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.6e-06       73-      18  2.2851e+03  3.1817e+01  5.1807e-05
    1T -2.1e-07       48-      17  2.0466e+03  3.0035e+01  1.2754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       48-      18  2.2923e+03  3.1475e+01  1.1103e-05
    1T -5.9e-07       44-      17  2.3151e+03  3.1078e+01  1.2145e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       41-      18  2.1587e+03  3.1795e+01  1.1886e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       41-      17  2.1006e+03  3.1401e+01  5.3380e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       62-      18  2.0483e+03  2.9656e+01  1.3180e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.2e-06       73-      17  1.7067e+03  2.5887e+01  6.9963e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.7e-06       44-      19  1.9142e+03  2.8043e+01  1.2096e-04
    1T -9.5e-06       44-      17  2.0699e+03  3.0361e+01  1.9702e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  6.8e-06       38-      18  2.1302e+03  3.1840e+01  9.7250e-05
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        3-      17  1.1710e+03  2.5432e+01  1.5958e-04
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
    1T  8.6e-07       64-      17  1.2252e+03  2.2592e+01  9.1137e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       38-      19  1.5013e+03  2.5570e+01  5.3590e-04
    1T  8.3e-06        7-      25  1.8941e+03  1.8701e+01  1.1526e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.8e-06       63-      27  3.1104e+03  2.1423e+01  1.7804e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      25  1.9262e+03  1.9889e+01  3.7687e-03
    1T  8.8e-07       65-      28  2.4093e+03  2.4978e+01  4.3833e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       53-      25  2.8131e+03  3.6292e+01  1.9116e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       61-      29  3.5021e+03  2.2490e+01  2.0589e-04
    1T  9.6e-06       53-      25  2.7911e+03  3.5400e+01  2.8623e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06        7-      24  1.6309e+03  1.7722e+01  1.1502e-04
    1T  4.7e-06       32-      24  1.7730e+03  1.9306e+01  6.2446e-05
    1T  1.7e-06       56-      23  1.4684e+03  2.4781e+01  2.3322e-04
    1T  8.9e-07       56-      23  1.6833e+03  2.9351e+01  1.7455e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.5e-06       32-      24  2.0245e+03  2.0027e+01  8.7533e-05
    1T  7.3e-06       66-      27  2.0672e+03  2.5697e+01  3.1621e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-09       61-      28  2.9617e+03  2.5742e+01  3.4007e-07
    1T  8.7e-08       56-      23  1.6762e+03  2.9455e+01  1.7166e-05
    1T  7.0e-06       24-      32  3.1252e+03  1.0338e+01  3.7652e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.3e-06        7-      27  2.7904e+03  2.6951e+01  8.7414e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       61-      28  3.5082e+03  2.2726e+01  4.2819e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06        7-      27  2.7948e+03  2.7156e+01  9.6022e-05
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       53-      19  2.3796e+03  2.9640e+01  2.6314e-05
    1T  8.3e-06       38-      22  2.4167e+03  2.6568e+01  1.6914e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       38-      20  3.1053e+03  2.8788e+01  1.0260e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.4e-06       40-      23  2.4745e+03  2.8633e+01  1.6540e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       21-      23  2.3117e+03  2.6402e+01  4.6784e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       54-      23  3.6198e+03  3.0866e+01  2.0418e-05
    1T -3.6e-06       40-      23  2.7523e+03  2.7293e+01  2.4792e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-07       38-      23  2.5910e+03  2.6566e+01  5.7984e-06
    1T  8.3e-06       21-      22  5.2483e+03  3.1473e+01  3.9251e-05
    1T -2.2e-06       40-      22  3.3762e+03  2.7210e+01  1.9267e-05
    1T -8.8e-06       61-      22  2.5121e+03  2.6567e+01  5.4144e-05
    1T  7.4e-06       38-      24  3.1857e+03  2.7684e+01  1.5044e-04
    1T  5.6e-06       23-      20  2.6774e+03  3.9230e+01  4.5034e-04
    1T  2.2e-06       40-      22  2.4119e+03  2.7860e+01  1.5632e-05
    1T  8.0e-06       40-      21  3.5988e+03  3.2831e+01  7.1606e-05
    1T  7.7e-07       59-      19  2.8634e+03  3.2325e+01  2.9748e-06
    1T  8.3e-06        5-      22  5.5040e+03  3.2846e+01  3.1813e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       49-      23  2.6517e+03  2.3016e+01  1.0188e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       38-      22  4.8274e+03  3.4866e+01  1.1428e-03
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       24-      18  2.7746e+03  2.6086e+01  9.3578e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       48-      19  5.9662e+03  3.0987e+01  2.7685e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       59-      20  2.6774e+03  2.4566e+01  7.1008e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       24-      18  2.7607e+03  2.6554e+01  1.4437e-05
    1T  4.2e-06       59-      20  2.6849e+03  2.4546e+01  6.9485e-05
    1T  9.9e-06       59-      20  2.7166e+03  2.4571e+01  1.6436e-04
    1T  1.7e-06       59-      20  2.7176e+03  2.4843e+01  2.8220e-05
    1T  8.4e-06       47-      20  4.0980e+03  2.4645e+01  5.6850e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       71-      20  2.6985e+03  2.0378e+01  4.0808e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       59-      20  3.2520e+03  2.4835e+01  1.9015e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.5e-06        3-      18  3.2494e+03  2.4868e+01  7.8587e-05
    1T -4.2e-06       47-      20  4.8752e+03  2.9262e+01  1.2131e-04
    1T  3.5e-06       20-      21  5.5445e+03  3.3038e+01  5.7644e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-06       28-      21  3.9226e+03  3.2080e+01  3.9830e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       28-      21  4.3091e+03  3.3715e+01  3.5843e-04
    1T  1.6e-06       71-      19  5.2914e+03  2.9430e+01  3.5330e-03
    1T  9.3e-06       71-      20  3.9993e+03  3.0701e+01  3.7577e-04
    1T  6.4e-06       71-      20  6.0290e+03  3.4745e+01  7.5902e-04
    1T  6.7e-06       71-      19  3.7954e+03  2.8132e+01  8.8836e-04
    1T -3.7e-06       64-      19  4.1190e+03  3.0451e+01  4.2038e-05
    1T  5.8e-06       71-      20  3.4800e+03  2.6772e+01  2.3308e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       43-      19  4.0638e+03  2.8371e+01  4.6914e-05
    1T  6.1e-06       71-      20  3.9350e+03  3.0104e+01  2.4598e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.4e-07        3-      19  3.7502e+03  2.7347e+01  3.9161e-06
    1T  5.1e-06       64-      19  6.2489e+03  2.5161e+01  5.8426e-05
    1T -8.0e-06       43-      18  3.4267e+03  2.4955e+01  4.0954e-05
    1T  7.3e-06        3-      20  2.2286e+03  2.2444e+01  6.2463e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   163   126   123    63    44    47   145   104    89    52   104    44   165

  Columns 14 through 26

    19    52   130   154    47    44    97   118   195   136    80     7   131

  Columns 27 through 30

    66    62     9    63


Accuracy =

   97.0197


Accuracy =

   97.0911


Accuracy =

   97.0625


Accuracy =

   97.0401


Accuracy =

   97.0136


Accuracy =

   97.0156


Accuracy =

   97.0319


Accuracy =

   97.0238


Accuracy =

   96.9911


Accuracy =

   97.0483


Accuracy =9.704826e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   99.9450
   99.8518
   99.9441
   98.6519
   99.5873
   99.9441
   99.6300
   93.1720
   99.9287
   98.8204
   99.8966
  100.0000
  100.0000
   98.9669
   90.2357
   99.4492

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   98.6265




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Pavia');

load('Pavia_gt');
image=pavia;
image_gt=pavia_gt;
size(image)

ans =

        1096         715         102


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-07       57-      40  5.4784e+02  5.5556e+05  9.7833e-08
    1T -1.1e-06       46-      41  6.8978e+01  6.8917e+01  2.5181e-04
    1T  7.2e-06       11-      48  3.0627e+02  1.1275e+05  2.0212e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        6-      55  9.3911e+02  5.4034e+08  1.6792e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       23-      52  9.8040e+01  7.6560e+02  2.2639e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-07        6-      49  8.6904e+01  3.6426e+02  6.6221e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       58-      54  1.0197e+02  3.9955e+02  3.0305e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       74-      41  9.3825e+01  9.6003e+00  5.6877e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06        4-      50  9.9806e+01  1.5754e+01  6.4029e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       62-      40  9.0581e+01  1.5519e+01  4.6735e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.1e-06       70-      45  9.8806e+01  1.1106e+01  2.9201e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       44-      52  9.7612e+01  1.7648e+01  1.1747e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06       16-      46  8.5865e+01  2.0410e+02  1.2519e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       61-      51  8.7345e+01  2.0247e+01  3.8373e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       28-      49  1.0314e+02  7.8073e+01  2.9901e-06
    1T  9.3e-07        5-      59  9.4057e+01  2.8708e+01  7.5748e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       16-      48  9.2924e+01  3.8223e+02  1.1919e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       19-      47  9.8314e+01  2.2705e+02  1.0923e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.2e-06       52-      60  7.8625e+02  5.6979e+01  1.3706e-04
    1T  5.4e-06        8-      53  1.0684e+02  6.2206e+01  1.6973e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       60-      63  1.1719e+03  3.8996e+01  7.4788e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       63-      37  9.8076e+01  1.4007e+01  2.5122e-04
    1T -1.6e-06       56-      60  2.7164e+02  1.1905e+03  4.8358e-03
    1T  5.3e-06       41-      52  1.0456e+02  1.5984e+01  5.4978e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       57-      52  9.8286e+01  8.4127e+01  3.0123e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       10-      51  9.1778e+01  1.8637e+02  1.6211e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.1e-06       55-      61  9.4589e+02  5.0885e+01  9.0953e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.4e-06       12-      49  8.9087e+01  1.5538e+02  7.7575e-05
    1T -4.9e-06       53-      54  9.8225e+01  1.8529e+01  3.5139e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-07       59-      49  1.1516e+02  2.0013e+02  1.2678e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       64-      54  1.1123e+02  2.4818e+01  2.2094e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       44-      50  1.1599e+02  1.3062e+01  4.6118e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-06       24-      47  1.0357e+02  2.9027e+02  1.5746e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       14-      47  1.0107e+02  1.0111e+02  3.5946e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        6-      49  1.0025e+02  2.4033e+02  7.8666e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06       59-      61  9.7426e+01  1.2487e+02  5.7931e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       16-      42  9.3474e+01  1.1045e+01  1.4309e-06
    1T  5.1e-06       35-      49  9.8564e+01  2.8010e+01  1.7572e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       33-      45  9.5126e+01  1.1184e+01  4.9645e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.4e-06        6-      52  1.0457e+02  2.0047e+01  6.5502e-05
    1T -8.0e-06       57-      50  9.8363e+01  6.6794e+01  6.5249e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.1e-06       44-      56  1.1186e+02  2.3840e+02  4.9449e-04
    1T  1.0e-06       69-      53  1.0327e+02  5.2977e+01  3.7661e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       75-      49  9.7921e+01  2.0481e+01  9.6005e-07
    1T  7.7e-07       29-      60  1.0525e+03  4.9055e+01  3.3657e-03
    1T  7.3e-06       63-      46  9.6891e+01  1.7494e+01  1.9732e-04
    1T  9.4e-06       64-      56  1.0946e+02  6.4059e+01  8.0552e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.6e-06       64-      46  9.6690e+01  1.2618e+01  3.4202e-04
    1T -9.3e-06       71-      56  9.9170e+01  1.5806e+02  6.8832e-05
    1T  6.8e-06       66-      47  9.5309e+01  1.5451e+01  5.4848e-04
    1T  3.6e-06       37-      52  1.9885e+02  1.5526e+02  5.5740e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.0e-06       15-      61  1.0501e+02  4.4204e+02  6.8088e-04
    1T -4.6e-06       30-      62  4.9343e+02  1.3181e+02  2.8337e-03
    1T -4.0e-07       32-      62  4.3325e+02  5.4834e+01  1.4278e-03
    1T  9.3e-06       70-      66  5.0058e+02  2.9196e+02  2.1118e-03
    1T  2.4e-06       40-      60  1.0364e+02  7.8813e+02  1.9723e-07
    1T  4.1e-07       33-      55  9.9599e+01  1.6409e+01  1.0519e-07
    1T  4.8e-06       12-      54  2.6195e+02  1.1868e+03  9.6751e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-07       42-      55  1.5626e+03  8.0326e+02  2.7166e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       13-      68  3.6554e+02  1.8221e+03  1.8444e-03
    1T  8.8e-06       55-      60  1.0761e+03  1.0329e+03  7.2571e-06
    1T  5.0e-06       20-      46  1.0765e+03  4.5643e+02  2.6179e-06
    1T  7.7e-06       15-      62  1.5588e+03  9.8082e+02  2.5453e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       12-      57  2.6719e+02  3.8178e+01  2.5312e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       15-      53  1.4890e+02  1.5666e+01  5.2273e-07
    1T  2.4e-06        1-      56  1.1214e+02  1.2207e+01  3.7214e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       49-      55  1.4193e+02  1.2045e+01  6.3611e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       72-      53  1.4204e+02  1.0955e+01  7.5816e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       21-      44  1.2203e+02  9.6235e+00  5.7062e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       13-      53  1.5601e+02  1.0005e+01  6.7121e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       63-      50  1.0604e+03  4.2617e+01  3.3293e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       31-      55  1.3078e+02  1.2967e+01  2.0233e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-06       29-      52  1.6686e+02  1.3108e+01  5.7751e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       75-      65  1.3042e+03  3.1642e+01  1.7107e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06       31-      49  1.1619e+02  1.0680e+01  3.1806e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       23-      60  1.3104e+02  1.2885e+01  4.9108e-07
    1T  2.5e-06       15-      56  1.2866e+02  1.3294e+01  1.4223e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       20-      52  1.1874e+02  1.0023e+01  3.7341e-04
    1T  5.0e-07       52-      52  1.2333e+02  1.0688e+01  6.7211e-08
    1T  4.7e-06       19-      52  1.5614e+02  1.5300e+01  4.5559e-07
    1T  2.4e-06       70-      53  1.1411e+02  1.2677e+01  6.3830e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       58-      53  1.2796e+02  1.1407e+01  2.2066e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       15-      57  1.2580e+02  1.0828e+01  3.4331e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.2e-07       72-      61  1.3367e+02  1.2690e+01  3.6608e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.5e-06       64-      53  1.2806e+02  1.0024e+01  3.1347e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.9e-06        6-      55  1.4616e+02  1.3162e+01  4.6571e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       27-      51  1.3546e+02  1.0256e+01  1.3618e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06        7-      57  1.2518e+02  1.2949e+01  6.4660e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.8e-06       11-      48  1.4078e+02  1.2637e+01  1.3802e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       26-      53  1.3839e+02  9.8028e+00  9.4541e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       63-      55  1.1598e+02  1.0970e+01  2.5958e-04
    1T -3.8e-06       12-      58  1.2754e+02  1.6494e+01  6.4785e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-07       64-      41  1.2797e+02  8.4883e+00  7.9170e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       14-      54  1.1374e+02  1.0008e+01  2.2143e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-07       27-      54  3.3063e+02  1.7686e+01  1.6921e-07
    1T  3.2e-06       18-      55  1.2821e+02  1.2576e+01  3.5411e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       67-      47  1.1769e+02  9.5593e+00  3.3862e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       60-      47  1.8465e+03  4.8759e+01  6.8215e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-07       20-      56  1.2928e+02  1.2757e+01  3.7381e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.2e-06       50-      58  1.2051e+02  1.3955e+01  2.6120e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       56-      44  1.2593e+02  1.0583e+01  2.0896e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-06       27-      60  3.3259e+02  2.0170e+01  8.9495e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       56-      47  1.1978e+02  8.1418e+00  3.5321e-07
    1T  9.8e-06       23-      56  1.3192e+02  1.4098e+01  6.7562e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       20-      52  1.1958e+02  1.3794e+01  4.2013e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       20-      50  1.1769e+02  1.0463e+01  3.6040e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       33-      63  1.2747e+03  4.4580e+01  4.1514e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       22-      54  1.3042e+02  1.3564e+01  3.6100e-04
    1T  5.5e-06       60-      58  1.4247e+03  1.9641e+01  1.0480e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06       18-      57  1.3433e+02  1.3849e+01  7.2789e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       70-      50  1.3391e+02  1.0732e+01  1.3868e-06
    1T  1.7e-06       22-      51  1.1893e+02  1.0507e+01  3.4385e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       74-      57  1.2927e+02  1.8958e+01  1.2887e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-05        8-      55  1.2405e+02  1.0746e+01  1.6413e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       59-      53  1.2087e+02  1.3759e+01  1.2245e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       27-      49  1.1812e+02  1.0241e+01  2.2039e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       20-      58  2.6278e+02  2.6195e+01  4.1557e-04
    1T -5.4e-06       22-      72  8.3336e+02  4.3546e+01  6.1736e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.8e-07       21-      50  1.3463e+02  1.0807e+01  8.0515e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       74-      47  1.2113e+02  8.4008e+00  6.4886e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       55-      60  1.2613e+02  1.4891e+01  2.6219e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-06       31-      50  1.2860e+02  9.6320e+00  1.6571e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       27-      57  1.2711e+02  1.7464e+01  1.0141e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.6e-06       43-      51  1.1421e+02  8.4981e+00  4.0356e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       37-      52  1.2208e+02  1.0699e+01  9.8296e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.5e-06       58-      42  1.1704e+02  7.1011e+00  4.1061e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       22-      45  1.1644e+02  8.1828e+00  9.1276e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.4e-06       31-      55  1.2586e+02  1.0956e+01  2.6425e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.1e-06       62-      61  1.4178e+02  1.4744e+01  7.3518e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       59-      52  1.2625e+02  1.3685e+01  1.2254e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       66-      43  1.1992e+02  9.1561e+00  5.6433e-04
    1T  6.6e-06       53-      58  1.1568e+02  1.4520e+01  4.4067e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       11-      56  1.2757e+02  1.3934e+01  2.1608e-06
    1T  8.8e-06       62-      55  1.1630e+02  1.5294e+01  4.8508e-05
    1T  3.9e-06       34-      50  1.1248e+02  9.7079e+00  1.1120e-06
    1T  1.5e-06       20-      42  1.2771e+02  1.0418e+01  6.5703e-04
    1T  2.1e-06       67-      57  1.3629e+02  1.4018e+01  3.3132e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       69-      53  1.1761e+02  1.1883e+01  1.0388e-06
    1T -5.6e-06       40-      56  1.2457e+02  1.1859e+01  1.7051e-04
    1T  4.8e-07       46-      54  1.4096e+02  1.1111e+01  7.3360e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06       49-      55  1.2830e+02  1.1726e+01  5.9349e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06        2-      49  1.2216e+02  9.7059e+00  3.3795e-04
    1T -7.8e-06        2-      56  1.2838e+02  1.0358e+01  6.1681e-04
    1T  7.5e-06       58-      62  2.3833e+02  1.5556e+01  7.5155e-04
    1T  7.7e-06       34-      52  1.1856e+02  1.4184e+01  3.2592e-06
    1T  1.7e-06       27-      68  5.7009e+02  5.5297e+01  5.7785e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       18-      55  1.3227e+02  1.3518e+01  1.0262e-06
    1T  1.0e-06       61-      54  1.2899e+02  9.9471e+00  6.1181e-04
    1T  8.9e-06       65-      51  1.2639e+02  1.0363e+01  1.5725e-06
    1T  5.6e-06       65-      69  6.4977e+02  4.5490e+01  4.1054e-04
    1T  4.2e-07       25-      52  1.2522e+02  9.9141e+00  1.3266e-07
    1T  1.1e-06       58-      54  1.4042e+02  1.2897e+01  1.7678e-07
    1T  5.4e-06        6-      51  1.4000e+03  4.0102e+01  1.2071e-06
    1T  5.7e-06       51-      62  7.6187e+02  4.8115e+01  3.1654e-07
    1T  7.3e-06       61-      66  1.6431e+03  3.6179e+01  2.7037e-03
    1T  6.1e-06       61-      70  2.8580e+02  2.6418e+01  2.2704e-06
    1T -1.9e-08       15-      69  1.5106e+03  3.0281e+01  6.5135e-10

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        6-      69  1.1995e+03  4.6182e+01  1.8492e-03
    1T -9.3e-06       38-      63  2.3737e+03  3.2676e+01  2.4252e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       30-      63  9.6255e+02  3.6338e+01  3.9836e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06        5-      58  5.3384e+02  6.7618e+01  3.1166e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.2e-06       23-      56  9.9045e+02  3.6375e+01  8.2616e-04
    1T  6.0e-07       73-      64  1.8119e+03  2.6610e+01  1.2652e-03
    1T -4.9e-06        3-      61  1.7396e+03  2.7970e+01  8.7532e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [144x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       41-      53  1.5444e+02  1.6059e+01  1.9650e-06
    1T  8.4e-06       11-      54  1.5573e+02  1.6682e+01  2.2771e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.4e-06        8-      45  1.4865e+02  1.4349e+01  5.9408e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       57-      48  1.0306e+03  6.4165e+01  1.0686e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.7e-06       61-      50  1.3645e+02  1.5949e+01  7.1355e-07
    1T  3.9e-06       20-      40  1.4412e+02  1.1549e+01  4.5843e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.1e-06        5-      48  1.4686e+02  1.5552e+01  6.8105e-04
    1T  5.5e-06       16-      53  1.8255e+02  1.9795e+01  1.3611e-06
    1T  7.2e-06       40-      34  1.3836e+02  1.1677e+01  3.5899e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.9e-06       26-      52  1.4611e+02  1.5085e+01  6.4120e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       11-      37  1.3252e+02  1.1320e+01  4.6738e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-07       39-      44  1.4296e+02  1.7275e+01  2.0169e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06       51-      55  1.5733e+02  1.7900e+01  1.0575e-06
    1T -7.6e-06       75-      55  1.3982e+02  1.8802e+01  2.1142e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06        8-      54  1.5435e+02  2.0691e+01  5.9281e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       24-      52  1.5659e+02  1.4126e+01  1.3031e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.6e-06        6-      48  1.3886e+02  1.2835e+01  6.0473e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.1e-06       75-      53  1.4496e+02  1.5592e+01  1.2045e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.0e-06       37-      51  1.6681e+02  2.1129e+01  4.2529e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -7.3e-07       38-      57  1.6193e+02  2.3302e+01  4.9788e-04
    1T  6.3e-06       30-      43  1.3745e+02  1.2624e+01  3.2657e-06
    1T  8.3e-06       27-      55  1.4120e+02  2.1290e+01  1.3294e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       13-      48  1.3958e+02  1.3721e+01  7.8069e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       38-      51  1.5202e+02  1.7596e+01  5.2178e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06        7-      52  1.4503e+02  1.6302e+01  4.3664e-04
    1T  5.4e-06       56-      53  1.5048e+03  9.0717e+01  8.6119e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-07       52-      55  1.5110e+02  1.8967e+01  4.0948e-04
    1T  8.8e-06       33-      62  1.6361e+02  2.4463e+01  9.1092e-07
    1T  3.4e-08       35-      53  1.3833e+03  1.6929e+02  5.9821e-09

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       14-      52  1.5473e+02  2.1395e+01  3.0586e-04
    1T  7.6e-06        9-      51  2.2955e+03  8.4376e+01  9.0796e-07
    1T -3.2e-06       13-      49  1.3769e+02  1.6765e+01  5.2464e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06        4-      48  2.7321e+03  9.7013e+01  2.3548e-06
    1T -6.4e-06       46-      51  1.2556e+03  3.1659e+01  8.7029e-05
    1T -1.6e-06       70-      49  1.6014e+02  1.8390e+01  6.2561e-04
    1T  4.1e-06       20-      54  1.5968e+02  2.2901e+01  7.9141e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-07       54-      52  1.4863e+02  1.9019e+01  7.9854e-08
    1T  4.0e-06       69-      60  1.4881e+02  1.9565e+01  1.5964e-06
    1T  1.2e-06        2-      62  4.3062e+02  6.9837e+01  8.1315e-08
    1T  9.3e-06       24-      63  2.2510e+03  1.4920e+02  1.0013e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.7e-06       62-      54  3.2631e+03  1.9919e+02  7.6881e-07
    1T  7.5e-07       28-      56  1.2819e+03  1.0043e+02  2.4108e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.6e-07       67-      52  3.3459e+03  5.7351e+01  8.3530e-08
    1T  4.8e-07       11-      60  2.1961e+03  9.0797e+01  6.7610e-07
    1T  4.1e-06       66-      54  2.3346e+03  1.9022e+02  5.5808e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06       15-      46  1.2559e+03  1.0762e+02  7.9601e-07
    1T  5.4e-07       21-      51  2.1798e+03  5.4698e+01  3.2799e-08
    1T -8.0e-06       58-      54  1.9028e+03  6.8773e+01  7.5436e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.0e-06        9-      65  1.7391e+03  1.5853e+02  5.9915e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       35-      55  2.0290e+03  9.5945e+01  1.7711e-06
    1T  2.6e-06        7-      57  1.2873e+03  7.0736e+01  5.7109e-07
    1T  7.4e-06       15-      60  8.3922e+02  7.3698e+01  2.0452e-06
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   179   194   157   153    18    84    74   116    31    51    29    67   194

  Columns 14 through 26

    21    30   200   116   188    10   175    25    93   141   125   167    96

  Columns 27 through 30

    95   132   106   183


Accuracy =

   13.1972


Accuracy =

    8.3019


Accuracy =

    1.2522


Accuracy =

   13.5969


Accuracy =

   11.7720


Accuracy =

   13.6812


Accuracy =

   45.3855


Accuracy =

   13.3814


Accuracy =

    7.1244


Accuracy =

   13.4627


Accuracy =1.346270e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

    0.7620
    0.1891
         0
         0
         0
    4.0272
    2.1380
   44.1286
         0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

    5.6939




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:12
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-07        9-      34  3.8012e+02  1.9796e+08  6.1081e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-06       28-      34  1.8689e+02  3.3775e+06  3.2019e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       37-      27  1.5010e+02  1.2909e+08  2.0960e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       37-      27  1.5010e+02  1.2909e+08  2.0960e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       37-      27  1.5010e+02  1.2909e+08  2.0960e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       37-      27  1.5010e+02  1.2909e+08  2.0960e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       37-      27  1.5010e+02  1.2909e+08  2.0960e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.2e-06       37-      27  1.5010e+02  1.2909e+08  2.0960e-06
    1T -8.7e-06       61-      34  7.7579e+02  6.7178e+07  9.3345e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06       41-      47  2.0920e+02  1.8047e+03  8.4862e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       14-      43  5.1158e+02  3.4851e+03  7.5028e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       62-      47  8.4473e+02  4.1983e+03  4.2281e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.8e-06       51-      46  1.3792e+03  2.2114e+03  1.1606e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       41-      48  1.1720e+03  3.4669e+03  7.7173e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       25-      44  1.4857e+02  2.8760e+03  7.7994e-04
    1T  4.5e-06       28-      46  1.1993e+03  1.5497e+03  2.6746e-06
    1T  2.1e-06       44-      46  1.0394e+03  3.8035e+03  1.2347e-06
    1T  6.7e-06       53-      41  9.2112e+02  1.4187e+03  3.4133e-06
    1T  4.8e-06       57-      47  4.0518e+02  7.8346e+02  2.8089e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       28-      49  1.0639e+03  7.0976e+02  2.1480e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       73-      44  2.1406e+02  1.6072e+03  1.0502e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       31-      50  6.2022e+02  3.0435e+03  8.0679e-04
    1T  2.0e-06       35-      47  1.3089e+03  3.9300e+03  7.3108e-07
    1T  6.5e-06       75-      52  1.4523e+02  3.6965e+03  6.9455e-07
    1T  8.0e-06       62-      40  7.7424e+02  2.7803e+03  9.1323e-04
    1T  1.6e-06       34-      45  1.2215e+03  4.2041e+03  2.5703e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.6e-06       74-      49  1.2475e+03  3.9205e+03  3.9475e-04
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       17-      55  1.1401e+03  7.7281e+01  1.0448e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06        5-      42  2.8963e+02  4.8116e+01  5.0747e-07
    1T  4.9e-06       34-      52  1.4175e+03  6.9726e+01  3.3133e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       61-      41  9.9552e+02  4.9172e+01  2.8765e-03
    1T  5.5e-06       64-      53  1.8278e+03  7.4679e+01  1.1469e-06
    1T  2.7e-06       13-      38  2.1932e+02  4.3190e+01  4.5450e-07
    1T -6.6e-06       65-      38  3.2534e+02  4.3207e+01  8.1439e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06       52-      51  1.7628e+03  7.7516e+01  3.8315e-06
    1T  2.7e-06       10-      47  1.2597e+03  4.4071e+01  8.9737e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-07       19-      47  5.2386e+02  4.9985e+01  3.5349e-07
    1T  1.5e-06       75-      55  1.3650e+03  8.9998e+01  6.8783e-07
    1T  3.2e-06       16-      53  1.0891e+03  6.9011e+01  4.9532e-07
    1T -2.5e-07        4-      53  1.0313e+03  9.5040e+01  9.9052e-04
    1T  5.3e-06       53-      47  2.5527e+02  5.4322e+01  9.9564e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       40-      36  6.5050e+02  3.8916e+01  5.5141e-07
    1T  8.9e-06       12-      45  9.3240e+02  5.5583e+01  2.3517e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.5e-06        6-      39  2.7477e+02  4.7916e+01  7.1728e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.1e-06        5-      51  3.6950e+02  8.8200e+01  4.0303e-07
    1T  7.5e-06       68-      49  1.8534e+03  7.6181e+01  6.7724e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.0e-06       47-      36  4.0538e+02  5.5007e+01  5.6675e-07
    1T  1.7e-07       13-      44  2.1003e+02  5.9791e+01  1.1444e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.4e-07        1-      43  1.7465e+03  6.8873e+01  1.8089e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.9e-06       39-      42  1.6978e+03  8.2818e+01  8.8225e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06        1-      37  3.7924e+02  6.0276e+01  2.7323e-07
    1T  1.6e-06       35-      46  2.4136e+03  1.2466e+02  1.8725e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       31-      46  3.1614e+02  8.9814e+01  3.0467e-03
    1T  9.8e-06       16-      41  5.4513e+02  7.6910e+01  3.9793e-04
    1T  8.7e-06       32-      41  2.6059e+03  8.2398e+01  1.5886e-06
    1T  3.5e-06       55-      44  1.8740e+03  9.1398e+01  1.6160e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.8e-06       49-      46  5.3435e+02  1.0708e+02  3.0829e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       65-      36  3.7456e+02  8.4546e+01  7.0158e-07
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    21   144    88    42   182   177   133    78   107   115   145    41    40

  Columns 14 through 26

    80   144    31   145    76    62   144    20    46    64    22     7    77

  Columns 27 through 30

   114    58   166    17


Accuracy =

    9.3561


Accuracy =

    6.5371


Accuracy =

    7.4751


Accuracy =

    1.8888


Accuracy =

    3.0024


Accuracy =

    2.0438


Accuracy =

    6.9505


Accuracy =

    6.8446


Accuracy =

    9.1313


Accuracy =

    2.5503


Accuracy =2.550256e+00
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

         0
    0.9899
    4.7393
    0.0722
   42.9630
    1.6473
         0
         0
   15.2859

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

    7.2997




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'Pavia' ;

load('Pavia');

load('Pavia_gt');
image=pavia;
image_gt=pavia_gt;
size(image)

ans =

        1096         715         102


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.3e-07       75-      32  8.6403e+01  3.7354e+04  6.7433e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06        3-      48  6.9780e+02  3.1147e+04  1.2317e-06
    1T  2.1e-06       21-      55  6.4985e+02  5.8201e+05  2.4215e-07
    1T  7.7e-06       67-      59  5.3376e+02  7.3059e+05  3.1687e-03
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-06       12-      59  1.1101e+02  1.6651e+01  6.3497e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       52-      53  9.9123e+01  1.1076e+01  2.6817e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       57-      50  9.6118e+01  1.1026e+01  4.9990e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.2e-06       48-      62  1.7177e+02  1.9264e+01  6.7685e-04
    1T -2.4e-07       51-      51  9.7579e+01  1.0255e+01  4.5391e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       59-      52  2.1085e+02  2.8082e+01  4.1883e-06
    1T -3.1e-06       48-      57  9.8785e+01  1.3063e+01  4.4816e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-07       36-      54  9.6083e+01  1.3637e+01  1.0403e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.9e-07       72-      59  9.9238e+02  2.7590e+01  3.5105e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-07        5-      53  1.0151e+02  8.9591e+00  6.1385e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       36-      58  8.9392e+01  1.2900e+01  2.3633e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       61-      50  9.8056e+01  1.0675e+01  1.2201e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       16-      64  6.4625e+02  3.9771e+01  2.3214e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       18-      63  9.2265e+01  1.6724e+01  1.2307e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06        8-      52  9.5698e+01  1.0473e+01  2.8692e-06
    1T  9.8e-06       73-      62  3.8231e+02  2.4977e+01  4.0796e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       12-      36  8.8162e+01  7.1518e+00  7.8112e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06        8-      50  9.4149e+01  8.9422e+00  1.9822e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06        5-      54  1.0628e+02  1.0695e+01  9.0308e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.7e-06        2-      46  9.6703e+01  1.1341e+01  2.7023e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-07       41-      57  9.5449e+01  1.2949e+01  3.2237e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06        7-      59  1.3166e+02  1.5708e+01  1.8051e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.3e-06       50-      62  9.9565e+01  2.0093e+01  1.5944e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-07       25-      50  1.8114e+02  2.8627e+01  1.0620e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-07        7-      65  8.3064e+02  4.4172e+01  8.4277e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.3e-06       30-      56  8.4119e+01  1.3921e+01  4.3974e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.5e-06       36-      45  8.7577e+01  7.6358e+00  2.7837e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.5e-06       47-      61  1.8251e+02  1.1884e+01  5.1180e-05
    1T  6.1e-07        8-      52  9.4670e+01  1.0717e+01  9.4538e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.6e-06       68-      59  9.4156e+01  1.8769e+01  1.0534e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05        6-      49  9.6703e+01  9.9186e+00  5.0276e-04
    1T  9.5e-06       73-      47  8.8791e+01  1.0389e+01  2.6803e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       71-      59  9.9352e+01  1.2061e+01  1.5519e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06        9-      51  1.0082e+02  1.0289e+01  3.1825e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.1e-06       62-      59  9.4767e+01  1.3947e+01  2.2055e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       69-      44  9.0108e+01  8.0761e+00  2.1056e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       41-      55  9.5959e+01  1.0618e+01  1.4611e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       38-      57  8.9285e+01  1.5675e+01  9.3049e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.8e-06       61-      58  8.9849e+01  1.4031e+01  5.3448e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.8e-06        7-      62  9.3079e+01  1.6607e+01  4.2444e-07
    1T  1.5e-06       57-      59  9.4147e+01  1.3725e+01  1.1629e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.2e-06       15-      47  1.1251e+02  1.7992e+01  2.1925e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.7e-06       17-      58  9.7892e+01  1.2279e+01  2.2841e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.9e-06       44-      51  8.8296e+01  1.1474e+01  6.1481e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.1e-07       11-      61  1.0901e+02  1.9217e+01  2.0141e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       17-      57  9.8812e+01  1.8791e+01  4.5140e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06        8-      55  9.1664e+01  1.1794e+01  2.4217e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.4e-06        6-      56  9.3371e+01  1.2428e+01  1.6965e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.8e-06       49-      47  1.0590e+02  2.1210e+01  1.5647e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.8e-06       40-      44  9.4549e+01  9.3566e+00  3.5646e-06
    1T  7.1e-06       18-      59  1.0303e+02  1.8010e+01  9.2843e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.2e-06       27-      49  9.7368e+01  1.2665e+01  4.8449e-05
    1T  9.7e-06       26-      56  1.0040e+02  1.1683e+01  2.0172e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       18-      43  9.9571e+01  1.1808e+01  2.2197e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       55-      59  1.0904e+02  1.2884e+01  1.1024e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.3e-06       17-      47  9.4314e+01  9.1885e+00  7.0899e-04
    1T  6.7e-06       65-      64  9.9804e+01  1.5334e+01  8.2144e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       13-      56  1.0446e+02  1.3125e+01  6.4948e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.6e-06       19-      58  1.0033e+02  1.0594e+01  5.1761e-04
    1T -4.4e-06       45-      55  9.2473e+01  1.1184e+01  2.2151e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       20-      60  5.9731e+02  3.8040e+01  1.5389e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       33-      58  1.0173e+02  1.4485e+01  1.3071e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.6e-06       10-      59  9.4056e+01  1.4632e+01  7.4705e-05
    1T  2.4e-06       50-      70  2.7647e+02  3.3812e+01  1.4891e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.9e-06       43-      56  1.0085e+02  1.3315e+01  4.3563e-04
    1T  4.1e-06       26-      48  9.8078e+01  8.5365e+00  1.6710e-06
    1T -9.4e-06       18-      66  8.1577e+02  4.6629e+01  3.8311e-03
    1T  7.8e-06       73-      61  1.4048e+02  1.8731e+01  1.2378e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.7e-06       20-      42  9.6436e+01  1.1168e+01  4.9624e-04
    1T  3.9e-06       50-      57  9.9516e+01  1.4868e+01  7.1056e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.7e-07       55-      53  9.5502e+01  9.8900e+00  5.4007e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06        7-      45  9.2905e+01  9.7206e+00  3.1864e-06
    1T  1.0e-06       13-      56  1.0477e+02  1.2915e+01  1.7151e-04
    1T  3.1e-06       45-      52  1.0394e+02  1.2758e+01  6.0104e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       67-      61  1.0315e+02  1.2220e+01  5.8911e-04
    1T  9.3e-06       70-      54  1.0882e+02  1.3600e+01  3.8774e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.4e-06       73-      58  1.0915e+02  1.7182e+01  6.5484e-06
    1T  9.8e-06       51-      57  3.4036e+02  3.4948e+01  2.8362e-06
    1T  7.5e-06       19-      54  1.0447e+02  1.4370e+01  1.2265e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       48-      63  3.7976e+02  3.9213e+01  4.0901e-03
    1T  6.5e-06       23-      64  4.9763e+02  3.5656e+01  2.2090e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       48-      65  1.1387e+03  4.1952e+01  1.7334e-06
    1T  9.3e-07       52-      68  2.0428e+02  4.9426e+01  9.9441e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06        9-      62  4.6989e+02  3.5352e+01  6.6302e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.1e-06       18-      65  2.5707e+02  3.2038e+01  2.1061e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.2e-06       10-      67  2.5946e+02  6.0202e+01  3.3700e-07
    1T  3.4e-07       46-      68  5.3232e+02  4.1350e+01  1.9289e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       36-      60  3.3511e+02  4.4166e+01  5.8160e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-07       57-      62  4.5590e+02  5.0138e+01  3.8840e-08
    1T -8.0e-06       75-      42  5.6599e+02  3.8000e+01  6.6340e-04
    1T  5.2e-07       64-      64  9.0302e+02  2.5069e+01  8.2404e-08
    1T -6.2e-06       51-      61  5.0995e+02  2.8058e+01  7.7438e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -2.8e-06       12-      67  9.9238e+02  3.8225e+01  7.8176e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.7e-06        3-      59  1.3136e+03  3.1381e+01  5.5223e-04
    1T  2.8e-06       73-      55  3.6262e+02  2.7380e+01  5.9068e-07
    1T -7.9e-06       20-      60  7.4230e+02  3.0373e+01  4.7096e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.2e-08       10-      60  1.0703e+03  2.1643e+01  9.0682e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.4e-07       33-      62  3.8269e+02  3.2755e+01  8.2027e-04
    1T  8.8e-06        5-      64  3.5053e+02  3.2600e+01  1.5416e-06
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [102x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.2e-06       41-      56  1.2718e+02  1.7858e+01  5.0137e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.8e-06       55-      46  1.4110e+02  1.4516e+01  3.9743e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-07       49-      53  1.2402e+02  1.7686e+01  5.1651e-08

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       44-      65  1.5736e+03  4.2024e+01  1.5003e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.2e-06       26-      46  1.2027e+02  1.1621e+01  8.9423e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.0e-06       40-      53  6.5268e+02  4.8205e+01  1.2445e-06
    1T  7.3e-06       74-      56  1.3353e+02  1.9879e+01  3.2982e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -8.5e-06       54-      46  1.1569e+02  1.2640e+01  3.3656e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.5e-06       59-      38  1.3588e+02  1.5502e+01  1.3414e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.9e-06       70-      52  1.1046e+02  1.7335e+01  9.7806e-06
    1T  7.2e-06       43-      46  1.2455e+02  1.2371e+01  1.3682e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.0e-06       54-      49  1.1798e+02  1.2987e+01  9.0042e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       54-      52  3.3399e+02  2.9337e+01  8.3481e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.7e-06       65-      48  1.2737e+02  1.8776e+01  4.4298e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.6e-06       22-      55  1.2282e+02  1.7877e+01  5.4101e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       24-      47  1.2574e+02  1.3811e+01  1.2368e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       65-      43  1.3223e+02  1.3347e+01  2.6478e-06
    1T  8.2e-06       51-      49  1.2496e+02  1.3318e+01  2.8624e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.9e-06       38-      58  1.2362e+02  2.2026e+01  1.5324e-04
    1T  7.6e-06       27-      56  1.3716e+02  2.2664e+01  9.9393e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.3e-06       40-      52  1.2904e+02  1.3210e+01  6.4528e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -3.8e-06       69-      49  1.2323e+02  1.3904e+01  3.8169e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -1.0e-05       36-      44  1.1630e+02  1.3482e+01  5.2185e-04
    1T -1.4e-06       41-      68  1.9038e+03  4.5059e+01  1.5064e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06       45-      52  1.1693e+02  1.3560e+01  1.1069e-06
    1T  4.3e-06       21-      53  1.3235e+02  1.9453e+01  7.6332e-07
    1T -9.7e-06       64-      49  1.2936e+02  1.8007e+01  1.9001e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.8e-06       51-      56  1.3142e+02  2.3216e+01  5.0024e-07
    1T -8.9e-06       34-      61  1.5119e+03  5.4324e+01  4.0018e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06       16-      61  1.2572e+02  2.4795e+01  1.1587e-06
    1T  7.3e-06       59-      58  1.6930e+02  3.0157e+01  1.0799e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.7e-06       25-      56  1.2147e+02  1.5860e+01  7.6117e-07
    1T  9.3e-06       36-      54  1.3536e+02  1.8835e+01  1.3769e-06
    1T -8.7e-06       14-      51  1.2768e+02  1.2605e+01  2.6886e-04
    1T -6.9e-06       12-      67  5.1190e+02  5.4481e+01  1.6030e-07
    1T -9.3e-06        5-      48  1.2593e+02  1.4886e+01  5.2545e-04
    1T  2.5e-06       25-      60  1.2244e+02  2.4460e+01  3.7164e-07
    1T  3.5e-06       16-      47  1.3569e+02  1.5767e+01  4.3075e-07
    1T  7.7e-06       70-      44  1.2789e+02  1.4156e+01  4.6560e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-07       25-      55  1.3101e+02  1.9015e+01  8.3351e-08
    1T  6.6e-07       45-      65  2.2069e+03  4.9078e+01  6.8426e-04
    1T  9.2e-06       35-      67  1.7903e+03  5.7120e+01  9.2053e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.1e-06       52-      56  2.7834e+02  4.6583e+01  3.9880e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -4.1e-07       74-      62  1.5885e+03  3.8223e+01  1.1169e-03
    1T  2.2e-06        6-      66  6.0211e+02  6.7244e+01  9.3649e-06
    1T -8.0e-06       60-      69  7.5443e+02  6.3744e+01  2.3679e-03
    1T -1.4e-06        4-      64  1.5748e+03  4.2099e+01  3.9100e-08
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   135   116   177   166    61    92    21   129    39    25   184    95   130

  Columns 14 through 26

   180   171   115   130   166   166     6   127   162   103   163    82   166

  Columns 27 through 30

    57   137    14   189

{Index in position 3 exceeds array bounds (must not exceed 225).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       37-      50  4.7250e+02  2.3398e+06  1.0519e-04
    1T  5.5e-06       72-      42  1.9097e+02  1.9260e+05  7.0303e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       72-      34  4.3129e+02  2.0992e+05  9.6440e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       23-      53  9.6242e+02  6.3481e+01  9.9075e-06
    1T  6.0e-06       38-      43  4.8184e+02  4.0576e+01  6.1714e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       56-      44  6.4656e+02  4.1516e+01  1.9024e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       56-      37  4.3168e+02  4.4536e+01  1.6863e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       19-      52  1.1011e+03  7.2036e+01  3.0076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       55-      48  3.0625e+02  7.6915e+01  9.2051e-07
    1T  9.7e-06       73-      45  3.8106e+02  4.2600e+01  4.0938e-06
    1T  2.5e-06       62-      41  9.0105e+02  4.1242e+01  5.4698e-07
    1T -9.4e-06       37-      48  1.5859e+03  6.9246e+01  3.2582e-05
    1T  9.4e-06        2-      53  2.9340e+03  9.3537e+01  4.0075e-06
    1T  5.9e-06       56-      50  1.7399e+02  5.9152e+01  6.9376e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       16-      48  2.8647e+02  5.6404e+01  3.3273e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       30-      42  8.5048e+02  3.9207e+01  2.0289e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       36-      55  7.0423e+02  6.6866e+01  2.1366e-06
    1T  1.5e-06       52-      47  9.9770e+02  4.7028e+01  1.9058e-06
    1T  2.1e-06       69-      51  1.8372e+03  8.6607e+01  3.2951e-03
    1T  5.0e-06       18-      56  1.2724e+03  1.0634e+02  1.2326e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       55-      39  1.6594e+03  4.7974e+01  3.2119e-03
    1T  4.3e-06       52-      47  3.8623e+02  8.7172e+01  2.4350e-06
    1T  1.1e-06       14-      50  3.6582e+02  5.2441e+01  9.3543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       12-      40  5.5690e+02  4.5200e+01  1.1818e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  2.0e-06       36-      49  9.5368e+02  4.4198e+01  3.2246e-07
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.2e-06       68-      53  3.1282e+03  6.9833e+01  8.9848e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       39-      49  1.3001e+03  1.3013e+02  6.2194e-07
    1T  8.3e-06       72-      47  5.9641e+02  9.3298e+01  1.3833e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       37-      47  1.5253e+03  1.1076e+02  5.6004e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       10-      45  2.2681e+03  8.0807e+01  7.2432e-07
    1T  6.7e-06       16-      47  1.5019e+03  1.0164e+02  3.5283e-05
    1T -9.7e-06       75-      38  3.6130e+02  6.7211e+01  8.4337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       16-      51  8.4339e+02  8.5983e+01  1.9594e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        4-      44  6.3131e+02  9.2953e+01  3.3843e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       27-      53  2.5665e+02  1.4004e+02  5.0567e-07
    1T  9.0e-06       18-      37  2.9176e+02  7.7553e+01  1.0234e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   129   191     7    64    72    76    66    41   137   183   157   176    59

  Columns 14 through 26

    42    77    40    81    73    98    87    76   146   124    22   142    96

  Columns 27 through 30

   120   107   180    66

{Index in position 3 exceeds array bounds (must not exceed 225).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       72-      42  1.9097e+02  1.9260e+05  7.0303e-06
    1T  3.4e-06       37-      50  4.7250e+02  2.3398e+06  1.0519e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       72-      34  4.3129e+02  2.0992e+05  9.6440e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       23-      53  9.6242e+02  6.3481e+01  9.9075e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       38-      43  4.8184e+02  4.0576e+01  6.1714e-06
    1T -6.0e-06       56-      44  6.4656e+02  4.1516e+01  1.9024e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       56-      37  4.3168e+02  4.4536e+01  1.6863e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       19-      52  1.1011e+03  7.2036e+01  3.0076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.9e-06       56-      50  1.7399e+02  5.9152e+01  6.9376e-07
    1T  5.3e-06       55-      48  3.0625e+02  7.6915e+01  9.2051e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06        2-      53  2.9340e+03  9.3537e+01  4.0075e-06
    1T  9.7e-06       73-      45  3.8106e+02  4.2600e+01  4.0938e-06
    1T -9.4e-06       37-      48  1.5859e+03  6.9246e+01  3.2582e-05
    1T  2.5e-06       62-      41  9.0105e+02  4.1242e+01  5.4698e-07
    1T  8.9e-06       16-      48  2.8647e+02  5.6404e+01  3.3273e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       52-      47  9.9770e+02  4.7028e+01  1.9058e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       30-      42  8.5048e+02  3.9207e+01  2.0289e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       36-      55  7.0423e+02  6.6866e+01  2.1366e-06
    1T  4.3e-06       52-      47  3.8623e+02  8.7172e+01  2.4350e-06
    1T  2.1e-06       69-      51  1.8372e+03  8.6607e+01  3.2951e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.2e-06       68-      53  3.1282e+03  6.9833e+01  8.9848e-07
    1T  1.1e-06       14-      50  3.6582e+02  5.2441e+01  9.3543e-07
    1T  5.0e-06       18-      56  1.2724e+03  1.0634e+02  1.2326e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       36-      49  9.5368e+02  4.4198e+01  3.2246e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       12-      40  5.5690e+02  4.5200e+01  1.1818e-05
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  4.2e-06       55-      39  1.6594e+03  4.7974e+01  3.2119e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       39-      49  1.3001e+03  1.3013e+02  6.2194e-07
    1T  8.3e-06       72-      47  5.9641e+02  9.3298e+01  1.3833e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       37-      47  1.5253e+03  1.1076e+02  5.6004e-07
    1T  4.4e-06       10-      45  2.2681e+03  8.0807e+01  7.2432e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.7e-06       75-      38  3.6130e+02  6.7211e+01  8.4337e-04
    1T  6.7e-06       16-      47  1.5019e+03  1.0164e+02  3.5283e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       16-      51  8.4339e+02  8.5983e+01  1.9594e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        4-      44  6.3131e+02  9.2953e+01  3.3843e-07
    1T  9.0e-06       18-      37  2.9176e+02  7.7553e+01  1.0234e-03
    1T  2.5e-06       27-      53  2.5665e+02  1.4004e+02  5.0567e-07
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    26    18     6    41   166    93   110     9   111   139   179    80   137

  Columns 14 through 26

   196     2   175    61    59   136   193    52   145    59    63    52    99

  Columns 27 through 30

   171    39    38   161

{Index in position 3 exceeds array bounds (must not exceed 225).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*4  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       37-      50  4.7250e+02  2.3398e+06  1.0519e-04
    1T  5.5e-06       72-      42  1.9097e+02  1.9260e+05  7.0303e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       72-      34  4.3129e+02  2.0992e+05  9.6440e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       23-      53  9.6242e+02  6.3481e+01  9.9075e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.0e-06       38-      43  4.8184e+02  4.0576e+01  6.1714e-06
    1T -6.0e-06       56-      44  6.4656e+02  4.1516e+01  1.9024e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       56-      37  4.3168e+02  4.4536e+01  1.6863e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       19-      52  1.1011e+03  7.2036e+01  3.0076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06        2-      53  2.9340e+03  9.3537e+01  4.0075e-06
    1T  5.9e-06       56-      50  1.7399e+02  5.9152e+01  6.9376e-07
    1T  9.7e-06       73-      45  3.8106e+02  4.2600e+01  4.0938e-06
    1T  5.3e-06       55-      48  3.0625e+02  7.6915e+01  9.2051e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       16-      48  2.8647e+02  5.6404e+01  3.3273e-03
    1T  2.5e-06       62-      41  9.0105e+02  4.1242e+01  5.4698e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       37-      48  1.5859e+03  6.9246e+01  3.2582e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       52-      47  9.9770e+02  4.7028e+01  1.9058e-06
    1T  2.6e-06       30-      42  8.5048e+02  3.9207e+01  2.0289e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       36-      55  7.0423e+02  6.6866e+01  2.1366e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       52-      47  3.8623e+02  8.7172e+01  2.4350e-06
    1T  2.1e-06       69-      51  1.8372e+03  8.6607e+01  3.2951e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       36-      49  9.5368e+02  4.4198e+01  3.2246e-07
    1T  3.2e-06       68-      53  3.1282e+03  6.9833e+01  8.9848e-07
    1T  5.0e-06       18-      56  1.2724e+03  1.0634e+02  1.2326e-06
    1T  1.1e-06       14-      50  3.6582e+02  5.2441e+01  9.3543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  4.2e-06       55-      39  1.6594e+03  4.7974e+01  3.2119e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       12-      40  5.5690e+02  4.5200e+01  1.1818e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       39-      49  1.3001e+03  1.3013e+02  6.2194e-07
    1T  8.3e-06       72-      47  5.9641e+02  9.3298e+01  1.3833e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       37-      47  1.5253e+03  1.1076e+02  5.6004e-07
    1T  4.4e-06       10-      45  2.2681e+03  8.0807e+01  7.2432e-07
    1T -9.7e-06       75-      38  3.6130e+02  6.7211e+01  8.4337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.7e-06       16-      47  1.5019e+03  1.0164e+02  3.5283e-05
    1T  1.4e-06       16-      51  8.4339e+02  8.5983e+01  1.9594e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        4-      44  6.3131e+02  9.2953e+01  3.3843e-07
    1T  2.5e-06       27-      53  2.5665e+02  1.4004e+02  5.0567e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       18-      37  2.9176e+02  7.7553e+01  1.0234e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    76   147   200   172    22   128   113    99   109   152    13    27   136

  Columns 14 through 26

   146   184    75    71   114   191   152    64   137    30    67   189   121

  Columns 27 through 30

    79    38   152   150

{Index in position 3 exceeds array bounds (must not exceed 225).

Error in SVM_train (line 20)
flatFeatures=reshape(totalFeatures(:,:,1:trainingNum),[rows*cols trainingNum]);
} 
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'labeled_pixels_crop'.
} 
class_accuracy

class_accuracy =

     0
     0
     0
     0
     0
     0
     0
     0
     0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

     0




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*3  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.4e-06       37-      50  4.7250e+02  2.3398e+06  1.0519e-04
    1T  5.5e-06       72-      42  1.9097e+02  1.9260e+05  7.0303e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       72-      34  4.3129e+02  2.0992e+05  9.6440e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       23-      53  9.6242e+02  6.3481e+01  9.9075e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -6.0e-06       56-      44  6.4656e+02  4.1516e+01  1.9024e-03
    1T  6.0e-06       38-      43  4.8184e+02  4.0576e+01  6.1714e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       56-      37  4.3168e+02  4.4536e+01  1.6863e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       19-      52  1.1011e+03  7.2036e+01  3.0076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       55-      48  3.0625e+02  7.6915e+01  9.2051e-07
    1T  9.4e-06        2-      53  2.9340e+03  9.3537e+01  4.0075e-06
    1T  9.7e-06       73-      45  3.8106e+02  4.2600e+01  4.0938e-06
    1T  5.9e-06       56-      50  1.7399e+02  5.9152e+01  6.9376e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.9e-06       16-      48  2.8647e+02  5.6404e+01  3.3273e-03
    1T  2.5e-06       62-      41  9.0105e+02  4.1242e+01  5.4698e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -9.4e-06       37-      48  1.5859e+03  6.9246e+01  3.2582e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.5e-06       52-      47  9.9770e+02  4.7028e+01  1.9058e-06
    1T  2.6e-06       30-      42  8.5048e+02  3.9207e+01  2.0289e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       36-      55  7.0423e+02  6.6866e+01  2.1366e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       52-      47  3.8623e+02  8.7172e+01  2.4350e-06
    1T  2.1e-06       69-      51  1.8372e+03  8.6607e+01  3.2951e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.0e-06       18-      56  1.2724e+03  1.0634e+02  1.2326e-06
    1T  3.2e-06       68-      53  3.1282e+03  6.9833e+01  8.9848e-07
    1T  2.0e-06       36-      49  9.5368e+02  4.4198e+01  3.2246e-07
    1T  1.1e-06       14-      50  3.6582e+02  5.2441e+01  9.3543e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       12-      40  5.5690e+02  4.5200e+01  1.1818e-05
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       55-      39  1.6594e+03  4.7974e+01  3.2119e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       39-      49  1.3001e+03  1.3013e+02  6.2194e-07
    1T  8.3e-06       72-      47  5.9641e+02  9.3298e+01  1.3833e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       37-      47  1.5253e+03  1.1076e+02  5.6004e-07
    1T  4.4e-06       10-      45  2.2681e+03  8.0807e+01  7.2432e-07
    1T -9.7e-06       75-      38  3.6130e+02  6.7211e+01  8.4337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.4e-06       16-      51  8.4339e+02  8.5983e+01  1.9594e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        4-      44  6.3131e+02  9.2953e+01  3.3843e-07
    1T  6.7e-06       16-      47  1.5019e+03  1.0164e+02  3.5283e-05
    1T  2.5e-06       27-      53  2.5665e+02  1.4004e+02  5.0567e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       18-      37  2.9176e+02  7.7553e+01  1.0234e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   127   132    69   139   181   153   135    83    22   161     8   123   111

  Columns 14 through 26

   157    38    38   142    98    54   125    20    51   131    28    96    65

  Columns 27 through 30

   114    24    29   176


Accuracy =

    2.2740


Accuracy =

    6.0131


Accuracy =

    6.7004


Accuracy =

    6.9304


Accuracy =

    5.7934


Accuracy =

    4.2818


Accuracy =

    7.1035


Accuracy =

    3.7262


Accuracy =

    5.3335


Accuracy =

    7.8116


Accuracy =7.811571e+00
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

         0
         0
         0
    0.2531
   22.6601
   60.1495
    0.4160
         0
         0

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

    9.2754




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('PaviaU');

load('PaviaU_gt');
image=paviaU;
image_gt=paviaU_gt;
size(image)

ans =

   610   340   103


train_on_image=0;

databaseID=2;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

  uint8

   1


ii =

  uint8

   2


ii =

  uint8

   3


ii =

  uint8

   4


ii =

  uint8

   5


ii =

  uint8

   6


ii =

  uint8

   7


ii =

  uint8

   8


ii =

  uint8

   9


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*3  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.5e-06       72-      42  1.9097e+02  1.9260e+05  7.0303e-06
    1T  3.4e-06       37-      50  4.7250e+02  2.3398e+06  1.0519e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.8e-06       72-      34  4.3129e+02  2.0992e+05  9.6440e-07
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.8e-06       23-      53  9.6242e+02  6.3481e+01  9.9075e-06
    1T  6.0e-06       38-      43  4.8184e+02  4.0576e+01  6.1714e-06
    1T -6.0e-06       56-      44  6.4656e+02  4.1516e+01  1.9024e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.6e-06       56-      37  4.3168e+02  4.4536e+01  1.6863e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.6e-06       19-      52  1.1011e+03  7.2036e+01  3.0076e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.4e-06        2-      53  2.9340e+03  9.3537e+01  4.0075e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.3e-06       55-      48  3.0625e+02  7.6915e+01  9.2051e-07
    1T  5.9e-06       56-      50  1.7399e+02  5.9152e+01  6.9376e-07
    1T  9.7e-06       73-      45  3.8106e+02  4.2600e+01  4.0938e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       62-      41  9.0105e+02  4.1242e+01  5.4698e-07
    1T  8.9e-06       16-      48  2.8647e+02  5.6404e+01  3.3273e-03
    1T -9.4e-06       37-      48  1.5859e+03  6.9246e+01  3.2582e-05
    1T  1.5e-06       52-      47  9.9770e+02  4.7028e+01  1.9058e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.6e-06       30-      42  8.5048e+02  3.9207e+01  2.0289e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       36-      55  7.0423e+02  6.6866e+01  2.1366e-06
    1T  2.1e-06       69-      51  1.8372e+03  8.6607e+01  3.2951e-03

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.3e-06       52-      47  3.8623e+02  8.7172e+01  2.4350e-06
    1T  1.1e-06       14-      50  3.6582e+02  5.2441e+01  9.3543e-07
    1T  5.0e-06       18-      56  1.2724e+03  1.0634e+02  1.2326e-06
    1T  3.2e-06       68-      53  3.1282e+03  6.9833e+01  8.9848e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       36-      49  9.5368e+02  4.4198e+01  3.2246e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.2e-06       55-      39  1.6594e+03  4.7974e+01  3.2119e-03
    1T  9.0e-06       12-      40  5.5690e+02  4.5200e+01  1.1818e-05
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  3.9e-06       18-      46  4.1703e+02  6.5129e+01  1.3268e-06
Parallel pool using the 'local' profile is shutting down.
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.3e-06       72-      47  5.9641e+02  9.3298e+01  1.3833e-06
    1T  4.2e-06       39-      49  1.3001e+03  1.3013e+02  6.2194e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       10-      45  2.2681e+03  8.0807e+01  7.2432e-07
    1T -9.7e-06       75-      38  3.6130e+02  6.7211e+01  8.4337e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.0e-06       37-      47  1.5253e+03  1.1076e+02  5.6004e-07
    1T  1.4e-06       16-      51  8.4339e+02  8.5983e+01  1.9594e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       27-      53  2.5665e+02  1.4004e+02  5.0567e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  9.0e-06       18-      37  2.9176e+02  7.7553e+01  1.0234e-03
    1T  6.7e-06       16-      47  1.5019e+03  1.0164e+02  3.5283e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.3e-06        4-      44  6.3131e+02  9.2953e+01  3.3843e-07
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   137    62   184    48   132   125    23    53    44    57   104   172    88

  Columns 14 through 26

   172    19   136    33    67    53    76    28    21    92   179   179   107

  Columns 27 through 30

   136    76    95   102


Accuracy =

    8.6581


Accuracy =

   18.0299


Accuracy =

    5.1643


Accuracy =

    3.7006


Accuracy =

    4.9109


Accuracy =

    8.0918


Accuracy =

    6.4134


Accuracy =

    4.8488


Accuracy =

    4.3549


Accuracy =

    7.7969


Accuracy =7.796943e+00
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

  uint8

   1


i =

  uint8

   2


i =

  uint8

   3


i =

  uint8

   4


i =

  uint8

   5


i =

  uint8

   6


i =

  uint8

   7


i =

  uint8

   8


i =

  uint8

   9

class_accuracy

class_accuracy =

         0
   15.5119
   12.7503
         0
    2.4691
         0
    2.0833
    1.2909
    7.0340

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

    4.5711




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('indian_pines_corrected');
{Error using load
Unable to read file 'indian_pines_corrected'. No such file or directory.
} 

load('indian_pines_gt');
{Error using load
Unable to read file 'indian_pines_gt'. No such file or directory.
} 
image=indian_pines_corrected;
{Undefined function or variable 'indian_pines_corrected'.
} 
image_gt=indian_pines_gt;
{Undefined function or variable 'indian_pines_gt'.
} 
size(image)
[Warning: MATLAB has disabled some advanced graphics rendering features by
switching to software OpenGL. For more information, click <a
href="matlab:opengl('problems')">here</a>.] 

ans =

     1     1


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end
{Undefined function or variable 'image'.
} 


class_num=max(max(image_gt));
{Undefined function or variable 'image_gt'.
} 

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);
{Undefined function or variable 'image_gt'.
} 

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end
{Undefined function or variable 'class_num'.
} 

 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*3  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
{Error using randi
First input must be a positive scalar integer value IMAX, or two integer values
[IMIN IMAX] with IMIN less than or equal to IMAX.
} 
SVM_train;

indexes =

  Columns 1 through 13

    58    22   128   161    73    63   181    64    47   115   102    15   200

  Columns 14 through 26

   144    72    14   176   142   116   132   124   187    24    13   130    92

  Columns 27 through 30

    69     5   144   176

{Undefined function or variable 'image_gt'.

Error in SVM_train (line 11)
class_num=max(max(image_gt));
} 
class_accuracy=zeros(class_num,1);
{Undefined function or variable 'class_num'.
} 
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end
{Undefined function or variable 'class_num'.
} 
class_accuracy
{Undefined function or variable 'class_accuracy'.
} 
AverageAccuracy=mean(class_accuracy)
{Undefined function or variable 'class_accuracy'.
} 



clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=6:2:10
    R=75;
components=75;
trainingNum=75*3  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [36x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  1.0e-06        4-      64  2.0005e+03  5.5940e+01  7.7747e-04
    1T  6.4e-08       37-      73  2.8495e+03  7.2747e+01  6.5980e-08
    1T  1.7e-06       29-      71  2.5083e+03  6.4765e+01  9.2376e-07

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  8.0e-06       75-      72  2.2152e+03  5.7160e+01  1.0662e-05
    1T  1.1e-06       21-      65  1.4327e+03  5.9382e+01  2.3143e-05
    1T  4.1e-06       62-      69  9.5524e+02  5.8081e+01  1.1458e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  7.1e-06       56-      68  2.5860e+03  5.0698e+01  1.0009e-05
    1T  4.2e-06       48-      69  2.4340e+03  5.8598e+01  1.5976e-04

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T -5.6e-06       26-      62  1.6495e+03  5.0098e+01  1.5284e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.5e-06       33-      53  8.8568e+02  4.6114e+01  9.5022e-06
    1T -4.8e-06       34-      57  1.7750e+03  4.4036e+01  1.0059e-05
Parallel pool using the 'local' profile is shutting down.
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [100x75]             

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       62-      60  1.4343e+03  4.0627e+01  1.3452e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       62-      60  1.4343e+03  4.0627e+01  1.3452e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       62-      60  1.4343e+03  4.0627e+01  1.3452e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       62-      60  1.4343e+03  4.0627e+01  1.3452e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  6.2e-06       62-      60  1.4343e+03  4.0627e+01  1.3452e-05
    1T  4.5e-06       13-      71  3.3177e+03  5.2709e+01  3.8450e-05
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

     2   137   126    81    21    31   178   179   164    93    58    69    43

  Columns 14 through 26

   160   179   152    79    75    85    96   104    22    77   197   153    32

  Columns 27 through 30

   185   178   178     5

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.6440


Accuracy =

   96.7088


Accuracy =

   96.3419


Accuracy =

   96.6332


Accuracy =

   96.4606


Accuracy =

   96.7303


Accuracy =

   96.4498


Accuracy =

   96.6980


Accuracy =

   96.5793


Accuracy =

   96.8275


Accuracy =9.682745e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   33.3333
   96.0434
   96.1282
   92.5234
   99.0868
   98.6384
  100.0000
  100.0000
   72.2222
   94.1847
   98.6030
   93.4823
   95.1613
   98.6014
   99.1429
   91.6667

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   91.1761




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.4e-06       67-      68  2.1737e+03  4.3659e+01  1.1839e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.7e-07       74-      63  1.0556e+03  4.0255e+01  8.2565e-06
    1T -2.1e-06       69-      66  1.3374e+03  4.6053e+01  4.8084e-06
    1T  5.7e-06       53-      66  1.8016e+03  4.8943e+01  3.7754e-05

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  2.9e-06       10-      65  1.7411e+03  4.0279e+01  1.1756e-04
    1T  3.1e-06       61-      58  1.1570e+03  4.4290e+01  9.9398e-03
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

   132    72   160     7    53    44    54   155   157    88    84   130    76

  Columns 14 through 26

    91   125   196    71   170    38    28    52    43    49   132    32   152

  Columns 27 through 30

    41   116    25    58

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   96.3254


Accuracy =

   96.1315


Accuracy =

   95.7435


Accuracy =

   95.9914


Accuracy =

   96.3470


Accuracy =

   96.4224


Accuracy =

   96.4547


Accuracy =

   96.3470


Accuracy =

   96.4440


Accuracy =

   96.3793


Accuracy =9.637931e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   88.0952
   97.8345
   95.3395
   97.2222
   98.1735
   96.2236
   96.1538
   99.3039
   57.8947
   93.9567
   95.1824
   92.0370
   98.3784
   99.5633
   98.8571
   97.6190

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   93.8647




clear all;
%%%according to indian_pines doc bands: 1,33,97,161 were all zeros and not
%%%used
rng('shuffle');
filename= 'PaviaU' ;

load('Indian_pines_corrected');

load('Indian_pines_gt');
image=indian_pines_corrected;
image_gt=indian_pines_gt;
size(image)

ans =

   145   145   200


train_on_image=1;

databaseID=0;%%%1 for salinas, 0 for indian_pines, 2 for pavia U
[r,c,bands]=size(image);
image_added=zeros(r,c,224);


if(databaseID==1)
%      image_added(:, :, 1:108) = image(:, :, 1:108);
%              image_added(:, :, 113:154) = image(:, :, 108:149);
%              image_added(:, :, 168:224) = image(:, :, 149:205);
% 
    image(:,:,[1,33,97,161])=[]; 
end
if(databaseID==2)

    image(:,:,2)=[]; 
end
% else
%     image_added(:,:,1:104)=image(:,:,1:104);
%     image_added(:,:,110:150)=image(:,:,105:145);
%     image_added(:,:,165:220)=image(:,:,145:200);
%     end
% image=image_added;
[r,c,bands]=size(image);
for i=1:bands
    
meanImage=min(min(image(:,:,i)));
image(:,:,i)=image(:,:,i)-meanImage*ones(size(image(:,:,i)));
maxImage=max(max(image(:,:,i)));
image(:,:,i)=image(:,:,i)./maxImage*255;
end


class_num=max(max(image_gt));

T=permute(image,[3 1 2]);;
Ttemp=double(T); 
[bands row_original col_original]=size(Ttemp);

rows=row_original;
cols=col_original;

maxAccuracy=0;
im_predict_max=[];
max_features=[];


flatImage=reshape(image_gt,[rows*cols 1]);

inds=[];
for ii=1:class_num
    ii
    classInds=find(flatImage==ii);
    
   
    size_i=size(classInds,1);
    if(size_i==0)
        continue;
    end
    
 classInds=classInds(randi( size_i,1,floor(0.1*size_i)));
inds=cat(1,inds, classInds);


end

ii =

     1


ii =

     2


ii =

     3


ii =

     4


ii =

     5


ii =

     6


ii =

     7


ii =

     8


ii =

     9


ii =

    10


ii =

    11


ii =

    12


ii =

    13


ii =

    14


ii =

    15


ii =

    16


 size_i=size(inds,1);

bsize=2

bsize =

     2

begin=1

begin =

     1

bbegin=1

bbegin =

     1

count=1

count =

     1

bcount=1

bcount =

     1


totalFeatures=[];
for bsize=8:8:8
    R=75;
components=75;
trainingNum=75  ;



pcount=1;

if(train_on_image==1)

rand_num=2000;
clear patches;
while(pcount<rand_num)
    
    i=randi([bsize/2,rows-bsize/2-1]);
    j=randi([bsize/2,cols-bsize/2-1]);
    if(image_gt(i,j)>0)
        fcount=1;
       for x=i-bsize/2+1:i+bsize/2
           for y=j-bsize/2+1:j+bsize/2
               patch=Ttemp(:,i,j);
               patches(:,pcount,fcount)=patch;
               fcount=fcount+1;
           end
       end
     
     pcount=pcount+1;      
   end
   
   
end

   

FactorizeTensor;

CreateDictionaryBands;

save(strcat('Dictionary',int2str(bsize)),'dictionary');

else
   load(strcat('Dictionary',int2str(bsize)));
end

create_centered_features_bands;
totalFeatures=cat(3,totalFeatures,imageFeatures);
end
Entered factorization
Factor               Size                 Comment                                 
--------------------------------------------------------------------------------
A                    [200x75]             
B                    [1999x75]            
C                    [64x75]              

Factorization        Type       Factors              Comments            
--------------------------------------------------------------------------------
tensor (id = 1)      cpd        A,B,C                                    
reg (id = 2)         regL1      B,A,C                                    
entered dictionary creation
feature calculation enter
Starting parallel pool (parpool) using the 'local' profile ...
Preserving jobs with IDs: 8 10 because they contain crash dump files.
You can use 'delete(myCluster.Jobs)' to remove all jobs created with profile local. To create 'myCluster' use 'myCluster = parcluster('local')'.
connected to 36 workers.

ans = 

 Pool with properties: 

            Connected: true
           NumWorkers: 36
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  4.0e-06       33-      57  1.3588e+03  4.3400e+01  6.8754e-06

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm

  Itn    xSmall Add/Drop   Active      rNorm2      xNorm1      dyNorm
    1T  5.1e-06       67-      60  1.5205e+03  4.5583e+01  2.9776e-05
    1T  4.1e-06       20-      64  1.4384e+03  4.7996e+01  1.7000e-04
Parallel pool using the 'local' profile is shutting down.
SVM_train;

indexes =

  Columns 1 through 13

    16    63   140   189    95    50   171    48    82   142   199    27    28

  Columns 14 through 26

    24    82    58   102    28    49    63   191    72   149   144    54   143

  Columns 27 through 30

   169    36   138    87

[Warning: One or more folds do not contain points from all the groups.] 
[> In internal.stats.cvpartitionImpl>stra_kfoldcv (line 364)
  In internal.stats.cvpartitionImpl/rerandom (line 315)
  In internal.stats.cvpartitionInMemoryImpl (line 166)
  In cvpartition (line 175)
  In classreg.learning.generator.Partitioner (line 52)
  In classreg.learning.modelparams.EnsembleParams/makeGenerator (line 349)
  In classreg.learning.modelparams.EnsembleParams/fillDefaultParams (line 589)
  In classreg.learning.modelparams.ModelParams/fillIfNeeded (line 93)
  In classreg.learning.classif.FullClassificationModel (line 35)
  In classreg.learning.classif.ClassificationEnsemble (line 69)
  In classreg.learning.partition.ClassificationPartitionedModel (line 159)
  In classreg.learning.partition.ClassificationPartitionedECOC (line 78)
  In classreg.learning.FitTemplate/fit (line 258)
  In ClassificationECOC/crossval (line 247)
  In SVM_train (line 71)] 

Accuracy =

   95.9276


Accuracy =

   96.0892


Accuracy =

   95.6798


Accuracy =

   96.2831


Accuracy =

   95.9061


Accuracy =

   95.7983


Accuracy =

   95.6475


Accuracy =

   96.2616


Accuracy =

   95.9599


Accuracy =

   96.2939


Accuracy =9.629390e+01
class_accuracy=zeros(class_num,1);
for i=1:class_num
indsi=(find(labeled_pixels_crop==i));
true_labelsi=labeled_pixels_crop(indsi);
labelsi=labels(indsi);
i
class_accuracy(i)=(mean(true_labelsi==labelsi)*100);

end

i =

     1


i =

     2


i =

     3


i =

     4


i =

     5


i =

     6


i =

     7


i =

     8


i =

     9


i =

    10


i =

    11


i =

    12


i =

    13


i =

    14


i =

    15


i =

    16

class_accuracy

class_accuracy =

   86.0465
   96.0465
   95.0601
   91.2442
   91.9908
   97.8756
  100.0000
   99.7685
   66.6667
   94.5268
   98.2511
   92.9236
  100.0000
   98.7773
   90.6250
   96.4286

AverageAccuracy=mean(class_accuracy)

AverageAccuracy =

   93.5145




